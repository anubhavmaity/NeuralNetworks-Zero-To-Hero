<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>NeuralNetworks-Zero-To-Hero - Building makemore - Activations &amp; Gradients, BatchNorm</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="NeuralNetworks-Zero-To-Hero - Building makemore - Activations &amp; Gradients, BatchNorm">
<meta property="og:description" content="">
<meta property="og:image" content="https://anubhavmaity.github.io/NeuralNetworks-Zero-To-Hero/lecture_notes/04_building_makemore_mlp2_files/figure-html/cell-22-output-1.png">
<meta property="og:site-name" content="NeuralNetworks-Zero-To-Hero">
<meta property="og:image:height" content="413">
<meta property="og:image:width" content="547">
<meta name="twitter:title" content="NeuralNetworks-Zero-To-Hero - Building makemore - Activations &amp; Gradients, BatchNorm">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://anubhavmaity.github.io/NeuralNetworks-Zero-To-Hero/lecture_notes/04_building_makemore_mlp2_files/figure-html/cell-22-output-1.png">
<meta name="twitter:image-height" content="413">
<meta name="twitter:image-width" content="547">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">NeuralNetworks-Zero-To-Hero</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../lecture_notes/building_micrograd.html">lecture_notes</a></li><li class="breadcrumb-item"><a href="../lecture_notes/building_makemore_mlp2.html">Building makemore - Activations &amp; Gradients, BatchNorm</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">NeuralNetworks-Zero-To-Hero</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">exercises</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/micrograd_from_scratch_exercise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Micrograd from scratch exercise</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/building_makemore_execise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building makemore exercise</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/building_makemore_mlp_exercise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building Makemore MLP Exercise</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/building_makemore_mlp2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building Makemore MLP 2 Exercise</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/wavenet_exercise-1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wavenet Hyperparameter Tuning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../exercises/wavenet_exercise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wavenet Hyperparameter Tuning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">lecture_notes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lecture_notes/building_micrograd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mircrograd from scratch</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lecture_notes/building_makemore.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building makemore</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lecture_notes/building_makemore_mlp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building makemore - MLP</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lecture_notes/building_makemore_mlp2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Building makemore - Activations &amp; Gradients, BatchNorm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lecture_notes/becoming_backprop_ninja.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lesson 5: Becoming a Backprop Ninja</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../lecture_notes/building_a_wavenet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building a WaveNet</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#imports" id="toc-imports" class="nav-link active" data-scroll-target="#imports">Imports</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#train" id="toc-train" class="nav-link" data-scroll-target="#train">Train</a></li>
  <li><a href="#evaluate-loss" id="toc-evaluate-loss" class="nav-link" data-scroll-target="#evaluate-loss">Evaluate Loss</a></li>
  <li><a href="#sampling" id="toc-sampling" class="nav-link" data-scroll-target="#sampling">Sampling</a></li>
  <li><a href="#fixing-the-initial-loss" id="toc-fixing-the-initial-loss" class="nav-link" data-scroll-target="#fixing-the-initial-loss">Fixing the initial loss</a>
  <ul class="collapse">
  <li><a href="#sample-issue" id="toc-sample-issue" class="nav-link" data-scroll-target="#sample-issue">Sample issue</a></li>
  </ul></li>
  <li><a href="#fix-the-saturated-tanh" id="toc-fix-the-saturated-tanh" class="nav-link" data-scroll-target="#fix-the-saturated-tanh">Fix the saturated tanh</a>
  <ul class="collapse">
  <li><a href="#plot-tanh" id="toc-plot-tanh" class="nav-link" data-scroll-target="#plot-tanh">Plot <code>tanh</code></a></li>
  <li><a href="#visualize-h" id="toc-visualize-h" class="nav-link" data-scroll-target="#visualize-h">Visualize h</a></li>
  </ul></li>
  <li><a href="#calculating-the-init-scale-kaiming-init" id="toc-calculating-the-init-scale-kaiming-init" class="nav-link" data-scroll-target="#calculating-the-init-scale-kaiming-init">Calculating the init scale: “Kaiming init”</a></li>
  <li><a href="#batch-normalization" id="toc-batch-normalization" class="nav-link" data-scroll-target="#batch-normalization">Batch Normalization</a>
  <ul class="collapse">
  <li><a href="#normalization" id="toc-normalization" class="nav-link" data-scroll-target="#normalization">Normalization</a></li>
  <li><a href="#define-new-training" id="toc-define-new-training" class="nav-link" data-scroll-target="#define-new-training">Define new training</a></li>
  <li><a href="#consider-the-training-set-mean-and-std-deviation" id="toc-consider-the-training-set-mean-and-std-deviation" class="nav-link" data-scroll-target="#consider-the-training-set-mean-and-std-deviation">Consider the Training set mean and std deviation</a></li>
  <li><a href="#compute-running-mean-and-std" id="toc-compute-running-mean-and-std" class="nav-link" data-scroll-target="#compute-running-mean-and-std">Compute running mean and std</a></li>
  </ul></li>
  <li><a href="#pytorchifying-the-code" id="toc-pytorchifying-the-code" class="nav-link" data-scroll-target="#pytorchifying-the-code">Pytorchifying the code</a>
  <ul class="collapse">
  <li><a href="#only-non-linearities" id="toc-only-non-linearities" class="nav-link" data-scroll-target="#only-non-linearities">Only Non Linearities</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/anubhavmaity/NeuralNetworks-Zero-To-Hero/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Building makemore - Activations &amp; Gradients, BatchNorm</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="imports" class="level2">
<h2 class="anchored" data-anchor-id="imports">Imports</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#!pip install tqdm</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm, tqdm_notebook</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plot</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>words <span class="op">=</span> <span class="bu">open</span>(<span class="st">'../data/names.txt'</span>, <span class="st">'r'</span>).read().splitlines()</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>words[:<span class="dv">8</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(<span class="st">''</span>.join(words))))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>stoi <span class="op">=</span> {s: i<span class="op">+</span><span class="dv">1</span> <span class="cf">for</span> i, s <span class="kw">in</span> <span class="bu">enumerate</span>(chars)}</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>stoi[<span class="st">'.'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>itos <span class="op">=</span> {i:s <span class="cf">for</span> s, i <span class="kw">in</span> stoi.items()}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(words)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>32033</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_training_set(words, block_size, print_disabled<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    chars <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">set</span>(<span class="st">''</span>.join(words))))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    stoi <span class="op">=</span> {s: i<span class="op">+</span><span class="dv">1</span> <span class="cf">for</span> i, s <span class="kw">in</span> <span class="bu">enumerate</span>(chars)}</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    stoi[<span class="st">'.'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    itos <span class="op">=</span> {i:s <span class="cf">for</span> s, i <span class="kw">in</span> stoi.items()}</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> [], []</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> w <span class="kw">in</span> words:</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> print_disabled: <span class="bu">print</span>(w)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> block_size</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ch <span class="kw">in</span> w <span class="op">+</span> <span class="st">'.'</span>:</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>            ix <span class="op">=</span> stoi[ch]</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>            X.append(context)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            Y.append(ix)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> print_disabled: <span class="bu">print</span>(<span class="st">''</span>.join(itos[i] <span class="cf">for</span> i <span class="kw">in</span> context), <span class="st">'---&gt;'</span>, itos[ix])</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>            context <span class="op">=</span> context[<span class="dv">1</span>:] <span class="op">+</span> [ix] <span class="co"># crop and append</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> torch.tensor(X)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> torch.tensor(Y)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, Y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> generate_training_set(words, <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>X.shape, Y.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(torch.Size([228146, 3]), torch.Size([228146]))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_train_valid_test_split(words, block_size<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    random.seed(<span class="dv">42</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    random.shuffle(words)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    n1 <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span><span class="op">*</span><span class="bu">len</span>(words))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    n2 <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.9</span><span class="op">*</span><span class="bu">len</span>(words))</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    Xtr, Ytr <span class="op">=</span> generate_training_set(words[:n1], block_size)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    Xdev, Ydev <span class="op">=</span> generate_training_set(words[n1:n2], block_size)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    Xte, Yte <span class="op">=</span> generate_training_set(words[n2:], block_size)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Xtr, Ytr, Xdev, Ydev, Xte, Yte</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>Xtr, Ytr, Xdev, Ydev, Xte, Yte <span class="op">=</span> generate_train_valid_test_split(words, block_size<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>Xtr.shape, Ytr.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(torch.Size([182625, 3]), torch.Size([182625]))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>Xdev.shape, Ydev.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(torch.Size([22655, 3]), torch.Size([22655]))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>Xte.shape, Yte.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(torch.Size([22866, 3]), torch.Size([22866]))</code></pre>
</div>
</div>
</section>
<section id="train" class="level2">
<h2 class="anchored" data-anchor-id="train">Train</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_logits(parameters, X):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    C, W1, b1, W2, b2 <span class="op">=</span> parameters</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> C[X]</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> torch.tanh(emb.view(<span class="op">-</span><span class="dv">1</span>, W1.shape[<span class="dv">0</span>]) <span class="op">@</span> W1 <span class="op">+</span> b1)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> h <span class="op">@</span> W2 <span class="op">+</span> b2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _regularization_loss(parameters, lambdas):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">sum</span>(l <span class="op">*</span> (p<span class="op">**</span><span class="dv">2</span>).mean() <span class="cf">for</span> p, l <span class="kw">in</span> <span class="bu">zip</span>(parameters, lambdas))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initilialize_parameters(block_size, embedding_size, hidden_neuron):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((<span class="dv">27</span>, embedding_size), generator<span class="op">=</span>g)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> torch.randn((block_size <span class="op">*</span> embedding_size, hidden_neuron), generator<span class="op">=</span>g)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> torch.randn(hidden_neuron, generator<span class="op">=</span>g)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> torch.randn((hidden_neuron, <span class="dv">27</span>), generator<span class="op">=</span>g)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> torch.randn(<span class="dv">27</span>, generator<span class="op">=</span>g)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [C, W1, b1, W2, b2]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(parameters,</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>          epochs,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>          X, </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>          Y, </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>          bs<span class="op">=</span><span class="dv">32</span>, </span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>          lambdas <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>          enable_print<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>          print_at_every_nth_epoch<span class="op">=</span><span class="dv">10000</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>         ):</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> parameters:</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">Exception</span>(<span class="st">"No initial parameters passed"</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> parameters: p.requires_grad <span class="op">=</span> <span class="va">True</span> </span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    losses <span class="op">=</span> []</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>        lr <span class="op">=</span> <span class="fl">0.1</span> <span class="cf">if</span> epoch <span class="op">&lt;</span> <span class="dv">100_000</span> <span class="cf">else</span> <span class="fl">0.01</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.randint(<span class="dv">0</span>, X.shape[<span class="dv">0</span>], (bs, ))</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>        batch_x, batch_y <span class="op">=</span> X[ix], Y[ix]</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> compute_logits(parameters, batch_x)</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> F.cross_entropy(logits, batch_y)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        regularization_loss <span class="op">=</span> _regularization_loss(parameters, lambdas)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> regularization_loss</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>            p.grad<span class="op">=</span> <span class="va">None</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>            p.data <span class="op">+=</span> <span class="op">-</span> lr <span class="op">*</span> p.grad</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> enable_print <span class="kw">and</span> epoch <span class="op">%</span> print_at_every_nth_epoch <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(epoch, loss.item())</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>        losses.append(loss.item())</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> enable_print:  <span class="bu">print</span>(epoch, loss.item())   </span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> losses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>params1 <span class="op">=</span> initilialize_parameters(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params1, <span class="dv">200_000</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|                                                                                                                                                                  | 50/200000 [00:00&lt;14:51, 224.22it/s]  5%|████████                                                                                                                                                       | 10086/200000 [00:16&lt;05:14, 602.91it/s] 10%|███████████████▉                                                                                                                                               | 19993/200000 [00:36&lt;06:22, 470.09it/s] 15%|███████████████████████▉                                                                                                                                       | 30086/200000 [00:56&lt;05:16, 536.84it/s] 20%|███████████████████████████████▉                                                                                                                               | 40107/200000 [01:15&lt;04:28, 595.70it/s] 25%|███████████████████████████████████████▊                                                                                                                       | 50117/200000 [01:34&lt;04:09, 601.27it/s] 30%|███████████████████████████████████████████████▊                                                                                                               | 60073/200000 [01:50&lt;03:55, 593.51it/s] 35%|███████████████████████████████████████████████████████▋                                                                                                       | 70114/200000 [02:08&lt;03:43, 581.43it/s] 40%|███████████████████████████████████████████████████████████████▋                                                                                               | 80089/200000 [02:26&lt;03:26, 579.70it/s] 45%|███████████████████████████████████████████████████████████████████████▋                                                                                       | 90115/200000 [02:43&lt;03:00, 607.76it/s] 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 100092/200000 [03:00&lt;02:46, 598.58it/s] 55%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 110109/200000 [03:16&lt;02:30, 599.05it/s] 60%|██████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 120106/200000 [03:33&lt;02:08, 619.76it/s] 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 130061/200000 [03:53&lt;04:29, 259.66it/s] 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 140117/200000 [04:14&lt;01:39, 600.35it/s] 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 150090/200000 [04:30&lt;01:20, 620.44it/s] 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 160095/200000 [04:47&lt;01:02, 639.88it/s] 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 170112/200000 [05:02&lt;00:46, 637.91it/s] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 180125/200000 [05:18&lt;00:31, 634.12it/s] 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 190104/200000 [05:34&lt;00:15, 644.02it/s]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [05:50&lt;00:00, 571.05it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 27.642881393432617
10000 2.6563515663146973
20000 2.4569218158721924
30000 2.4299867153167725
40000 2.2356979846954346
50000 2.222148895263672
60000 1.997029423713684
70000 2.013292074203491
80000 2.4996888637542725
90000 2.8243627548217773
100000 2.815431833267212
110000 2.333662509918213
120000 2.5455234050750732
130000 2.3017194271087646
140000 2.1503050327301025
150000 1.8232505321502686
160000 2.411186456680298
170000 2.52275013923645
180000 2.173576593399048
190000 2.165059804916382
199999 2.3922524452209473</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>plot.plot(losses)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="evaluate-loss" class="level2">
<h2 class="anchored" data-anchor-id="evaluate-loss">Evaluate Loss</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#torch.no_grad()</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_loss(parameters, X, Y):</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> compute_logits(parameters, X)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> F.cross_entropy(logits, Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loss_split(parameters, dataset<span class="op">=</span><span class="st">'train'</span>):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    dataset_choices <span class="op">=</span> {</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train'</span>: (Xtr, Ytr),</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'valid'</span>: (Xdev, Ydev),</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'test'</span>: (Xte, Yte)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> evaluate_loss(parameters, <span class="op">*</span>dataset_choices[dataset])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>loss_split(params1), loss_split(params1, <span class="st">'valid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(2.1137, grad_fn=&lt;NllLossBackward0&gt;),
 tensor(2.1547, grad_fn=&lt;NllLossBackward0&gt;))</code></pre>
</div>
</div>
</section>
<section id="sampling" class="level2">
<h2 class="anchored" data-anchor-id="sampling">Sampling</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_words(parameters, count, block_size<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(count):</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> []</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>        context <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> block_size <span class="co"># initialize with all ...</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> compute_logits(parameters, torch.tensor([context]))</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> F.softmax(logits, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>            ix <span class="op">=</span> torch.multinomial(probs, num_samples<span class="op">=</span><span class="dv">1</span>, generator<span class="op">=</span>g).item()</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>            context <span class="op">=</span> context[<span class="dv">1</span>:] <span class="op">+</span> [ix]</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>            out.append(ix)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> ix <span class="op">==</span> <span class="dv">0</span>: <span class="cf">break</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">''</span>.join(itos[i] <span class="cf">for</span> i <span class="kw">in</span> out))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>generate_words(params1, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>jacklyny.
nita.
sano.
maketissariydah.
jama.
coanley.
zemyni.
khreen.
sis.
cin.</code></pre>
</div>
</div>
</section>
<section id="fixing-the-initial-loss" class="level2">
<h2 class="anchored" data-anchor-id="fixing-the-initial-loss">Fixing the initial loss</h2>
<p>In the above training, at the 1st epoch the loss is 33.7 then it drops to 2.23</p>
<p>if all the probabilities are uniform then we will expect a loss of</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span> torch.tensor(<span class="dv">1</span><span class="op">/</span><span class="fl">27.0</span>).log()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor(3.2958)</code></pre>
</div>
</div>
<section id="sample-issue" class="level3">
<h3 class="anchored" data-anchor-id="sample-issue">Sample issue</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>probs[<span class="dv">2</span>].log()</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>probs, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([0.2500, 0.2500, 0.2500, 0.2500]), tensor(1.3863))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">5.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>probs[<span class="dv">2</span>].log()</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>probs, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([0.0066, 0.0066, 0.9802, 0.0066]), tensor(0.0200))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>, <span class="fl">5.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>probs[<span class="dv">2</span>].log()</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>probs, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([0.0066, 0.9802, 0.0066, 0.0066]), tensor(5.0200))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.randn(<span class="dv">4</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>probs[<span class="dv">2</span>].log()</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>probs, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([0.0808, 0.5283, 0.2293, 0.1616]), tensor(1.4727))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.randn(<span class="dv">4</span>) <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>probs[<span class="dv">2</span>].log()</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>probs, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([1.8579e-01, 8.1123e-01, 1.6882e-04, 2.8133e-03]), tensor(8.6867))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.rand(<span class="dv">4</span>) </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>probs[<span class="dv">2</span>].log()</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>probs, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([0.3815, 0.2294, 0.2123, 0.1768]), tensor(1.5497))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">1.0</span>, <span class="fl">1.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>probs <span class="op">=</span> torch.softmax(logits, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>probs[<span class="dv">2</span>].log()</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>probs, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([0.2500, 0.2500, 0.2500, 0.2500]), tensor(1.3863))</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>params2 <span class="op">=</span> initilialize_parameters(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params2, <span class="dv">1</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 357.51it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 28.708385467529297
0 28.708385467529297</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>compute_logits(params2, Xtr)[<span class="dv">0</span>] <span class="co"># the logits are not uniform</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([  9.6100,   0.7546,  -4.9247,  -7.5269, -27.5197,  -7.1780,  -9.5191,
         -6.9432, -11.4050,  15.3572,   3.7384,  24.8570,   5.2003,  -9.1091,
          8.3202,   2.2977,  13.8022,   8.5462, -10.4909,  15.6155,  10.7404,
        -10.5370,   4.4306,  22.4479,  21.0907,  13.4340,   5.8010],
       grad_fn=&lt;SelectBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initilialize_parameters_v2(block_size, embedding_size, hidden_neuron):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((<span class="dv">27</span>, embedding_size), generator<span class="op">=</span>g)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> torch.randn((block_size <span class="op">*</span> embedding_size, hidden_neuron), generator<span class="op">=</span>g)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> torch.randn(hidden_neuron, generator<span class="op">=</span>g)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> torch.randn((hidden_neuron, <span class="dv">27</span>), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> torch.randn(<span class="dv">27</span>, generator<span class="op">=</span>g) <span class="op">*</span> <span class="dv">0</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [C, W1, b1, W2, b2]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>params3 <span class="op">=</span> initilialize_parameters_v2(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params3, <span class="dv">1</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 66.04it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.2968194484710693
0 3.2968194484710693</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>compute_logits(params3, Xtr)[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([-0.1350,  0.2579, -0.1748,  0.3775, -0.1732, -0.2264, -0.0493, -0.3319,
         0.0467, -0.0121, -0.0923, -0.3330, -0.0462,  0.5159,  0.3215,  0.0554,
        -0.0875, -0.2089, -0.1959,  0.1785,  0.1165, -0.2548, -0.2711, -0.1847,
        -0.3341,  0.3078, -0.2509], grad_fn=&lt;SelectBackward0&gt;)</code></pre>
</div>
</div>
<p>The logits are closer to zero now</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>params4 <span class="op">=</span> initilialize_parameters_v2(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params4, <span class="dv">200_000</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|                                                                                                                                                                  | 23/200000 [00:00&lt;14:34, 228.75it/s]  5%|████████                                                                                                                                                       | 10114/200000 [00:18&lt;05:16, 599.28it/s] 10%|███████████████▉                                                                                                                                               | 20079/200000 [00:37&lt;05:10, 579.29it/s] 15%|███████████████████████▉                                                                                                                                       | 30114/200000 [00:55&lt;04:55, 575.28it/s] 20%|███████████████████████████████▉                                                                                                                               | 40108/200000 [01:13&lt;04:50, 550.33it/s] 25%|███████████████████████████████████████▊                                                                                                                       | 50088/200000 [01:30&lt;04:06, 607.78it/s] 30%|███████████████████████████████████████████████▊                                                                                                               | 60080/200000 [01:47&lt;03:51, 604.43it/s] 35%|███████████████████████████████████████████████████████▋                                                                                                       | 70121/200000 [02:03&lt;03:34, 604.67it/s] 40%|███████████████████████████████████████████████████████████████▋                                                                                               | 80125/200000 [02:19&lt;03:10, 629.99it/s] 45%|███████████████████████████████████████████████████████████████████████▌                                                                                       | 90074/200000 [02:36&lt;03:05, 591.36it/s] 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 100078/200000 [02:52&lt;02:44, 608.54it/s] 55%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 110082/200000 [03:08&lt;02:24, 624.28it/s] 60%|██████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 120123/200000 [03:25&lt;02:08, 622.65it/s] 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 130079/200000 [03:42&lt;02:21, 495.27it/s] 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 140100/200000 [03:58&lt;01:34, 632.41it/s] 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 150100/200000 [04:15&lt;01:24, 593.63it/s] 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 160112/200000 [04:32&lt;01:12, 552.32it/s] 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 170099/200000 [04:49&lt;00:50, 588.99it/s] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 180120/200000 [05:05&lt;00:32, 618.06it/s] 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 190054/200000 [05:22&lt;00:17, 554.68it/s]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [05:39&lt;00:00, 589.22it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.3012616634368896
10000 2.0390188694000244
20000 2.519038200378418
30000 1.9892827272415161
40000 1.973912239074707
50000 2.0713963508605957
60000 1.9657005071640015
70000 2.3061559200286865
80000 1.693084478378296
90000 2.190971851348877
100000 2.581700563430786
110000 1.8936327695846558
120000 2.3227176666259766
130000 1.8893438577651978
140000 2.0941903591156006
150000 2.1335291862487793
160000 2.551553964614868
170000 1.945476770401001
180000 2.069230318069458
190000 1.791576862335205
199999 2.231049060821533</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>loss_split(params4, <span class="st">'train'</span>), loss_split(params4, <span class="st">'valid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(2.0690, grad_fn=&lt;NllLossBackward0&gt;),
 tensor(2.1281, grad_fn=&lt;NllLossBackward0&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="fix-the-saturated-tanh" class="level2">
<h2 class="anchored" data-anchor-id="fix-the-saturated-tanh">Fix the saturated tanh</h2>
<section id="plot-tanh" class="level3">
<h3 class="anchored" data-anchor-id="plot-tanh">Plot <code>tanh</code></h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>plot.plot(x, torch.tanh(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-47-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="visualize-h" class="level3">
<h3 class="anchored" data-anchor-id="visualize-h">Visualize h</h3>
<blockquote class="blockquote">
<p>h is the output of tanh in the above neural network</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_h(parameters, X):</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>    C, W1, b1, W2, b2 <span class="op">=</span> parameters</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> C[X]</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.tanh(emb.view(<span class="op">-</span><span class="dv">1</span>, W1.shape[<span class="dv">0</span>]) <span class="op">@</span> W1 <span class="op">+</span> b1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>batch_x <span class="op">=</span> Xtr[torch.randint(<span class="dv">0</span>, Xtr.shape[<span class="dv">0</span>], (<span class="dv">32</span>, ))]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> compute_h(params4, batch_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>h</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([[ 1.0000, -1.0000,  0.2621,  ..., -0.9742,  0.9999, -1.0000],
        [ 1.0000, -1.0000,  0.9999,  ...,  0.2515,  0.1090, -0.8337],
        [ 1.0000, -1.0000,  0.6779,  ..., -0.8491, -0.9900,  0.9737],
        ...,
        [ 0.9999,  0.9009, -0.9950,  ..., -1.0000,  0.9464,  0.9997],
        [ 1.0000,  1.0000, -0.9781,  ...,  0.9608,  0.9965,  0.9994],
        [-0.9998,  0.8074, -0.9989,  ...,  1.0000,  0.9892,  0.9999]],
       grad_fn=&lt;TanhBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>h.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([32, 200])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>h.view(<span class="op">-</span><span class="dv">1</span>).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([6400])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>plot.hist(h.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-54-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As we can see most values are -1 and 1</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_pre_activation(parameters, X):</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    C, W1, b1, W2, b2 <span class="op">=</span> parameters</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> C[X]</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> emb.view(<span class="op">-</span><span class="dv">1</span>, W1.shape[<span class="dv">0</span>]) <span class="op">@</span> W1 <span class="op">+</span> b1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>h_pre_act <span class="op">=</span> compute_pre_activation(params4, batch_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>plot.hist(h_pre_act.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-57-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>plot.imshow(h.<span class="bu">abs</span>() <span class="op">&gt;</span> <span class="fl">0.99</span>, cmap<span class="op">=</span><span class="st">'gray'</span>, interpolation<span class="op">=</span><span class="st">'nearest'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;matplotlib.image.AxesImage&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-58-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The <code>white</code> portion are the ones satisfying <code>h.abs() &gt; 0.99</code> and <code>black</code> are the ones which are not satisfying the same</p>
<p>As we can see there are lots of whites, and the activations are lying mostly in the region of squashed</p>
<p>The gradient of tanh is <code>(1 - t**2) * out.grad</code> which will be 0 if tanh is +/-1, so there will be no gradients flowing through the network</p>
<p>If in the above image there is a single column of whites then that neuron will not learn anything for the batch of data</p>
<p>The <code>h_pre_act</code> is too off from zero therefore the activations are mostly -1 and 1. Lets change the parameters contributing to <code>h_pre_act</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initilialize_parameters_v3(block_size, embedding_size, hidden_neuron):</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((<span class="dv">27</span>, embedding_size), generator<span class="op">=</span>g)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> torch.randn((block_size <span class="op">*</span> embedding_size, hidden_neuron), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> torch.randn(hidden_neuron, generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> torch.randn((hidden_neuron, <span class="dv">27</span>), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> torch.randn(<span class="dv">27</span>, generator<span class="op">=</span>g) <span class="op">*</span> <span class="dv">0</span></span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [C, W1, b1, W2, b2]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>params5 <span class="op">=</span> initilialize_parameters_v3(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params5, <span class="dv">1</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 273.58it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.2925052642822266
0 3.2925052642822266</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>h1 <span class="op">=</span> compute_h(params5, batch_x)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>plot.hist(h1.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-62-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>h1_pre_act <span class="op">=</span> compute_pre_activation(params5, batch_x)</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>plot.hist(h1_pre_act.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-63-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>plot.imshow(h1.<span class="bu">abs</span>() <span class="op">&gt;</span> <span class="fl">0.99</span>, cmap<span class="op">=</span><span class="st">'gray'</span>, interpolation<span class="op">=</span><span class="st">'nearest'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;matplotlib.image.AxesImage&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-64-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>No neurons saturated over 0.99 in either direction</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initilialize_parameters_v4(block_size, embedding_size, hidden_neuron):</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((<span class="dv">27</span>, embedding_size), generator<span class="op">=</span>g)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> torch.randn((block_size <span class="op">*</span> embedding_size, hidden_neuron), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.2</span></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> torch.randn(hidden_neuron, generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> torch.randn((hidden_neuron, <span class="dv">27</span>), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> torch.randn(<span class="dv">27</span>, generator<span class="op">=</span>g) <span class="op">*</span> <span class="dv">0</span></span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [C, W1, b1, W2, b2]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>params6 <span class="op">=</span> initilialize_parameters_v4(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params6, <span class="dv">1</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 387.46it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.315361976623535
0 3.315361976623535</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>h2 <span class="op">=</span> compute_h(params6, batch_x)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>plot.hist(h2.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-68-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>h2_pre_act <span class="op">=</span> compute_pre_activation(params6, batch_x)</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>plot.hist(h2_pre_act.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-69-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>))</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>plot.imshow(h2.<span class="bu">abs</span>() <span class="op">&gt;</span> <span class="fl">0.99</span>, cmap<span class="op">=</span><span class="st">'gray'</span>, interpolation<span class="op">=</span><span class="st">'nearest'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;matplotlib.image.AxesImage&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-70-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params6, <span class="dv">200_000</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|                                                                                                                                                                 | 114/200000 [00:00&lt;05:52, 566.51it/s]  5%|████████                                                                                                                                                       | 10086/200000 [00:18&lt;05:32, 571.40it/s] 10%|███████████████▉                                                                                                                                               | 20103/200000 [00:37&lt;05:18, 564.13it/s] 15%|███████████████████████▉                                                                                                                                       | 30062/200000 [01:00&lt;07:17, 388.41it/s] 20%|███████████████████████████████▉                                                                                                                               | 40130/200000 [01:20&lt;04:18, 618.81it/s] 25%|███████████████████████████████████████▊                                                                                                                       | 50087/200000 [01:37&lt;04:15, 587.11it/s] 30%|███████████████████████████████████████████████▊                                                                                                               | 60082/200000 [01:54&lt;04:00, 582.39it/s] 35%|███████████████████████████████████████████████████████▋                                                                                                       | 70069/200000 [02:14&lt;05:20, 405.03it/s] 40%|███████████████████████████████████████████████████████████████▋                                                                                               | 80094/200000 [02:38&lt;03:43, 535.66it/s] 45%|███████████████████████████████████████████████████████████████████████▌                                                                                       | 90067/200000 [03:00&lt;03:50, 477.81it/s] 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 100049/200000 [03:26&lt;03:11, 520.97it/s] 55%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 110095/200000 [03:54&lt;03:16, 457.70it/s] 60%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 120021/200000 [04:21&lt;02:43, 487.95it/s] 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 130064/200000 [04:40&lt;02:11, 531.51it/s] 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 140109/200000 [05:01&lt;01:48, 549.81it/s] 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 150027/200000 [05:22&lt;01:33, 531.64it/s] 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 160100/200000 [05:45&lt;01:09, 573.43it/s] 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 170099/200000 [06:03&lt;00:53, 562.53it/s] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 180121/200000 [06:22&lt;00:30, 652.22it/s] 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 190125/200000 [06:38&lt;00:14, 664.52it/s]100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [16:38:01&lt;00:00,  3.34it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.252462863922119
10000 2.2485759258270264
20000 1.924424648284912
30000 2.3567395210266113
40000 1.7223490476608276
50000 1.9401909112930298
60000 2.2472681999206543
70000 2.110548973083496
80000 1.9843206405639648
90000 2.498479127883911
100000 2.0100741386413574
110000 1.9128767251968384
120000 2.1294615268707275
130000 1.7961547374725342
140000 1.6151217222213745
150000 1.905795693397522
160000 2.0080981254577637
170000 2.0118043422698975
180000 1.73159921169281
190000 2.196617841720581
199999 2.2335524559020996</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>loss_split(params6, <span class="st">'train'</span>), loss_split(params6, <span class="st">'valid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(2.0385, grad_fn=&lt;NllLossBackward0&gt;),
 tensor(2.1043, grad_fn=&lt;NllLossBackward0&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="calculating-the-init-scale-kaiming-init" class="level2">
<h2 class="anchored" data-anchor-id="calculating-the-init-scale-kaiming-init">Calculating the init scale: “Kaiming init”</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1000</span>, <span class="dv">10</span>)</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">10</span>, <span class="dv">200</span>)</span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">@</span> w</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.mean(), x.std())</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y.mean(), y.std())</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">121</span>)</span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a>plot.hist(x.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span>
<span id="cb112-9"><a href="#cb112-9" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">122</span>)</span>
<span id="cb112-10"><a href="#cb112-10" aria-hidden="true" tabindex="-1"></a>plot.hist(y.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(-0.0029) tensor(0.9987)
tensor(-0.0028) tensor(3.1829)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-73-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The <code>y</code> has more standard deviation compared to <code>x</code></p>
<p>The guassian is expanding, we dont want that, we need similar activations during initialization</p>
<p>If we multiply <code>w</code> by a large number i.e.&nbsp;5, then the standard deviation increases</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1000</span>, <span class="dv">10</span>)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">10</span>, <span class="dv">200</span>) <span class="op">*</span> <span class="dv">5</span></span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">@</span> w</span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.mean(), x.std())</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y.mean(), y.std())</span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a>plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">121</span>)</span>
<span id="cb114-8"><a href="#cb114-8" aria-hidden="true" tabindex="-1"></a>plot.hist(x.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span>
<span id="cb114-9"><a href="#cb114-9" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">122</span>)</span>
<span id="cb114-10"><a href="#cb114-10" aria-hidden="true" tabindex="-1"></a>plot.hist(y.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(-0.0073) tensor(0.9939)
tensor(0.0191) tensor(15.9527)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-74-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>if we multiply <code>w</code> by a small number, then the standard deviation will be smaller</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1000</span>, <span class="dv">10</span>)</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">10</span>, <span class="dv">200</span>) <span class="op">*</span> <span class="fl">0.2</span></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">@</span> w</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.mean(), x.std())</span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y.mean(), y.std())</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">121</span>)</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>plot.hist(x.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">122</span>)</span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a>plot.hist(y.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(-0.0038) tensor(0.9879)
tensor(-0.0003) tensor(0.6244)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-75-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>What number should we multiply <code>w</code> by to preserve the standard deviation as 1?</p>
<blockquote class="blockquote">
<p>We can multiply by (1/sqrt(fan_in))</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">1000</span>, <span class="dv">10</span>)</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">10</span>, <span class="dv">200</span>) <span class="op">*</span> <span class="dv">1</span><span class="op">/</span>(math.sqrt(<span class="dv">10</span>))</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">@</span> w</span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.mean(), x.std())</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y.mean(), y.std())</span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a>plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">121</span>)</span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a>plot.hist(x.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a>plot.subplot(<span class="dv">122</span>)</span>
<span id="cb118-10"><a href="#cb118-10" aria-hidden="true" tabindex="-1"></a>plot.hist(y.view(<span class="op">-</span><span class="dv">1</span>).tolist(), <span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(0.0040) tensor(0.9988)
tensor(-0.0010) tensor(0.9846)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-76-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>torch.randn(<span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([-4.4491e-01,  8.1468e-01, -4.9041e-01,  8.5084e-01, -7.5546e-01,
        -1.2834e+00, -1.4080e-01, -1.5628e-01,  7.0759e-01,  5.4389e-01,
         1.0249e+00, -3.6809e-01,  1.5767e-01, -1.2903e-01, -9.6614e-01,
        -5.1882e-01, -1.0040e+00, -9.6146e-01, -4.9114e-02, -1.0125e+00,
         1.0659e+00,  1.3129e+00,  5.9042e-01, -1.3400e-01, -4.0615e-01,
         7.1402e-01,  8.5876e-01,  1.1057e+00, -1.7399e-01, -2.5380e-01,
        -1.9785e-01, -2.2213e+00,  3.8632e-02, -1.4455e+00,  1.4416e+00,
         4.6785e-02,  1.0486e+00,  1.7613e-02,  5.2755e-01, -1.3378e+00,
         7.3152e-01,  1.5148e+00, -9.0945e-01,  9.5265e-01,  1.7500e+00,
        -1.5277e+00, -5.6958e-02, -9.2872e-01, -5.7160e-01, -1.3054e+00,
         2.9642e-01, -9.0971e-01,  1.4852e-01,  4.8295e-01,  2.0170e-02,
        -1.5728e-01,  6.1446e-01, -7.2750e-01,  2.7242e-01, -5.0731e-01,
        -1.6935e+00, -1.1223e+00,  4.0411e-01,  7.8083e-01,  8.9397e-01,
         1.1677e+00, -1.6698e+00, -1.1389e-01, -1.3376e+00, -3.3989e-01,
         4.6134e-01,  1.3889e+00, -2.0328e-01, -8.0168e-01, -1.3011e+00,
         1.7799e-01,  9.1866e-01,  7.4976e-01, -1.7144e+00,  7.3718e-01,
        -3.3846e-01,  1.7048e-01, -1.6116e-01,  5.1980e-01, -3.2220e-01,
         9.6030e-01,  3.0398e-01, -7.1770e-01,  5.1479e-01,  8.8952e-02,
         1.5568e+00, -6.4372e-01, -1.4770e-01, -1.2715e+00,  1.1549e+00,
        -2.2085e+00, -8.0787e-01, -8.0596e-01,  1.1667e+00,  1.1490e+00,
         1.9939e-01,  3.5011e-01,  4.3978e-01,  1.0387e+00,  1.1948e+00,
         6.5371e-01, -1.1983e+00, -7.9712e-02,  9.4302e-01,  7.7875e-01,
        -3.7207e-01,  6.0207e-01,  1.4607e-01,  3.4527e-02, -8.4879e-01,
        -7.7520e-01, -2.9863e-01,  2.2895e-01, -1.8310e+00,  4.8203e-01,
        -1.5591e+00,  1.1811e+00, -6.0453e-01, -3.9585e-01, -1.0402e+00,
         1.1609e+00, -1.3437e+00,  1.3366e+00,  2.7067e+00,  6.6262e-01,
         1.1726e-01, -1.4091e+00,  8.6855e-01, -3.2722e-01, -1.0854e+00,
        -1.7248e-01,  4.2303e-01, -1.0056e-01,  6.7321e-01, -2.1935e-01,
        -1.3298e-01,  3.1146e-01, -3.2207e-01, -8.5663e-01,  1.0111e+00,
        -3.8868e-01,  1.1240e+00,  1.3679e-01, -1.2754e+00,  1.6846e+00,
         1.8569e-01, -1.4316e+00, -5.2817e-01,  4.4829e-01,  1.1192e+00,
        -1.0870e+00,  1.2514e+00,  2.4123e-01,  4.1799e-01,  1.3938e+00,
        -6.4690e-01, -3.2768e-01, -1.0039e+00,  1.0455e+00, -1.1427e+00,
        -3.5521e-01,  3.8842e-01, -1.3270e+00,  1.1490e+00, -1.4166e+00,
        -1.7509e+00, -2.6920e-02, -2.8950e-01,  7.1716e-01, -1.0339e+00,
        -1.4395e-01, -7.5489e-01, -3.2210e-02,  1.3414e+00, -4.4632e-01,
         1.0532e+00, -1.1267e+00,  1.1626e+00, -1.0597e+00,  4.8057e-01,
         1.2193e+00,  9.7095e-01, -4.6855e-01,  9.6808e-01, -7.2747e-01,
        -1.0172e+00, -1.5430e-01, -3.7111e-01,  1.1363e+00,  1.1665e+00,
        -5.7238e-01, -7.2625e-01,  1.1168e+00, -1.9561e+00,  3.6347e-01,
         1.2211e+00, -1.0392e+00,  9.1227e-01, -5.3476e-01,  7.7828e-01,
        -1.8234e-01,  1.2498e+00, -7.6176e-02, -1.4105e-01, -2.7955e-01,
        -7.7375e-01, -2.3475e+00, -7.9845e-01,  8.9417e-01, -4.1188e-01,
         1.1319e+00,  1.2606e-01, -2.1836e+00,  7.5730e-01, -6.8296e-01,
        -1.0518e+00,  1.2614e+00,  3.5788e-01,  3.6420e-01, -3.9252e-01,
        -7.4942e-01, -1.8380e+00,  1.3533e+00, -2.8998e-02, -2.3180e+00,
        -1.9691e-01, -1.2409e+00, -9.2009e-01, -1.9675e-01, -9.7025e-01,
        -1.3910e+00, -6.6132e-01, -1.7533e+00, -1.0233e+00, -2.0021e+00,
        -2.3171e+00, -7.7370e-01, -1.2550e+00,  1.2218e+00,  1.7372e-01,
         8.3574e-01,  1.6951e-01,  1.0796e-01,  1.2036e+00, -1.1552e+00,
         1.7398e-01,  3.1005e-01, -7.4864e-01,  9.1199e-01, -8.1297e-01,
        -1.3774e+00, -4.1376e-02,  1.5385e+00,  1.5433e-01,  7.6850e-01,
        -4.5575e-01, -3.3947e-01,  1.5767e+00, -1.6138e+00,  1.3509e+00,
         7.7009e-01, -1.6286e+00,  1.4196e+00,  8.5499e-01, -6.5572e-01,
         1.0467e+00,  5.3764e-01,  5.4705e-01, -3.0934e-01,  1.4358e+00,
        -2.3142e+00, -2.5676e-01, -6.9334e-01,  6.7920e-01, -1.5806e-02,
         6.6129e-01, -1.1277e-01,  3.7076e-01, -2.0539e+00,  9.6729e-01,
        -1.1464e-01,  9.3331e-02,  7.1655e-01,  2.2155e-01, -2.1334e-01,
        -7.2953e-01, -1.0252e+00,  1.1660e+00,  4.8370e-01, -4.9408e-01,
         8.3829e-01, -8.5957e-01, -6.6706e-02, -6.7575e-01,  9.3957e-01,
         5.0669e-01, -2.3851e-01,  2.9753e-01,  5.4236e-01, -7.0215e-01,
         1.4101e+00,  1.6822e-01,  3.4431e+00,  1.3912e+00, -1.8377e+00,
         1.4642e+00,  5.8495e-01, -8.7159e-01,  1.9798e+00,  4.8268e-01,
         1.1796e+00,  1.8971e+00, -2.2471e-01,  1.4477e+00,  1.4796e+00,
         2.0498e+00,  6.0896e-01,  1.7562e+00, -1.5760e+00, -6.4049e-01,
         1.2525e+00, -1.5839e-01, -8.6765e-01, -6.2326e-01,  1.1278e-01,
        -9.8297e-01, -5.5136e-01,  1.4451e-01,  1.4907e+00, -9.7304e-01,
         1.1056e+00,  1.0133e+00,  6.1220e-01,  4.0848e-01, -6.6162e-01,
        -7.4903e-01,  2.9114e+00,  1.3749e+00, -2.3306e+00, -2.3087e-01,
        -1.1470e+00,  2.0197e+00, -9.6675e-01, -7.4702e-01, -1.0908e-01,
        -2.6147e-01, -3.2547e-01, -1.7522e-01, -2.4414e-01, -3.6424e-01,
        -1.3112e+00, -4.8352e-01, -1.5956e+00, -1.0321e-01,  3.1300e-01,
        -2.2417e-01,  6.4919e-01, -9.9813e-01,  1.9788e+00, -2.3398e+00,
         3.1999e-01,  1.1417e+00, -7.2538e-02,  7.5595e-01, -1.1833e+00,
        -1.0342e+00,  1.3779e+00,  4.6179e-01, -4.4127e-01, -1.5523e+00,
         2.4986e+00, -1.4134e+00,  8.8584e-01,  3.8325e-01,  3.0485e-01,
         1.8157e+00, -7.2691e-01, -4.9207e-01,  8.3230e-01,  1.0072e+00,
        -8.1437e-01, -1.3365e-01,  3.8920e-01, -1.0508e-01, -1.1311e+00,
        -8.0398e-01,  3.3417e-01,  3.9109e-01, -9.8168e-01, -1.1504e+00,
         9.3065e-01, -2.1849e-01, -2.7455e-03,  1.5553e+00, -1.5637e-01,
         1.1848e-01, -9.1837e-01, -1.1483e-01, -5.6455e-01, -6.8401e-02,
         5.4284e-01,  6.9041e-01,  1.5359e+00,  6.5503e-02,  1.2606e+00,
        -2.3238e-01,  5.0018e-01,  4.0842e-01,  1.2282e-01, -8.3332e-01,
        -5.2143e-01,  1.0709e-01,  5.5946e-01, -1.7920e+00,  9.8011e-02,
         2.3607e-01,  9.1122e-01, -1.7815e+00, -2.2378e+00,  6.0846e-01,
        -1.0682e+00,  6.7406e-01,  1.1799e+00, -2.7380e-02,  1.1086e+00,
         1.2985e-01, -1.5836e+00,  9.9837e-01, -8.8163e-01,  4.2766e-01,
        -7.5449e-01, -9.1209e-01,  8.2167e-01, -1.3376e+00, -5.5470e-01,
        -2.5744e+00,  2.3497e+00,  9.1383e-01, -8.6754e-01,  2.6851e-02,
        -5.6935e-01,  1.7634e+00, -5.4466e-01,  6.4427e-01, -2.8968e+00,
         1.0398e+00, -1.7710e+00,  2.6833e-01,  9.7795e-01, -5.1294e-01,
        -4.4039e-01,  8.8880e-01, -1.5962e+00,  2.2802e-01,  9.9065e-01,
        -3.9762e-01, -8.1780e-01,  2.2655e+00, -1.6902e+00, -1.0324e-01,
         1.4844e+00,  5.5991e-01, -1.9720e+00,  2.3696e+00,  1.4115e-01,
        -1.0652e+00, -9.0866e-01,  1.1514e+00,  1.6936e+00,  4.7878e-01,
        -2.9971e-01,  5.4005e-01,  7.3565e-01, -4.4122e-01, -6.8278e-01,
         5.9391e-01, -7.5252e-01, -6.0103e-01, -4.1738e-01, -6.0496e-01,
        -1.9164e+00,  3.4902e-01,  6.5277e-02, -1.8154e-01,  9.1510e-01,
        -9.1029e-02, -2.4382e-01,  2.3432e+00,  1.9859e+00, -7.8514e-01,
         1.2721e-01,  1.4515e+00, -1.2700e-01, -1.6711e-01,  6.6730e-01,
        -1.6903e-01,  1.0743e-01, -1.1094e+00, -1.0274e+00,  3.7128e-01,
        -2.3233e-01, -3.0973e-01,  1.8141e+00,  1.9199e-01, -1.8364e+00,
        -2.1589e-01, -7.8127e-02, -3.4849e-01, -2.1622e+00,  4.0660e-01,
        -9.5050e-01, -9.0194e-01, -5.4401e-01,  1.9922e+00,  5.5333e-01,
         2.2488e-01, -4.8751e-01,  7.1682e-01,  3.6225e-01,  8.9288e-01,
        -8.5990e-01,  9.6229e-01,  9.5417e-01, -5.1965e-01, -2.3035e+00,
        -4.9344e-01, -1.7938e+00,  9.6043e-01,  3.4079e-01, -6.7608e-01,
         1.1257e+00, -2.9176e-01, -2.4500e-01,  2.1111e+00, -9.0706e-01,
         2.4174e+00,  1.8432e+00,  8.5921e-01,  3.7028e-02,  3.3475e-01,
        -1.2499e+00, -2.7984e-01, -9.5921e-02, -1.2070e+00, -5.6210e-01,
        -7.6785e-01, -1.0238e-01, -4.1785e-01, -1.0449e+00,  1.4974e+00,
        -9.2206e-01,  8.6997e-02, -7.2990e-01, -5.8177e-02,  1.2354e+00,
        -1.8226e-02, -1.2640e+00, -8.9501e-01, -1.2832e+00, -4.8085e-01,
         1.0304e+00, -2.2113e+00, -4.8045e-01, -5.8689e-01,  9.0754e-01,
         2.4374e-01, -5.2606e-01, -6.5553e-01, -3.4300e-01,  6.7370e-01,
         9.0023e-01,  1.2187e+00,  1.0026e+00, -5.2062e-01, -1.2393e+00,
        -7.0569e-01,  1.3346e+00, -1.0457e+00, -2.1257e-02, -4.9760e-01,
        -6.0507e-01,  1.4430e+00,  3.0979e-01, -1.2321e+00,  1.8128e-01,
         4.8367e-01,  5.6369e-01, -9.7980e-02,  1.4244e+00,  9.5563e-02,
         8.2211e-01,  1.2565e+00,  1.7145e+00,  1.8543e+00,  8.3598e-01,
        -1.5805e+00,  4.4981e-01,  4.9791e-01,  1.5932e+00, -7.8263e-01,
         1.1016e+00, -1.4328e+00, -1.3174e-01, -2.3278e-01,  1.2399e+00,
        -1.1156e-01, -1.0908e+00, -8.6325e-01, -1.2553e-02, -2.0168e-01,
         9.7023e-02,  6.2413e-01,  4.3617e-01, -7.6339e-01,  1.7359e+00,
        -8.8891e-02,  1.1993e+00,  1.2335e+00, -1.7588e-01, -1.1068e+00,
         1.5370e+00,  5.3286e-01, -1.7069e+00, -7.0883e-01,  6.0098e-01,
        -1.8722e+00,  1.0028e+00, -1.7522e+00,  1.9773e+00,  7.6629e-02,
         9.7794e-01,  9.1844e-01,  3.6816e-02,  7.0968e-01,  1.4424e+00,
        -8.8674e-01,  9.6100e-01,  4.4609e-01, -3.7348e-01,  2.1652e+00,
        -2.0705e-01,  2.8895e+00, -8.2157e-03,  1.0014e-01,  1.3509e+00,
        -9.2852e-01, -1.4189e+00, -3.4976e-01,  1.1974e-01, -6.0752e-01,
         1.2418e+00,  1.4813e+00, -2.9009e-01, -6.5577e-02, -3.7928e-01,
         4.0710e-01, -7.4858e-02,  5.8135e-01,  1.4308e+00,  4.6332e-01,
         1.5282e+00, -1.1648e+00, -1.3339e+00,  8.2611e-01, -8.9988e-02,
         1.2866e+00,  9.7417e-04, -1.0353e+00, -7.7178e-01,  1.5070e+00,
         1.3771e+00, -1.4094e+00,  4.6631e-02,  6.4983e-01,  4.4373e-01,
         4.3267e-01, -1.5054e-01, -7.0889e-01, -4.7002e-01, -1.2221e+00,
         1.1314e-01,  2.0500e-01,  5.8394e-01, -1.1366e-02,  1.1042e-02,
        -5.1476e-01, -1.6741e+00,  1.8323e+00, -3.9113e-01,  3.0786e-01,
         5.6348e-01, -2.2628e-01, -1.0945e+00, -2.5047e+00, -1.3732e-01,
        -9.4335e-01,  9.3365e-01, -1.3367e-01,  5.3266e-01, -7.3486e-01,
        -1.2251e+00,  1.5481e+00,  7.1739e-01,  1.1879e+00,  8.1519e-01,
         2.0114e-01, -1.6691e+00, -2.9070e-02, -1.6126e+00,  2.6002e-01,
         1.7315e+00, -3.7181e-01,  1.7891e+00,  2.6855e-02,  1.3394e+00,
        -1.2826e-01,  6.9187e-01,  5.2593e-01,  5.1028e-01, -2.9707e-01,
         1.0332e+00,  7.6733e-01,  2.4797e+00, -1.6167e-01,  6.6452e-02,
         9.0616e-01,  7.1738e-01,  7.1106e-01,  9.8761e-02, -1.0895e+00,
        -8.7591e-01,  8.7157e-01,  1.9313e+00, -6.2044e-01,  3.4145e-02,
        -3.4549e-01,  5.2566e-01, -6.1216e-01,  4.0845e-01,  1.2780e+00,
        -6.7273e-01, -1.6323e+00,  1.3512e+00,  7.9965e-02,  1.2352e-01,
        -2.9542e-01,  1.5546e+00, -2.2835e-01, -1.1723e+00, -8.9304e-01,
        -9.0590e-01, -3.3402e-01,  5.9588e-01,  1.6975e-01, -1.3846e+00,
         8.1981e-01,  2.4207e-02,  1.1152e-01,  2.1979e+00,  4.7347e-01,
        -3.6197e-02, -7.3026e-03, -6.8270e-01, -8.8449e-01,  3.6973e-01,
         7.1029e-01,  1.6141e-01,  3.9045e-01, -1.6220e-01, -1.0303e-02,
         2.9736e-01, -2.5634e-01, -7.6549e-01,  7.0336e-01,  4.5149e-01,
        -3.2849e-01, -1.6511e+00,  6.9789e-01,  1.1553e+00, -1.5515e+00,
         1.1479e+00,  7.9370e-01, -1.1824e+00, -8.7946e-01,  1.3841e+00,
        -1.8442e+00,  9.5913e-01, -1.0785e+00,  2.8138e-01,  1.4519e+00,
         1.6403e+00, -1.6989e+00, -1.7778e+00, -1.3598e+00, -6.3483e-01,
         5.2751e-01,  4.9287e-01,  5.0181e-01, -6.0085e-01,  6.2637e-01,
        -7.0738e-01,  4.8160e-01, -1.1089e-01,  7.4083e-01, -8.9509e-01,
         9.0353e-01, -4.0467e-01, -8.5919e-02,  2.6746e-01, -1.9548e+00,
         6.0947e-01,  8.7655e-01, -6.5896e-01, -6.1613e-01,  1.7297e+00,
         1.9492e-01, -1.8195e+00,  2.2503e-02, -1.9076e+00,  7.5093e-02,
         1.6529e+00,  3.4259e-01,  1.4164e+00,  1.5928e+00, -4.3144e-01,
        -9.2303e-01, -4.6064e-01, -4.6902e-01, -1.5084e+00,  8.9347e-01,
         1.1865e+00, -9.3348e-01,  8.6712e-01, -3.0535e-01, -7.8115e-01,
         1.8942e+00,  4.7689e-01,  6.3666e-01, -2.2987e-01,  2.2629e+00,
        -3.9918e-01, -1.7252e+00,  1.5192e+00, -2.2920e+00,  2.6366e-01,
        -6.8147e-02,  1.3599e-01,  1.3921e+00,  1.6916e-01,  1.2853e+00,
        -1.9718e+00, -5.3289e-01,  1.2188e+00, -2.4011e-01, -4.4860e-01,
        -5.3689e-01, -5.2381e-01,  1.0976e-01,  5.2891e-01, -9.0536e-01,
        -5.3731e-01, -5.0766e-01, -1.2572e+00, -1.3832e+00,  1.0783e+00,
        -5.6167e-01,  3.8724e-01,  1.8097e-01, -5.9655e-01, -9.2021e-01,
        -2.1552e+00,  1.3431e-01, -1.2162e+00, -1.5789e+00, -4.1252e-01,
        -1.0802e+00, -6.0434e-02, -3.3154e-01,  1.1832e+00,  7.1232e-01,
        -1.1653e+00, -2.1207e+00,  2.2294e-01, -4.0428e-01,  1.6746e+00,
        -9.8364e-01, -1.8898e+00,  4.7501e-02, -1.9037e-02,  6.3712e-01,
        -5.2208e-01,  1.1077e+00,  5.4200e-02,  4.3732e-01,  9.7521e-01,
         4.4448e-01,  8.5956e-01,  5.4088e-01, -7.5151e-01, -8.2385e-02,
         2.7066e+00, -4.0313e-01, -1.2705e+00, -1.8110e-03, -7.9295e-01,
        -4.0852e-01, -7.5687e-01,  1.1580e+00,  3.5440e-01,  8.5731e-01,
        -1.4712e+00,  1.6121e-01, -4.4616e-01,  2.1555e+00,  6.6903e-02,
        -1.2607e+00, -2.2889e-01, -2.4372e-02,  1.6145e+00,  1.6716e+00,
         4.4838e-01, -1.8342e-01,  7.2343e-01, -1.0761e+00,  2.1152e+00,
        -1.0926e+00,  7.0204e-01, -3.3275e-01,  2.6774e-02, -3.8973e-01,
        -1.2466e+00,  5.2782e-01, -5.4509e-01,  4.6797e-01,  9.5262e-01,
         3.0096e-02, -1.1982e+00, -6.1488e-01,  5.2910e-01, -4.2660e-01,
        -1.1221e+00, -3.5857e-01,  2.8266e-01, -6.7295e-01, -6.9349e-01,
         8.0775e-01,  5.0606e-01,  1.9053e+00,  1.2228e+00,  4.7014e-01,
         3.8042e-01, -5.3530e-01, -1.6741e-01,  1.2887e+00, -1.3320e+00,
         1.2936e+00,  1.0690e+00,  1.3661e+00,  6.7960e-01, -4.4733e-01,
         6.9975e-01,  1.8949e-01,  3.4809e-02, -1.2910e-01,  1.0193e+00,
        -1.7590e-01, -2.5930e-01,  3.2330e-01, -2.9028e-01, -5.4029e-01,
        -8.1340e-01, -1.1686e+00,  9.4940e-01, -6.8079e-02, -3.1358e-01,
        -2.6569e-01, -3.5748e-01,  1.4510e+00, -7.5871e-01,  9.6715e-01,
         3.7772e-01,  8.1767e-01, -1.7959e+00, -3.8471e-01, -1.3908e+00,
        -7.9921e-01, -1.6201e+00, -1.7005e-01,  9.1469e-01,  1.7542e+00,
        -1.3094e+00, -1.0830e+00, -2.7837e+00,  3.6276e-01,  3.3478e-01])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>(torch.randn(<span class="dv">1000</span>) <span class="op">*</span> <span class="fl">0.2</span>).std()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor(0.2046)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>std_dev <span class="op">=</span> (<span class="dv">5</span><span class="op">/</span><span class="dv">3</span>) <span class="op">/</span> (<span class="dv">30</span> <span class="op">**</span> <span class="fl">0.5</span>)<span class="op">;</span> std_dev</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>0.3042903097250923</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initilialize_parameters_v5(block_size, embedding_size, hidden_neuron):</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((<span class="dv">27</span>, embedding_size), generator<span class="op">=</span>g)</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> torch.randn((block_size <span class="op">*</span> embedding_size, hidden_neuron), generator<span class="op">=</span>g) <span class="op">*</span> ((<span class="dv">5</span><span class="op">/</span><span class="dv">3</span>) <span class="op">/</span> ((embedding_size <span class="op">*</span> block_size) <span class="op">**</span> <span class="fl">0.5</span>))</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> torch.randn(hidden_neuron, generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> torch.randn((hidden_neuron, <span class="dv">27</span>), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb126-6"><a href="#cb126-6" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> torch.randn(<span class="dv">27</span>, generator<span class="op">=</span>g) <span class="op">*</span> <span class="dv">0</span></span>
<span id="cb126-7"><a href="#cb126-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [C, W1, b1, W2, b2]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>params7 <span class="op">=</span> initilialize_parameters_v5(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train(params7, <span class="dv">200_000</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|                                                                                                                                                                 | 132/200000 [00:00&lt;05:09, 645.01it/s]  5%|████████                                                                                                                                                       | 10125/200000 [00:14&lt;04:19, 733.07it/s] 10%|███████████████▊                                                                                                                                             | 20084/200000 [1:00:00&lt;04:29, 668.33it/s] 15%|███████████████████████▋                                                                                                                                     | 30138/200000 [1:00:14&lt;04:01, 702.35it/s] 19%|██████████████████████████████▌                                                                                                                              | 38883/200000 [4:01:38&lt;04:25, 605.88it/s] 25%|███████████████████████████████████████▎                                                                                                                     | 50091/200000 [4:01:54&lt;03:29, 715.16it/s] 30%|███████████████████████████████████████████████▏                                                                                                             | 60084/200000 [4:02:09&lt;03:31, 661.46it/s] 35%|███████████████████████████████████████████████████████                                                                                                      | 70071/200000 [4:02:24&lt;03:19, 650.30it/s] 40%|██████████████████████████████████████████████████████████████▉                                                                                              | 80121/200000 [4:02:39&lt;02:59, 667.73it/s] 45%|██████████████████████████████████████████████████████████████████████▋                                                                                      | 90110/200000 [4:02:55&lt;02:37, 695.86it/s] 50%|██████████████████████████████████████████████████████████████████████████████                                                                              | 100130/200000 [4:03:10&lt;02:26, 680.25it/s] 55%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 110085/200000 [4:03:25&lt;02:17, 655.44it/s] 60%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                              | 120089/200000 [4:03:40&lt;02:04, 644.20it/s] 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 130067/200000 [4:03:55&lt;01:46, 655.76it/s] 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 140063/200000 [4:04:10&lt;01:29, 666.43it/s] 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                       | 150093/200000 [4:04:25&lt;01:19, 628.04it/s] 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                               | 160115/200000 [4:04:40&lt;00:53, 743.59it/s] 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 170077/200000 [4:04:54&lt;00:44, 677.63it/s] 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 180117/200000 [4:05:08&lt;00:26, 751.15it/s] 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 190117/200000 [4:05:23&lt;00:14, 702.81it/s]100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [4:05:37&lt;00:00, 13.57it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.2795920372009277
10000 2.470160484313965
20000 2.183413505554199
30000 2.3951308727264404
40000 1.8953704833984375
50000 2.1281423568725586
60000 2.08463454246521
70000 1.564221739768982
80000 2.0972611904144287
90000 2.21366810798645
100000 2.302164077758789
110000 1.839044451713562
120000 1.8937313556671143
130000 2.7189743518829346
140000 2.1313252449035645
150000 1.9625704288482666
160000 1.89139723777771
170000 1.889981985092163
180000 1.9499194622039795
190000 1.9968667030334473
199999 1.9478144645690918</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a>loss_split(params7, <span class="st">'train'</span>), loss_split(params7, <span class="st">'valid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(2.0388, grad_fn=&lt;NllLossBackward0&gt;),
 tensor(2.1015, grad_fn=&lt;NllLossBackward0&gt;))</code></pre>
</div>
</div>
</section>
<section id="batch-normalization" class="level2">
<h2 class="anchored" data-anchor-id="batch-normalization">Batch Normalization</h2>
<section id="normalization" class="level3">
<h3 class="anchored" data-anchor-id="normalization">Normalization</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>h_pre_act <span class="op">=</span> compute_pre_activation(params7, batch_x)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>h_pre_act.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([32, 200])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>h_pre_act_mean <span class="op">=</span> h_pre_act.mean(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>h_pre_act_mean.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([1, 200])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>h_pre_act_std <span class="op">=</span> h_pre_act.std(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>h_pre_act_std.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([1, 200])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>h_pre_act_norm <span class="op">=</span> (h_pre_act <span class="op">-</span> h_pre_act_mean)<span class="op">/</span>h_pre_act_std</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>h_pre_act_norm.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([32, 200])</code></pre>
</div>
</div>
</section>
<section id="define-new-training" class="level3">
<h3 class="anchored" data-anchor-id="define-new-training">Define new training</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initilialize_parameters_v6(block_size, embedding_size, hidden_neuron):</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((<span class="dv">27</span>, embedding_size), generator<span class="op">=</span>g)</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> torch.randn((block_size <span class="op">*</span> embedding_size, hidden_neuron), generator<span class="op">=</span>g) <span class="op">*</span> ((<span class="dv">5</span><span class="op">/</span><span class="dv">3</span>) <span class="op">/</span> ((embedding_size <span class="op">*</span> block_size) <span class="op">**</span> <span class="fl">0.5</span>))</span>
<span id="cb141-4"><a href="#cb141-4" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> torch.randn(hidden_neuron, generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb141-5"><a href="#cb141-5" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> torch.randn((hidden_neuron, <span class="dv">27</span>), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb141-6"><a href="#cb141-6" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> torch.randn(<span class="dv">27</span>, generator<span class="op">=</span>g) <span class="op">*</span> <span class="dv">0</span></span>
<span id="cb141-7"><a href="#cb141-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb141-8"><a href="#cb141-8" aria-hidden="true" tabindex="-1"></a>    bngain <span class="op">=</span> torch.ones((<span class="dv">1</span>, hidden_neuron)) <span class="co"># for scale in batch normalization</span></span>
<span id="cb141-9"><a href="#cb141-9" aria-hidden="true" tabindex="-1"></a>    bnbias <span class="op">=</span> torch.zeros((<span class="dv">1</span>, hidden_neuron)) <span class="co"># for shift in batch normalization</span></span>
<span id="cb141-10"><a href="#cb141-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb141-11"><a href="#cb141-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [C, W1, b1, W2, b2, bngain, bnbias]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_logits_v2(parameters, X):</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>    C, W1, b1, W2, b2, bngain, bnbias <span class="op">=</span> parameters</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> C[X]</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>    embcat <span class="op">=</span> emb.view(<span class="op">-</span><span class="dv">1</span>, W1.shape[<span class="dv">0</span>]) </span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>    h_pre_act <span class="op">=</span> embcat <span class="op">@</span> W1 <span class="op">+</span> b1</span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>    h_pre_act_norm <span class="op">=</span> (h_pre_act <span class="op">-</span> h_pre_act.mean(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)) <span class="op">/</span> h_pre_act.std(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb142-7"><a href="#cb142-7" aria-hidden="true" tabindex="-1"></a>    h_pre_act_scale_shift <span class="op">=</span> bngain <span class="op">*</span> h_pre_act_norm <span class="op">+</span> bnbias</span>
<span id="cb142-8"><a href="#cb142-8" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> torch.tanh(h_pre_act_scale_shift)</span>
<span id="cb142-9"><a href="#cb142-9" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> h <span class="op">@</span> W2 <span class="op">+</span> b2</span>
<span id="cb142-10"><a href="#cb142-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_v2(parameters,</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>          epochs,</span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>          X, </span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a>          Y, </span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a>          bs<span class="op">=</span><span class="dv">32</span>, </span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a>          lambdas <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a>          enable_print<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb143-8"><a href="#cb143-8" aria-hidden="true" tabindex="-1"></a>          print_at_every_nth_epoch<span class="op">=</span><span class="dv">10000</span></span>
<span id="cb143-9"><a href="#cb143-9" aria-hidden="true" tabindex="-1"></a>         ):</span>
<span id="cb143-10"><a href="#cb143-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb143-11"><a href="#cb143-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> parameters:</span>
<span id="cb143-12"><a href="#cb143-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">Exception</span>(<span class="st">"No initial parameters passed"</span>)</span>
<span id="cb143-13"><a href="#cb143-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb143-14"><a href="#cb143-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> parameters: p.requires_grad <span class="op">=</span> <span class="va">True</span> </span>
<span id="cb143-15"><a href="#cb143-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb143-16"><a href="#cb143-16" aria-hidden="true" tabindex="-1"></a>    losses <span class="op">=</span> [] </span>
<span id="cb143-17"><a href="#cb143-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb143-18"><a href="#cb143-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb143-19"><a href="#cb143-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb143-20"><a href="#cb143-20" aria-hidden="true" tabindex="-1"></a>        lr <span class="op">=</span> <span class="fl">0.1</span> <span class="cf">if</span> epoch <span class="op">&lt;</span> <span class="dv">100_000</span> <span class="cf">else</span> <span class="fl">0.01</span></span>
<span id="cb143-21"><a href="#cb143-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb143-22"><a href="#cb143-22" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.randint(<span class="dv">0</span>, X.shape[<span class="dv">0</span>], (bs, ))</span>
<span id="cb143-23"><a href="#cb143-23" aria-hidden="true" tabindex="-1"></a>        batch_x, batch_y <span class="op">=</span> X[ix], Y[ix]</span>
<span id="cb143-24"><a href="#cb143-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb143-25"><a href="#cb143-25" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> compute_logits_v2(parameters, batch_x)</span>
<span id="cb143-26"><a href="#cb143-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb143-27"><a href="#cb143-27" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> F.cross_entropy(logits, batch_y)</span>
<span id="cb143-28"><a href="#cb143-28" aria-hidden="true" tabindex="-1"></a>        regularization_loss <span class="op">=</span> _regularization_loss(parameters, lambdas)</span>
<span id="cb143-29"><a href="#cb143-29" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> regularization_loss</span>
<span id="cb143-30"><a href="#cb143-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-31"><a href="#cb143-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb143-32"><a href="#cb143-32" aria-hidden="true" tabindex="-1"></a>            p.grad<span class="op">=</span> <span class="va">None</span></span>
<span id="cb143-33"><a href="#cb143-33" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb143-34"><a href="#cb143-34" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb143-35"><a href="#cb143-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-36"><a href="#cb143-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-37"><a href="#cb143-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> index, p <span class="kw">in</span> <span class="bu">enumerate</span>(parameters):</span>
<span id="cb143-38"><a href="#cb143-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> p.grad <span class="kw">is</span> <span class="va">None</span>: <span class="bu">print</span>(index)</span>
<span id="cb143-39"><a href="#cb143-39" aria-hidden="true" tabindex="-1"></a>            p.data <span class="op">+=</span> <span class="op">-</span> lr <span class="op">*</span> p.grad</span>
<span id="cb143-40"><a href="#cb143-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-41"><a href="#cb143-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> enable_print <span class="kw">and</span> epoch <span class="op">%</span> print_at_every_nth_epoch <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(epoch, loss.item())</span>
<span id="cb143-42"><a href="#cb143-42" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb143-43"><a href="#cb143-43" aria-hidden="true" tabindex="-1"></a>        losses.append(loss.item())</span>
<span id="cb143-44"><a href="#cb143-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb143-45"><a href="#cb143-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> enable_print:  <span class="bu">print</span>(epoch, loss.item())   </span>
<span id="cb143-46"><a href="#cb143-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> losses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>params8 <span class="op">=</span> initilialize_parameters_v6(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(params8)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>7</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train_v2(params8, <span class="dv">200_000</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|                                                                                                                                                                 | 104/200000 [00:00&lt;06:19, 526.54it/s]  5%|████████                                                                                                                                                       | 10108/200000 [00:19&lt;05:51, 539.73it/s] 10%|███████████████▉                                                                                                                                               | 20082/200000 [00:37&lt;05:26, 550.87it/s] 15%|███████████████████████▊                                                                                                                                       | 29997/200000 [00:58&lt;05:47, 489.55it/s] 20%|███████████████████████████████▊                                                                                                                               | 40049/200000 [01:26&lt;09:19, 285.73it/s] 25%|███████████████████████████████████████▊                                                                                                                       | 50024/200000 [02:08&lt;16:14, 153.85it/s] 30%|███████████████████████████████████████████████▊                                                                                                               | 60073/200000 [02:38&lt;04:36, 505.30it/s] 35%|███████████████████████████████████████████████████████▋                                                                                                       | 70022/200000 [03:17&lt;16:32, 130.95it/s] 40%|███████████████████████████████████████████████████████████████▋                                                                                               | 80090/200000 [03:41&lt;04:08, 483.44it/s] 45%|███████████████████████████████████████████████████████████████████████▌                                                                                       | 90063/200000 [04:00&lt;03:17, 557.71it/s] 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 100101/200000 [04:20&lt;03:10, 523.81it/s] 55%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 110071/200000 [04:39&lt;03:39, 410.30it/s] 60%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 120058/200000 [05:16&lt;02:55, 454.36it/s] 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 130062/200000 [05:37&lt;02:17, 506.81it/s] 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 140096/200000 [05:56&lt;01:53, 527.01it/s] 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 150095/200000 [06:15&lt;01:35, 525.17it/s] 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 160090/200000 [06:35&lt;01:19, 502.85it/s] 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 170102/200000 [06:54&lt;00:59, 501.19it/s] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 180063/200000 [07:13&lt;00:38, 511.77it/s] 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 190075/200000 [07:32&lt;00:18, 540.90it/s]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [07:51&lt;00:00, 424.08it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.2974765300750732
10000 2.2444629669189453
20000 2.0267117023468018
30000 2.3122177124023438
40000 1.8772399425506592
50000 1.8241453170776367
60000 2.2491812705993652
70000 2.332838535308838
80000 2.2603352069854736
90000 2.521674394607544
100000 2.1766295433044434
110000 2.0648574829101562
120000 1.9632437229156494
130000 2.6266632080078125
140000 1.9747267961502075
150000 2.2220919132232666
160000 2.2269341945648193
170000 1.8781782388687134
180000 2.018829107284546
190000 1.694084644317627
199999 1.8435885906219482</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_loss_v2(parameters, X, Y):</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> compute_logits_v2(parameters, X)</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> F.cross_entropy(logits, Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loss_split_v2(parameters, dataset<span class="op">=</span><span class="st">'train'</span>):</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>    dataset_choices <span class="op">=</span> {</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train'</span>: (Xtr, Ytr),</span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'valid'</span>: (Xdev, Ydev),</span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'test'</span>: (Xte, Yte)</span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb151-7"><a href="#cb151-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> evaluate_loss_v2(parameters, <span class="op">*</span>dataset_choices[dataset])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>loss_split_v2(params8, <span class="st">'train'</span>), loss_split_v2(params8, <span class="st">'valid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(2.0683, grad_fn=&lt;NllLossBackward0&gt;),
 tensor(2.1130, grad_fn=&lt;NllLossBackward0&gt;))</code></pre>
</div>
</div>
</section>
<section id="consider-the-training-set-mean-and-std-deviation" class="level3">
<h3 class="anchored" data-anchor-id="consider-the-training-set-mean-and-std-deviation">Consider the Training set mean and std deviation</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_batchnorm_mean_std(parameters):</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>    C, W1, b1, <span class="op">*</span>rest <span class="op">=</span> parameters</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> C[Xtr]</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>    embcat <span class="op">=</span> emb.view(emb.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>    hpreact <span class="op">=</span> embcat <span class="op">@</span> W1 <span class="op">+</span> b1</span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># measure the mean/std over the training set</span></span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>    bnmean <span class="op">=</span> hpreact.mean(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>    bnstd <span class="op">=</span> hpreact.std(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> bnmean, bnstd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>train_bnmean, train_bnstd <span class="op">=</span> compute_batchnorm_mean_std(params8)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_logits_v3(parameters, X, bnmean<span class="op">=</span><span class="va">None</span>, bnstd<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>    C, W1, b1, W2, b2, bngain, bnbias <span class="op">=</span> parameters</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> C[X]</span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a>    embcat <span class="op">=</span> emb.view(<span class="op">-</span><span class="dv">1</span>, W1.shape[<span class="dv">0</span>]) </span>
<span id="cb156-5"><a href="#cb156-5" aria-hidden="true" tabindex="-1"></a>    h_pre_act <span class="op">=</span> embcat <span class="op">@</span> W1 <span class="op">+</span> b1</span>
<span id="cb156-6"><a href="#cb156-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-7"><a href="#cb156-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>  bnmean <span class="kw">is</span> <span class="va">None</span>  <span class="kw">and</span> bnstd <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb156-8"><a href="#cb156-8" aria-hidden="true" tabindex="-1"></a>        bnmean <span class="op">=</span> h_pre_act.mean(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb156-9"><a href="#cb156-9" aria-hidden="true" tabindex="-1"></a>        bnstd <span class="op">=</span> h_pre_act.std(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb156-10"><a href="#cb156-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb156-11"><a href="#cb156-11" aria-hidden="true" tabindex="-1"></a>    h_pre_act_norm <span class="op">=</span> (h_pre_act <span class="op">-</span> bnmean) <span class="op">/</span> bnstd</span>
<span id="cb156-12"><a href="#cb156-12" aria-hidden="true" tabindex="-1"></a>    h_pre_act_scale_shift <span class="op">=</span> bngain <span class="op">*</span> h_pre_act_norm <span class="op">+</span> bnbias</span>
<span id="cb156-13"><a href="#cb156-13" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> torch.tanh(h_pre_act_scale_shift)</span>
<span id="cb156-14"><a href="#cb156-14" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> h <span class="op">@</span> W2 <span class="op">+</span> b2</span>
<span id="cb156-15"><a href="#cb156-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_loss_v3(parameters, X, Y, bnmean, bnstd):</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> compute_logits_v3(parameters, X, bnmean, bnstd)</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> F.cross_entropy(logits, Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loss_split_v3(parameters, bnmean, bnstd, dataset<span class="op">=</span><span class="st">'train'</span>):</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a>    dataset_choices <span class="op">=</span> {</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train'</span>: (Xtr, Ytr),</span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'valid'</span>: (Xdev, Ydev),</span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'test'</span>: (Xte, Yte)</span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb158-7"><a href="#cb158-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> evaluate_loss_v3(parameters, <span class="op">*</span>dataset_choices[dataset], bnmean, bnstd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>loss_split_v3(params8, train_bnmean, train_bnstd, <span class="st">'train'</span>), loss_split_v3(params8, train_bnmean, train_bnstd, <span class="st">'valid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(2.0683, grad_fn=&lt;NllLossBackward0&gt;),
 tensor(2.1131, grad_fn=&lt;NllLossBackward0&gt;))</code></pre>
</div>
</div>
</section>
<section id="compute-running-mean-and-std" class="level3">
<h3 class="anchored" data-anchor-id="compute-running-mean-and-std">Compute running mean and std</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initilialize_parameters_v7(block_size, embedding_size, hidden_neuron):</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((<span class="dv">27</span>, embedding_size), generator<span class="op">=</span>g)</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>    W1 <span class="op">=</span> torch.randn((block_size <span class="op">*</span> embedding_size, hidden_neuron), generator<span class="op">=</span>g) <span class="op">*</span> ((<span class="dv">5</span><span class="op">/</span><span class="dv">3</span>) <span class="op">/</span> ((embedding_size <span class="op">*</span> block_size) <span class="op">**</span> <span class="fl">0.5</span>))</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> torch.randn(hidden_neuron, generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a>    W2 <span class="op">=</span> torch.randn((hidden_neuron, <span class="dv">27</span>), generator<span class="op">=</span>g) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb161-6"><a href="#cb161-6" aria-hidden="true" tabindex="-1"></a>    b2 <span class="op">=</span> torch.randn(<span class="dv">27</span>, generator<span class="op">=</span>g) <span class="op">*</span> <span class="dv">0</span></span>
<span id="cb161-7"><a href="#cb161-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb161-8"><a href="#cb161-8" aria-hidden="true" tabindex="-1"></a>    bngain <span class="op">=</span> torch.ones((<span class="dv">1</span>, hidden_neuron)) <span class="co"># for scale in batch normalization</span></span>
<span id="cb161-9"><a href="#cb161-9" aria-hidden="true" tabindex="-1"></a>    bnbias <span class="op">=</span> torch.zeros((<span class="dv">1</span>, hidden_neuron)) <span class="co"># for shift in batch normalization</span></span>
<span id="cb161-10"><a href="#cb161-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb161-11"><a href="#cb161-11" aria-hidden="true" tabindex="-1"></a>    bnmean_running <span class="op">=</span> torch.zeros((<span class="dv">1</span>, hidden_neuron))</span>
<span id="cb161-12"><a href="#cb161-12" aria-hidden="true" tabindex="-1"></a>    bnstd_running <span class="op">=</span> torch.ones((<span class="dv">1</span>, hidden_neuron))</span>
<span id="cb161-13"><a href="#cb161-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb161-14"><a href="#cb161-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [C, W1, b1, W2, b2, bngain, bnbias, bnmean_running, bnstd_running]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_logits_v4(parameters, X, step<span class="op">=</span><span class="st">'training'</span>):</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a>    C, W1, b1, W2, b2, bngain, bnbias, bnmean_running, bnstd_running <span class="op">=</span> parameters</span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>    emb <span class="op">=</span> C[X]</span>
<span id="cb162-4"><a href="#cb162-4" aria-hidden="true" tabindex="-1"></a>    embcat <span class="op">=</span> emb.view(<span class="op">-</span><span class="dv">1</span>, W1.shape[<span class="dv">0</span>]) </span>
<span id="cb162-5"><a href="#cb162-5" aria-hidden="true" tabindex="-1"></a>    h_pre_act <span class="op">=</span> embcat <span class="op">@</span> W1 <span class="op">+</span> b1</span>
<span id="cb162-6"><a href="#cb162-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-7"><a href="#cb162-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> step <span class="op">==</span> <span class="st">'training'</span>:</span>
<span id="cb162-8"><a href="#cb162-8" aria-hidden="true" tabindex="-1"></a>        bnmeani <span class="op">=</span> h_pre_act.mean(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb162-9"><a href="#cb162-9" aria-hidden="true" tabindex="-1"></a>        bnstdi <span class="op">=</span> h_pre_act.std(<span class="dv">0</span>, keepdim <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb162-10"><a href="#cb162-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-11"><a href="#cb162-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb162-12"><a href="#cb162-12" aria-hidden="true" tabindex="-1"></a>            bnmean_running.data <span class="op">=</span> <span class="fl">0.999</span> <span class="op">*</span> bnmean_running.data <span class="op">+</span> <span class="fl">0.001</span> <span class="op">*</span> bnmeani</span>
<span id="cb162-13"><a href="#cb162-13" aria-hidden="true" tabindex="-1"></a>            bnstd_running.data <span class="op">=</span> <span class="fl">0.999</span> <span class="op">*</span> bnstd_running.data <span class="op">+</span> <span class="fl">0.001</span> <span class="op">*</span> bnstdi</span>
<span id="cb162-14"><a href="#cb162-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb162-15"><a href="#cb162-15" aria-hidden="true" tabindex="-1"></a>        bnmeani <span class="op">=</span> bnmean_running</span>
<span id="cb162-16"><a href="#cb162-16" aria-hidden="true" tabindex="-1"></a>        bnstdi <span class="op">=</span> bnstd_running</span>
<span id="cb162-17"><a href="#cb162-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb162-18"><a href="#cb162-18" aria-hidden="true" tabindex="-1"></a>    h_pre_act_norm <span class="op">=</span> (h_pre_act <span class="op">-</span> bnmeani) <span class="op">/</span> bnstdi</span>
<span id="cb162-19"><a href="#cb162-19" aria-hidden="true" tabindex="-1"></a>    h_pre_act_scale_shift <span class="op">=</span> bngain <span class="op">*</span> h_pre_act_norm <span class="op">+</span> bnbias</span>
<span id="cb162-20"><a href="#cb162-20" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> torch.tanh(h_pre_act_scale_shift)</span>
<span id="cb162-21"><a href="#cb162-21" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> h <span class="op">@</span> W2 <span class="op">+</span> b2</span>
<span id="cb162-22"><a href="#cb162-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> logits</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_v3(parameters,</span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>          epochs,</span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>          X, </span>
<span id="cb163-4"><a href="#cb163-4" aria-hidden="true" tabindex="-1"></a>          Y, </span>
<span id="cb163-5"><a href="#cb163-5" aria-hidden="true" tabindex="-1"></a>          bs<span class="op">=</span><span class="dv">32</span>, </span>
<span id="cb163-6"><a href="#cb163-6" aria-hidden="true" tabindex="-1"></a>          lambdas <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>],</span>
<span id="cb163-7"><a href="#cb163-7" aria-hidden="true" tabindex="-1"></a>          enable_print<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb163-8"><a href="#cb163-8" aria-hidden="true" tabindex="-1"></a>          print_at_every_nth_epoch<span class="op">=</span><span class="dv">10000</span></span>
<span id="cb163-9"><a href="#cb163-9" aria-hidden="true" tabindex="-1"></a>         ):</span>
<span id="cb163-10"><a href="#cb163-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb163-11"><a href="#cb163-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> parameters:</span>
<span id="cb163-12"><a href="#cb163-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">Exception</span>(<span class="st">"No initial parameters passed"</span>)</span>
<span id="cb163-13"><a href="#cb163-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb163-14"><a href="#cb163-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> parameters: p.requires_grad <span class="op">=</span> <span class="va">True</span> </span>
<span id="cb163-15"><a href="#cb163-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb163-16"><a href="#cb163-16" aria-hidden="true" tabindex="-1"></a>    losses <span class="op">=</span> [] </span>
<span id="cb163-17"><a href="#cb163-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb163-18"><a href="#cb163-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb163-19"><a href="#cb163-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb163-20"><a href="#cb163-20" aria-hidden="true" tabindex="-1"></a>        lr <span class="op">=</span> <span class="fl">0.1</span> <span class="cf">if</span> epoch <span class="op">&lt;</span> <span class="dv">100_000</span> <span class="cf">else</span> <span class="fl">0.01</span></span>
<span id="cb163-21"><a href="#cb163-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb163-22"><a href="#cb163-22" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.randint(<span class="dv">0</span>, X.shape[<span class="dv">0</span>], (bs, ))</span>
<span id="cb163-23"><a href="#cb163-23" aria-hidden="true" tabindex="-1"></a>        batch_x, batch_y <span class="op">=</span> X[ix], Y[ix]</span>
<span id="cb163-24"><a href="#cb163-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb163-25"><a href="#cb163-25" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> compute_logits_v4(parameters, batch_x)</span>
<span id="cb163-26"><a href="#cb163-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb163-27"><a href="#cb163-27" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> F.cross_entropy(logits, batch_y)</span>
<span id="cb163-28"><a href="#cb163-28" aria-hidden="true" tabindex="-1"></a>        regularization_loss <span class="op">=</span> _regularization_loss(parameters, lambdas)</span>
<span id="cb163-29"><a href="#cb163-29" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">+=</span> regularization_loss</span>
<span id="cb163-30"><a href="#cb163-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-31"><a href="#cb163-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb163-32"><a href="#cb163-32" aria-hidden="true" tabindex="-1"></a>            p.grad<span class="op">=</span> <span class="va">None</span></span>
<span id="cb163-33"><a href="#cb163-33" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb163-34"><a href="#cb163-34" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb163-35"><a href="#cb163-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-36"><a href="#cb163-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-37"><a href="#cb163-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> index, p <span class="kw">in</span> <span class="bu">enumerate</span>(parameters):</span>
<span id="cb163-38"><a href="#cb163-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> p.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: p.data <span class="op">+=</span> <span class="op">-</span> lr <span class="op">*</span> p.grad</span>
<span id="cb163-39"><a href="#cb163-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-40"><a href="#cb163-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> enable_print <span class="kw">and</span> epoch <span class="op">%</span> print_at_every_nth_epoch <span class="op">==</span> <span class="dv">0</span>: <span class="bu">print</span>(epoch, loss.item())</span>
<span id="cb163-41"><a href="#cb163-41" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb163-42"><a href="#cb163-42" aria-hidden="true" tabindex="-1"></a>        losses.append(loss.item())</span>
<span id="cb163-43"><a href="#cb163-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb163-44"><a href="#cb163-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> enable_print:  <span class="bu">print</span>(epoch, loss.item())   </span>
<span id="cb163-45"><a href="#cb163-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> losses</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>params9 <span class="op">=</span> initilialize_parameters_v7(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">200</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> train_v3(params9, <span class="dv">200_000</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>  0%|                                                                                                                                                                  | 53/200000 [00:00&lt;11:28, 290.39it/s]  5%|████████                                                                                                                                                       | 10064/200000 [00:21&lt;06:26, 491.17it/s] 10%|███████████████▉                                                                                                                                               | 20069/200000 [00:44&lt;06:25, 466.38it/s] 15%|███████████████████████▉                                                                                                                                       | 30094/200000 [01:05&lt;05:47, 489.06it/s] 20%|███████████████████████████████▊                                                                                                                               | 40057/200000 [01:25&lt;05:32, 481.69it/s] 25%|███████████████████████████████████████▊                                                                                                                       | 50058/200000 [01:47&lt;05:00, 499.70it/s] 30%|███████████████████████████████████████████████▊                                                                                                               | 60073/200000 [02:08&lt;04:49, 483.97it/s] 35%|███████████████████████████████████████████████████████▋                                                                                                       | 70031/200000 [02:36&lt;09:18, 232.65it/s] 40%|███████████████████████████████████████████████████████████████▋                                                                                               | 80046/200000 [03:29&lt;06:10, 323.66it/s] 45%|████████████████████████████████████████████████████████████████████████                                                                                        | 90023/200000 [04:09&lt;22:28, 81.54it/s] 50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 100065/200000 [04:35&lt;03:46, 440.83it/s] 55%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 110070/200000 [05:05&lt;03:09, 474.93it/s] 60%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 120084/200000 [05:26&lt;02:52, 462.69it/s] 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 130038/200000 [05:56&lt;03:10, 367.74it/s] 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 140079/200000 [06:35&lt;02:15, 443.66it/s] 75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 150058/200000 [06:58&lt;02:12, 375.75it/s] 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 160053/200000 [07:30&lt;01:22, 482.75it/s] 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 170064/200000 [08:07&lt;01:10, 422.13it/s] 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 180042/200000 [08:39&lt;00:47, 422.86it/s] 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 190066/200000 [09:03&lt;00:22, 440.71it/s]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [09:44&lt;00:00, 341.89it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0 3.2910704612731934
10000 2.2731170654296875
20000 2.676584482192993
30000 2.425685405731201
40000 2.1894543170928955
50000 2.406543731689453
60000 2.19313383102417
70000 1.9194616079330444
80000 2.9036688804626465
90000 2.281238079071045
100000 1.890221357345581
110000 2.034389019012451
120000 1.7974919080734253
130000 2.2577686309814453
140000 2.1341137886047363
150000 2.03934907913208
160000 2.2662088871002197
170000 2.285844564437866
180000 2.451364755630493
190000 2.512420654296875
199999 2.0207467079162598</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>train_bmean, train_bstd <span class="op">=</span> compute_batchnorm_mean_std(params9)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>train_bmean.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([1, 200])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>train_bstd.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>torch.Size([1, 200])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>params9[<span class="op">-</span><span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([[ 0.0375, -0.6331, -0.3791, -0.9008,  0.2962,  1.4619, -0.2891,  0.1883,
          0.3329,  0.2727, -0.9458, -0.6716, -0.5048, -0.6620,  0.2342,  1.1776,
          0.5657,  1.9836, -0.2188, -0.1207, -1.8573,  0.3398,  0.3636,  2.3903,
          0.4538,  0.0833, -1.0701, -0.7340, -0.3513,  1.9030, -0.7348, -0.4769,
         -2.3932, -0.3250,  0.3072,  0.4761,  1.0564, -0.9924, -0.5760,  1.1480,
         -1.0848,  1.0707,  1.4146, -1.5361, -1.7056, -1.0768,  0.5271, -0.1483,
         -0.3467, -1.4341,  0.3082, -0.1178,  1.0577, -1.3717,  0.2063, -0.7474,
         -0.5008,  0.7797, -0.4381, -0.5850, -0.6317,  0.9563, -1.2107,  0.2256,
         -0.3417, -0.0634, -1.0470, -0.7367,  0.4666, -0.9433,  0.0427,  0.6610,
         -0.0472, -0.6191, -0.2211, -0.3358, -0.1517, -0.5254,  1.0690, -1.2109,
         -0.2712, -1.7430, -1.3447,  0.6727,  0.9114, -0.9647, -0.1962,  0.2689,
         -0.5687,  0.5511, -0.1002,  0.4604, -0.3753, -0.3717, -0.8587, -0.2480,
         -0.8048,  0.5067,  0.9874, -0.9155,  1.0679,  0.8766, -0.3299, -0.4363,
          0.4756, -0.2838, -1.1314,  0.8018,  0.0026, -0.1068, -0.7755, -0.3257,
          1.3104,  0.4733,  0.2502,  0.9611,  1.2929, -0.7287, -0.7842, -1.1771,
          0.6131, -0.4987, -0.2233, -0.0505,  0.2554, -1.3391,  0.4501, -0.6442,
         -0.2634, -0.3602,  2.0635,  0.6144, -0.2697,  1.7540, -2.0597,  0.7119,
         -0.7171, -0.0732,  0.8917,  0.1726,  0.6225, -0.5065,  1.7100, -0.0922,
          0.1529,  1.6846,  0.3420, -0.4169, -0.2356, -0.4468, -0.8213,  0.2331,
         -2.2176, -0.0141,  0.2564,  0.1819,  0.0972,  0.4663,  0.5573,  0.5170,
         -2.4660,  0.6317, -0.0866, -1.3206, -0.3167, -1.1647, -1.4368,  0.0419,
         -0.6170, -0.8835,  0.8117, -0.8902, -1.6758,  1.4599,  0.6674, -0.5737,
         -0.3982, -0.8486,  0.7648, -0.6740, -0.8773,  0.1644,  0.3821, -1.0831,
          1.0532,  0.7580, -0.5744, -0.6737, -0.6705,  0.5464,  0.3474,  0.5626,
         -0.8972, -0.6644, -0.4031, -1.2800,  1.5996, -0.8948, -1.6051, -0.8797]],
       requires_grad=True)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>train_bmean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([[ 0.0336, -0.6265, -0.3734, -0.9142,  0.3122,  1.4727, -0.2720,  0.2043,
          0.3280,  0.2649, -0.9420, -0.6603, -0.5234, -0.6541,  0.2307,  1.1702,
          0.5762,  1.9697, -0.2134, -0.1228, -1.8548,  0.3674,  0.3822,  2.3695,
          0.4678,  0.0884, -1.0760, -0.7574, -0.3623,  1.9024, -0.7362, -0.4469,
         -2.3866, -0.3177,  0.2965,  0.4548,  1.0385, -0.9807, -0.5685,  1.1614,
         -1.0926,  1.0664,  1.4133, -1.5146, -1.6854, -1.0843,  0.5003, -0.1437,
         -0.3558, -1.4272,  0.2930, -0.1223,  1.0598, -1.3414,  0.2255, -0.7481,
         -0.5164,  0.7950, -0.4377, -0.5765, -0.6527,  0.9657, -1.1949,  0.2556,
         -0.3367, -0.0697, -1.0539, -0.7473,  0.4742, -0.9174,  0.0496,  0.6626,
         -0.0252, -0.6193, -0.2340, -0.3298, -0.1581, -0.5270,  1.0956, -1.1991,
         -0.2696, -1.7306, -1.3725,  0.6711,  0.9122, -0.9572, -0.1943,  0.2736,
         -0.5639,  0.5646, -0.0927,  0.4803, -0.3902, -0.3292, -0.8637, -0.2507,
         -0.8104,  0.5088,  0.9935, -0.9224,  1.0957,  0.8640, -0.3443, -0.4084,
          0.4823, -0.2982, -1.1175,  0.8094,  0.0229, -0.1139, -0.7825, -0.3265,
          1.3089,  0.4729,  0.2671,  0.9844,  1.3121, -0.7067, -0.8011, -1.1575,
          0.6211, -0.5021, -0.2209, -0.0643,  0.2590, -1.3219,  0.4299, -0.6472,
         -0.2602, -0.3664,  2.0622,  0.6203, -0.2817,  1.7380, -2.0716,  0.7414,
         -0.6948, -0.0536,  0.8889,  0.1630,  0.6067, -0.5124,  1.7246, -0.0809,
          0.1703,  1.6875,  0.3339, -0.4017, -0.2522, -0.4726, -0.8133,  0.2514,
         -2.2188, -0.0041,  0.2641,  0.1699,  0.0992,  0.4487,  0.5679,  0.5218,
         -2.4712,  0.6221, -0.0852, -1.3236, -0.3386, -1.1213, -1.4408,  0.0377,
         -0.5953, -0.8718,  0.8178, -0.9079, -1.6565,  1.4652,  0.6479, -0.5730,
         -0.4037, -0.8535,  0.7510, -0.6731, -0.8535,  0.1698,  0.3929, -1.0634,
          1.0645,  0.7542, -0.5708, -0.6714, -0.6442,  0.5538,  0.3533,  0.5629,
         -0.8813, -0.6482, -0.3858, -1.2797,  1.6030, -0.8916, -1.6031, -0.8928]],
       grad_fn=&lt;MeanBackward1&gt;)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>params9[<span class="op">-</span><span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([[2.4632, 2.3683, 2.4826, 2.0530, 2.1001, 2.5936, 2.4268, 1.8161, 2.2527,
         2.2914, 2.0653, 1.7652, 2.0370, 2.3531, 2.3336, 2.2467, 2.3725, 2.4981,
         2.1250, 1.9589, 2.4479, 2.1229, 1.9701, 2.6517, 2.4070, 2.2383, 1.5956,
         1.9934, 2.2423, 2.3018, 2.1449, 1.9444, 2.1350, 2.3635, 2.1110, 2.2966,
         1.9588, 2.2902, 2.0242, 2.2285, 2.6163, 2.5771, 1.9682, 2.4096, 2.1897,
         1.9587, 2.5828, 2.2682, 1.5224, 2.2569, 2.0790, 2.0309, 2.7052, 2.0490,
         2.6919, 2.7425, 1.6170, 2.2639, 2.2183, 2.4126, 2.5572, 2.1070, 2.3111,
         2.1343, 2.4835, 1.9523, 2.4436, 2.1352, 2.6667, 2.5792, 2.4142, 2.3900,
         1.8665, 2.1212, 2.2905, 2.1226, 1.9209, 2.4108, 2.4251, 1.9492, 2.0006,
         2.7582, 2.5923, 2.1482, 1.9433, 1.8152, 2.2074, 1.9798, 2.1282, 2.5727,
         2.2498, 2.1983, 2.3262, 2.6791, 2.0241, 2.0521, 2.2381, 2.0871, 2.0417,
         2.5972, 2.0449, 2.4388, 1.9639, 2.2393, 2.1035, 2.1849, 1.9384, 2.3872,
         2.5280, 2.6528, 2.2955, 1.9553, 2.3484, 2.3475, 2.7836, 2.1356, 2.3427,
         2.0554, 2.3580, 1.9564, 2.2688, 2.2788, 2.2936, 2.1819, 2.2038, 2.3220,
         2.2896, 1.9991, 2.0549, 2.1163, 2.6239, 1.5893, 2.8965, 2.0469, 2.2779,
         2.1321, 2.1158, 1.8507, 2.3508, 1.9726, 1.9283, 2.2762, 1.9608, 2.4423,
         2.0968, 2.0759, 2.7557, 3.1357, 2.2457, 2.5234, 2.3572, 2.6196, 2.2824,
         2.1964, 2.4175, 1.3403, 2.5489, 2.2041, 2.5038, 1.9908, 2.0546, 2.3802,
         2.4392, 2.2461, 2.1533, 2.1316, 2.4615, 1.8033, 2.3087, 1.9742, 2.3235,
         1.7176, 2.0494, 2.3848, 2.3092, 2.4218, 2.2263, 2.4015, 2.1627, 2.1673,
         2.3420, 2.0868, 2.7352, 2.4064, 2.0937, 2.4994, 1.7547, 2.3966, 2.3889,
         1.9188, 2.1525, 2.0753, 2.1131, 2.1583, 2.1470, 2.2530, 2.6288, 1.9458,
         2.1839, 2.2465]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>train_bstd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>tensor([[2.4732, 2.3784, 2.5213, 2.0699, 2.1313, 2.6214, 2.4610, 1.8370, 2.2874,
         2.3359, 2.0795, 1.7793, 2.0715, 2.3730, 2.3941, 2.2722, 2.4023, 2.5138,
         2.1447, 1.9971, 2.4711, 2.1447, 1.9872, 2.6469, 2.4311, 2.2664, 1.6039,
         2.0137, 2.2677, 2.3347, 2.1688, 1.9666, 2.1642, 2.4079, 2.1322, 2.3575,
         1.9967, 2.3048, 2.0512, 2.2445, 2.6568, 2.6134, 1.9959, 2.4373, 2.2055,
         1.9620, 2.6040, 2.3006, 1.5517, 2.2881, 2.1018, 2.0604, 2.7347, 2.0694,
         2.7125, 2.7579, 1.6329, 2.3031, 2.2478, 2.4416, 2.5732, 2.1449, 2.3496,
         2.1591, 2.5255, 1.9768, 2.4779, 2.1505, 2.6936, 2.5978, 2.4561, 2.3916,
         1.8887, 2.1492, 2.3122, 2.1676, 1.9488, 2.4345, 2.4486, 1.9695, 2.0231,
         2.7833, 2.6296, 2.1697, 1.9649, 1.8332, 2.2276, 1.9933, 2.1393, 2.5949,
         2.2839, 2.2298, 2.3553, 2.7204, 2.0429, 2.0738, 2.2546, 2.1089, 2.0694,
         2.6374, 2.0650, 2.4688, 1.9873, 2.2620, 2.1333, 2.2223, 1.9737, 2.4104,
         2.5586, 2.6578, 2.3239, 1.9960, 2.3708, 2.3778, 2.8150, 2.1605, 2.3796,
         2.0766, 2.3811, 1.9827, 2.2918, 2.3128, 2.3298, 2.2081, 2.2340, 2.3566,
         2.3248, 2.0105, 2.0888, 2.1318, 2.6333, 1.6082, 2.9117, 2.0752, 2.3033,
         2.1490, 2.1393, 1.8752, 2.3683, 1.9951, 1.9514, 2.3120, 1.9701, 2.4542,
         2.1293, 2.0938, 2.7844, 3.1507, 2.2620, 2.5633, 2.3879, 2.6383, 2.3134,
         2.2227, 2.4502, 1.3551, 2.5690, 2.2434, 2.5294, 2.0216, 2.0723, 2.4025,
         2.4604, 2.2773, 2.1765, 2.1551, 2.4940, 1.8347, 2.3483, 1.9932, 2.3455,
         1.7362, 2.0621, 2.4156, 2.3354, 2.4520, 2.2545, 2.4163, 2.1852, 2.1869,
         2.3587, 2.1191, 2.7597, 2.4383, 2.1112, 2.5392, 1.7744, 2.4260, 2.4106,
         1.9521, 2.1830, 2.1063, 2.1329, 2.1864, 2.1679, 2.2876, 2.6466, 1.9717,
         2.1994, 2.2678]], grad_fn=&lt;StdBackward0&gt;)</code></pre>
</div>
</div>
<p>above values are close</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_loss_v4(parameters, X, Y, bnmean, bnstd):</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> compute_logits_v4(parameters, X, <span class="st">'evaluation'</span>)</span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> F.cross_entropy(logits, Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> loss_split_v4(parameters, bnmean, bnstd, dataset<span class="op">=</span><span class="st">'train'</span>):</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>    dataset_choices <span class="op">=</span> {</span>
<span id="cb182-3"><a href="#cb182-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train'</span>: (Xtr, Ytr),</span>
<span id="cb182-4"><a href="#cb182-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'valid'</span>: (Xdev, Ydev),</span>
<span id="cb182-5"><a href="#cb182-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'test'</span>: (Xte, Yte)</span>
<span id="cb182-6"><a href="#cb182-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb182-7"><a href="#cb182-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> evaluate_loss_v4(parameters, <span class="op">*</span>dataset_choices[dataset], bnmean, bnstd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>loss_split_v4(params9, params9[<span class="op">-</span><span class="dv">2</span>], params9[<span class="op">-</span><span class="dv">1</span>], <span class="st">'train'</span>), loss_split_v4(params9, train_bnmean, train_bnstd, <span class="st">'valid'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor(2.0704, grad_fn=&lt;NllLossBackward0&gt;),
 tensor(2.1112, grad_fn=&lt;NllLossBackward0&gt;))</code></pre>
</div>
</div>
</section>
</section>
<section id="pytorchifying-the-code" class="level2">
<h2 class="anchored" data-anchor-id="pytorchifying-the-code">Pytorchifying the code</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">2147483647</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear:</span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, fan_in, fan_out, bias<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb186-4"><a href="#cb186-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weight <span class="op">=</span> torch.randn((fan_in, fan_out), generator<span class="op">=</span>g) <span class="op">/</span> fan_in <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb186-5"><a href="#cb186-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> torch.zeros(fan_out) <span class="cf">if</span> bias <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb186-6"><a href="#cb186-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb186-7"><a href="#cb186-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb186-8"><a href="#cb186-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> x <span class="op">@</span> <span class="va">self</span>.weight</span>
<span id="cb186-9"><a href="#cb186-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb186-10"><a href="#cb186-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.out <span class="op">+=</span> <span class="va">self</span>.bias</span>
<span id="cb186-11"><a href="#cb186-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out</span>
<span id="cb186-12"><a href="#cb186-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb186-13"><a href="#cb186-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parameters(<span class="va">self</span>):</span>
<span id="cb186-14"><a href="#cb186-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="va">self</span>.weight] <span class="op">+</span> ([] <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> [<span class="va">self</span>.bias])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BatchNorm1d:</span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb187-3"><a href="#cb187-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim, eps<span class="op">=</span><span class="fl">1e-5</span>, momentum<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb187-4"><a href="#cb187-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eps <span class="op">=</span> eps</span>
<span id="cb187-5"><a href="#cb187-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.momentum <span class="op">=</span> momentum</span>
<span id="cb187-6"><a href="#cb187-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.training <span class="op">=</span> <span class="va">True</span></span>
<span id="cb187-7"><a href="#cb187-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># parameters (trained with backprop)</span></span>
<span id="cb187-8"><a href="#cb187-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gamma <span class="op">=</span> torch.ones(dim)</span>
<span id="cb187-9"><a href="#cb187-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta <span class="op">=</span> torch.zeros(dim)</span>
<span id="cb187-10"><a href="#cb187-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># buffers (trained with a running `monentum update`)</span></span>
<span id="cb187-11"><a href="#cb187-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.running_mean <span class="op">=</span> torch.zeros(dim)</span>
<span id="cb187-12"><a href="#cb187-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.running_var  <span class="op">=</span> torch.ones(dim)</span>
<span id="cb187-13"><a href="#cb187-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb187-14"><a href="#cb187-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb187-15"><a href="#cb187-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.training:</span>
<span id="cb187-16"><a href="#cb187-16" aria-hidden="true" tabindex="-1"></a>            xmean <span class="op">=</span> x.mean(<span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>) <span class="co"># batch mean</span></span>
<span id="cb187-17"><a href="#cb187-17" aria-hidden="true" tabindex="-1"></a>            xvar <span class="op">=</span> x.var(<span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>, unbiased<span class="op">=</span><span class="va">True</span>) <span class="co"># batch variance</span></span>
<span id="cb187-18"><a href="#cb187-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb187-19"><a href="#cb187-19" aria-hidden="true" tabindex="-1"></a>            xmean <span class="op">=</span> <span class="va">self</span>.running_mean</span>
<span id="cb187-20"><a href="#cb187-20" aria-hidden="true" tabindex="-1"></a>            xvar <span class="op">=</span> <span class="va">self</span>.running_var</span>
<span id="cb187-21"><a href="#cb187-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb187-22"><a href="#cb187-22" aria-hidden="true" tabindex="-1"></a>        x_hat <span class="op">=</span> (x <span class="op">-</span> xmean) <span class="op">/</span> torch.sqrt(xvar <span class="op">+</span> <span class="va">self</span>.eps)</span>
<span id="cb187-23"><a href="#cb187-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> <span class="va">self</span>.gamma <span class="op">*</span> x_hat <span class="op">+</span> <span class="va">self</span>.beta</span>
<span id="cb187-24"><a href="#cb187-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb187-25"><a href="#cb187-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.training:</span>
<span id="cb187-26"><a href="#cb187-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb187-27"><a href="#cb187-27" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.running_mean <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.momentum) <span class="op">*</span> <span class="va">self</span>.running_mean  <span class="op">+</span> <span class="va">self</span>.momentum <span class="op">*</span> xmean</span>
<span id="cb187-28"><a href="#cb187-28" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.running_var <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.momentum) <span class="op">*</span> <span class="va">self</span>.running_mean <span class="op">+</span> <span class="va">self</span>.momentum <span class="op">*</span> xmean</span>
<span id="cb187-29"><a href="#cb187-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb187-30"><a href="#cb187-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out</span>
<span id="cb187-31"><a href="#cb187-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb187-32"><a href="#cb187-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parameters(<span class="va">self</span>):</span>
<span id="cb187-33"><a href="#cb187-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="va">self</span>.gamma, <span class="va">self</span>.beta]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Tanh:</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> torch.tanh(x)</span>
<span id="cb188-4"><a href="#cb188-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out</span>
<span id="cb188-5"><a href="#cb188-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parameters(<span class="va">self</span>):</span>
<span id="cb188-6"><a href="#cb188-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> []</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(max_steps, X, Y, </span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>            bs <span class="op">=</span> <span class="dv">32</span>, </span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>            vocab_size <span class="op">=</span> <span class="dv">27</span>, <span class="co"># the number of characters</span></span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a>            n_embd <span class="op">=</span> <span class="dv">10</span>, <span class="co"># the dimensionality of the character embedding vectors</span></span>
<span id="cb189-5"><a href="#cb189-5" aria-hidden="true" tabindex="-1"></a>            n_hidden <span class="op">=</span> <span class="dv">100</span>, <span class="co"># the number of neurons in the hidden layer of the MLP</span></span>
<span id="cb189-6"><a href="#cb189-6" aria-hidden="true" tabindex="-1"></a>            block_size <span class="op">=</span> <span class="dv">3</span>, </span>
<span id="cb189-7"><a href="#cb189-7" aria-hidden="true" tabindex="-1"></a>            weight_scale <span class="op">=</span> <span class="dv">5</span><span class="op">/</span><span class="dv">3</span>,</span>
<span id="cb189-8"><a href="#cb189-8" aria-hidden="true" tabindex="-1"></a>            network_type <span class="op">=</span> <span class="st">'non-linear'</span>,</span>
<span id="cb189-9"><a href="#cb189-9" aria-hidden="true" tabindex="-1"></a>            learning_rate <span class="op">=</span> <span class="va">None</span></span>
<span id="cb189-10"><a href="#cb189-10" aria-hidden="true" tabindex="-1"></a>         ):</span>
<span id="cb189-11"><a href="#cb189-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb189-12"><a href="#cb189-12" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> torch.randn((vocab_size, n_embd), generator<span class="op">=</span>g)</span>
<span id="cb189-13"><a href="#cb189-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb189-14"><a href="#cb189-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> network_type <span class="op">==</span> <span class="st">'linear'</span>:</span>
<span id="cb189-15"><a href="#cb189-15" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> [</span>
<span id="cb189-16"><a href="#cb189-16" aria-hidden="true" tabindex="-1"></a>            Linear(n_embd <span class="op">*</span> block_size, n_hidden),</span>
<span id="cb189-17"><a href="#cb189-17" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden),</span>
<span id="cb189-18"><a href="#cb189-18" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), </span>
<span id="cb189-19"><a href="#cb189-19" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), </span>
<span id="cb189-20"><a href="#cb189-20" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), </span>
<span id="cb189-21"><a href="#cb189-21" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, vocab_size)</span>
<span id="cb189-22"><a href="#cb189-22" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb189-23"><a href="#cb189-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> network_type <span class="op">==</span> <span class="st">'non-linear'</span>:</span>
<span id="cb189-24"><a href="#cb189-24" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> [</span>
<span id="cb189-25"><a href="#cb189-25" aria-hidden="true" tabindex="-1"></a>            Linear(n_embd <span class="op">*</span> block_size, n_hidden), Tanh(),</span>
<span id="cb189-26"><a href="#cb189-26" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), Tanh(),</span>
<span id="cb189-27"><a href="#cb189-27" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), Tanh(),</span>
<span id="cb189-28"><a href="#cb189-28" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), Tanh(),</span>
<span id="cb189-29"><a href="#cb189-29" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), Tanh(),</span>
<span id="cb189-30"><a href="#cb189-30" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, vocab_size)</span>
<span id="cb189-31"><a href="#cb189-31" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb189-32"><a href="#cb189-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb189-33"><a href="#cb189-33" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> [</span>
<span id="cb189-34"><a href="#cb189-34" aria-hidden="true" tabindex="-1"></a>            Linear(n_embd <span class="op">*</span> block_size, n_hidden), BatchNorm1d(n_hidden), Tanh(),</span>
<span id="cb189-35"><a href="#cb189-35" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),</span>
<span id="cb189-36"><a href="#cb189-36" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),</span>
<span id="cb189-37"><a href="#cb189-37" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),</span>
<span id="cb189-38"><a href="#cb189-38" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),</span>
<span id="cb189-39"><a href="#cb189-39" aria-hidden="true" tabindex="-1"></a>            Linear(n_hidden, vocab_size), BatchNorm1d(vocab_size)</span>
<span id="cb189-40"><a href="#cb189-40" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb189-41"><a href="#cb189-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb189-42"><a href="#cb189-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb189-43"><a href="#cb189-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># last layer: make less confident</span></span>
<span id="cb189-44"><a href="#cb189-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> network_type <span class="op">!=</span> <span class="st">'batchnorm'</span>:</span>
<span id="cb189-45"><a href="#cb189-45" aria-hidden="true" tabindex="-1"></a>            layers[<span class="op">-</span><span class="dv">1</span>].weight <span class="op">*=</span> <span class="fl">0.1</span></span>
<span id="cb189-46"><a href="#cb189-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb189-47"><a href="#cb189-47" aria-hidden="true" tabindex="-1"></a>            layers[<span class="op">-</span><span class="dv">1</span>].gamma <span class="op">*=</span> <span class="fl">0.1</span></span>
<span id="cb189-48"><a href="#cb189-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># all other layers: apply gain</span></span>
<span id="cb189-49"><a href="#cb189-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> layers[:<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb189-50"><a href="#cb189-50" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(layer, Linear):</span>
<span id="cb189-51"><a href="#cb189-51" aria-hidden="true" tabindex="-1"></a>                layer.weight <span class="op">*=</span> weight_scale</span>
<span id="cb189-52"><a href="#cb189-52" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb189-53"><a href="#cb189-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb189-54"><a href="#cb189-54" aria-hidden="true" tabindex="-1"></a>    parameters <span class="op">=</span> [C] <span class="op">+</span> [p <span class="cf">for</span> layer <span class="kw">in</span> layers <span class="cf">for</span> p <span class="kw">in</span> layer.parameters()]</span>
<span id="cb189-55"><a href="#cb189-55" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Total number of parameters are :'</span>, <span class="bu">sum</span>(p.nelement() <span class="cf">for</span> p <span class="kw">in</span> parameters))</span>
<span id="cb189-56"><a href="#cb189-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb189-57"><a href="#cb189-57" aria-hidden="true" tabindex="-1"></a>        p.requires_grad <span class="op">=</span> <span class="va">True</span> </span>
<span id="cb189-58"><a href="#cb189-58" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-59"><a href="#cb189-59" aria-hidden="true" tabindex="-1"></a>    lossi <span class="op">=</span> []</span>
<span id="cb189-60"><a href="#cb189-60" aria-hidden="true" tabindex="-1"></a>    ud <span class="op">=</span> []</span>
<span id="cb189-61"><a href="#cb189-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_steps):</span>
<span id="cb189-62"><a href="#cb189-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># minibatch construct</span></span>
<span id="cb189-63"><a href="#cb189-63" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> torch.randint(<span class="dv">0</span>, X.shape[<span class="dv">0</span>], (bs, ), generator <span class="op">=</span> g)</span>
<span id="cb189-64"><a href="#cb189-64" aria-hidden="true" tabindex="-1"></a>        Xb, Yb <span class="op">=</span> X[ix], Y[ix]</span>
<span id="cb189-65"><a href="#cb189-65" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-66"><a href="#cb189-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># forward pass</span></span>
<span id="cb189-67"><a href="#cb189-67" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> C[Xb]</span>
<span id="cb189-68"><a href="#cb189-68" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> emb.view(emb.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb189-69"><a href="#cb189-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> layers:</span>
<span id="cb189-70"><a href="#cb189-70" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb189-71"><a href="#cb189-71" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> F.cross_entropy(x, Yb)</span>
<span id="cb189-72"><a href="#cb189-72" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-73"><a href="#cb189-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> layers:</span>
<span id="cb189-74"><a href="#cb189-74" aria-hidden="true" tabindex="-1"></a>            layer.out.retain_grad() <span class="co"># AFTER_DEBUG: would take out retain_graph</span></span>
<span id="cb189-75"><a href="#cb189-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-76"><a href="#cb189-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb189-77"><a href="#cb189-77" aria-hidden="true" tabindex="-1"></a>            p.grad <span class="op">=</span> <span class="va">None</span></span>
<span id="cb189-78"><a href="#cb189-78" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-79"><a href="#cb189-79" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb189-80"><a href="#cb189-80" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-81"><a href="#cb189-81" aria-hidden="true" tabindex="-1"></a>        lr <span class="op">=</span> <span class="fl">0.1</span> <span class="cf">if</span> i <span class="op">&lt;</span> <span class="dv">100_000</span> <span class="cf">else</span> <span class="fl">0.01</span> <span class="co"># step learning rate decay</span></span>
<span id="cb189-82"><a href="#cb189-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> learning_rate: lr <span class="op">=</span> learning_rate</span>
<span id="cb189-83"><a href="#cb189-83" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-84"><a href="#cb189-84" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-85"><a href="#cb189-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> parameters:</span>
<span id="cb189-86"><a href="#cb189-86" aria-hidden="true" tabindex="-1"></a>            p.data <span class="op">+=</span> <span class="op">-</span>lr <span class="op">*</span> p.grad</span>
<span id="cb189-87"><a href="#cb189-87" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-88"><a href="#cb189-88" aria-hidden="true" tabindex="-1"></a>        <span class="co"># track stats</span></span>
<span id="cb189-89"><a href="#cb189-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">10_000</span> <span class="op">==</span> <span class="dv">0</span>: <span class="co"># print every once in a while</span></span>
<span id="cb189-90"><a href="#cb189-90" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>i<span class="sc">:7d}</span><span class="ss">/</span><span class="sc">{</span>max_steps<span class="sc">:7d}</span><span class="ss">: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">'</span>)</span>
<span id="cb189-91"><a href="#cb189-91" aria-hidden="true" tabindex="-1"></a>        lossi.append(loss.log10().item())</span>
<span id="cb189-92"><a href="#cb189-92" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb189-93"><a href="#cb189-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb189-94"><a href="#cb189-94" aria-hidden="true" tabindex="-1"></a>            ud.append([(lr <span class="op">*</span> p.grad.std() <span class="op">/</span> p.data.std()).log10().item() <span class="cf">for</span> p <span class="kw">in</span> parameters])</span>
<span id="cb189-95"><a href="#cb189-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> layers, parameters, lossi, ud</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1</span>, Xtr, Ytr, network_type <span class="op">=</span> <span class="st">'non-linear'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/      1: 3.3099</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb192"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_histograms(layers, instance_layer <span class="op">=</span> Tanh, output_type<span class="op">=</span><span class="st">'forward'</span>):</span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a>    plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">4</span>))</span>
<span id="cb192-3"><a href="#cb192-3" aria-hidden="true" tabindex="-1"></a>    legends <span class="op">=</span> []</span>
<span id="cb192-4"><a href="#cb192-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, layer <span class="kw">in</span> <span class="bu">enumerate</span>(layers[:<span class="op">-</span><span class="dv">1</span>]):</span>
<span id="cb192-5"><a href="#cb192-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(layer, instance_layer):</span>
<span id="cb192-6"><a href="#cb192-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> output_type <span class="op">==</span> <span class="st">'forward'</span>: t <span class="op">=</span> layer.out</span>
<span id="cb192-7"><a href="#cb192-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>: t <span class="op">=</span> layer.out.grad</span>
<span id="cb192-8"><a href="#cb192-8" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'layer </span><span class="sc">%d</span><span class="st"> (</span><span class="sc">%10s</span><span class="st">): mean </span><span class="sc">%+f</span><span class="st">, std </span><span class="sc">%e</span><span class="st">'</span> <span class="op">%</span> (i, layer.__class__.<span class="va">__name__</span>, t.mean(), t.std()))</span>
<span id="cb192-9"><a href="#cb192-9" aria-hidden="true" tabindex="-1"></a>            hy, hx <span class="op">=</span> torch.histogram(t, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb192-10"><a href="#cb192-10" aria-hidden="true" tabindex="-1"></a>            plot.plot(hx[:<span class="op">-</span><span class="dv">1</span>].detach(), hy.detach())</span>
<span id="cb192-11"><a href="#cb192-11" aria-hidden="true" tabindex="-1"></a>            legends.append(<span class="ss">f'layer </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>layer<span class="sc">.</span>__class__<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb192-12"><a href="#cb192-12" aria-hidden="true" tabindex="-1"></a>    plot.legend(legends)</span>
<span id="cb192-13"><a href="#cb192-13" aria-hidden="true" tabindex="-1"></a>    plot.title(<span class="st">'gradient distribution'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 1 (      Tanh): mean -0.023409, std 7.497526e-01
layer 3 (      Tanh): mean -0.002852, std 6.864228e-01
layer 5 (      Tanh): mean +0.001338, std 6.732427e-01
layer 7 (      Tanh): mean -0.006005, std 6.569249e-01
layer 9 (      Tanh): mean -0.020739, std 6.626034e-01</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-125-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, output_type<span class="op">=</span><span class="st">'backward'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 1 (      Tanh): mean +0.000010, std 4.205588e-04
layer 3 (      Tanh): mean -0.000003, std 3.991179e-04
layer 5 (      Tanh): mean +0.000003, std 3.743020e-04
layer 7 (      Tanh): mean +0.000015, std 3.290473e-04
layer 9 (      Tanh): mean -0.000014, std 3.054035e-04</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-126-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="only-non-linearities" class="level3">
<h3 class="anchored" data-anchor-id="only-non-linearities">Only Non Linearities</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1</span>, Xtr, Ytr, network_type<span class="op">=</span><span class="st">'linear'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/      1: 3.9508</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, instance_layer<span class="op">=</span>Linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 0 (    Linear): mean -0.026808, std 1.717835e+00
layer 1 (    Linear): mean +0.066778, std 2.721437e+00
layer 2 (    Linear): mean +0.011798, std 4.644542e+00
layer 3 (    Linear): mean +0.402860, std 7.625082e+00
layer 4 (    Linear): mean +0.125483, std 1.243459e+01</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-128-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, instance_layer<span class="op">=</span>Linear, output_type<span class="op">=</span><span class="st">'backward'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 0 (    Linear): mean -0.000040, std 2.520851e-03
layer 1 (    Linear): mean +0.000041, std 1.514516e-03
layer 2 (    Linear): mean +0.000030, std 9.373975e-04
layer 3 (    Linear): mean +0.000000, std 5.414668e-04
layer 4 (    Linear): mean +0.000006, std 3.237360e-04</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-129-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1</span>, Xtr, Ytr, weight_scale <span class="op">=</span> <span class="fl">0.5</span>, network_type<span class="op">=</span><span class="st">'linear'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/      1: 3.2955</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, instance_layer<span class="op">=</span>Linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 0 (    Linear): mean +0.005062, std 5.380081e-01
layer 1 (    Linear): mean +0.003729, std 2.749813e-01
layer 2 (    Linear): mean +0.004225, std 1.427801e-01
layer 3 (    Linear): mean +0.000118, std 7.137968e-02
layer 4 (    Linear): mean -0.000081, std 3.339273e-02</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-131-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, instance_layer<span class="op">=</span>Linear, output_type<span class="op">=</span><span class="st">'backward'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 0 (    Linear): mean -0.000001, std 2.208486e-05
layer 1 (    Linear): mean +0.000000, std 4.229027e-05
layer 2 (    Linear): mean +0.000002, std 8.004090e-05
layer 3 (    Linear): mean +0.000003, std 1.509417e-04
layer 4 (    Linear): mean +0.000007, std 3.050811e-04</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-132-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1</span>, Xtr, Ytr, weight_scale <span class="op">=</span> <span class="dv">1</span>, network_type<span class="op">=</span><span class="st">'linear'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/      1: 3.2962</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, instance_layer<span class="op">=</span>Linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 0 (    Linear): mean -0.033228, std 1.018080e+00
layer 1 (    Linear): mean +0.032009, std 9.739050e-01
layer 2 (    Linear): mean -0.021459, std 9.661991e-01
layer 3 (    Linear): mean -0.006396, std 9.748541e-01
layer 4 (    Linear): mean +0.008816, std 1.019902e+00</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-134-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, instance_layer<span class="op">=</span>Linear, output_type<span class="op">=</span><span class="st">'backward'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 0 (    Linear): mean +0.000011, std 3.135176e-04
layer 1 (    Linear): mean +0.000007, std 3.096962e-04
layer 2 (    Linear): mean -0.000003, std 3.211265e-04
layer 3 (    Linear): mean -0.000011, std 3.192310e-04
layer 4 (    Linear): mean -0.000010, std 3.158194e-04</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-135-output-2.png" class="img-fluid"></p>
</div>
</div>
<section id="grad-data-ratio" class="level4">
<h4 class="anchored" data-anchor-id="grad-data-ratio">grad: data ratio</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1</span>, Xtr, Ytr, weight_scale<span class="op">=</span><span class="dv">1</span>, network_type<span class="op">=</span><span class="st">'linear'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/      1: 3.2988</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_gain_data_ratio(parameters):</span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a>    plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">4</span>))</span>
<span id="cb217-3"><a href="#cb217-3" aria-hidden="true" tabindex="-1"></a>    legends <span class="op">=</span> []</span>
<span id="cb217-4"><a href="#cb217-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(parameters):</span>
<span id="cb217-5"><a href="#cb217-5" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> p.grad</span>
<span id="cb217-6"><a href="#cb217-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p.ndim<span class="op">==</span><span class="dv">2</span>: <span class="co"># excluding bias, gamma, beta</span></span>
<span id="cb217-7"><a href="#cb217-7" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'weight </span><span class="sc">%10s</span><span class="st"> | mean </span><span class="sc">%+f</span><span class="st"> | std </span><span class="sc">%e</span><span class="st"> | grad:data ratio </span><span class="sc">%e</span><span class="st">'</span> <span class="op">%</span>(<span class="bu">tuple</span>(p.shape), t.mean(), t.std(), t.std()<span class="op">/</span>p.std()))</span>
<span id="cb217-8"><a href="#cb217-8" aria-hidden="true" tabindex="-1"></a>            hy, hx <span class="op">=</span> torch.histogram(t, density <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb217-9"><a href="#cb217-9" aria-hidden="true" tabindex="-1"></a>            plot.plot(hx[:<span class="op">-</span><span class="dv">1</span>].detach(), hy.detach())</span>
<span id="cb217-10"><a href="#cb217-10" aria-hidden="true" tabindex="-1"></a>            legends.append(<span class="ss">f'</span><span class="sc">{</span>i<span class="sc">}{</span><span class="bu">tuple</span>(p.shape)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb217-11"><a href="#cb217-11" aria-hidden="true" tabindex="-1"></a>    plot.legend(legends)</span>
<span id="cb217-12"><a href="#cb217-12" aria-hidden="true" tabindex="-1"></a>    plot.title(<span class="st">'Weights gradient distribution'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb218"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a>visualize_gain_data_ratio(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>weight   (27, 10) | mean -0.000028 | std 9.268780e-04 | grad:data ratio 8.800050e-04
weight  (30, 100) | mean -0.000030 | std 1.736440e-03 | grad:data ratio 9.734222e-03
weight (100, 100) | mean -0.000002 | std 1.681667e-03 | grad:data ratio 1.686680e-02
weight (100, 100) | mean +0.000011 | std 1.695616e-03 | grad:data ratio 1.695003e-02
weight (100, 100) | mean -0.000042 | std 1.680904e-03 | grad:data ratio 1.670431e-02
weight (100, 100) | mean -0.000029 | std 1.830903e-03 | grad:data ratio 1.843546e-02
weight  (100, 27) | mean -0.000000 | std 3.505145e-02 | grad:data ratio 3.360777e+00</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-138-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1000</span>, Xtr, Ytr, weight_scale<span class="op">=</span><span class="dv">1</span>, network_type<span class="op">=</span><span class="st">'linear'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/   1000: 3.2966</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>visualize_gain_data_ratio(p)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>weight   (27, 10) | mean +0.001294 | std 1.157769e-02 | grad:data ratio 1.172457e-02
weight  (30, 100) | mean -0.000177 | std 1.309982e-02 | grad:data ratio 7.482659e-02
weight (100, 100) | mean +0.000006 | std 8.080219e-03 | grad:data ratio 8.206636e-02
weight (100, 100) | mean -0.000033 | std 6.700047e-03 | grad:data ratio 7.002961e-02
weight (100, 100) | mean +0.000095 | std 6.837256e-03 | grad:data ratio 7.082513e-02
weight (100, 100) | mean -0.000055 | std 6.807048e-03 | grad:data ratio 7.096651e-02
weight  (100, 27) | mean +0.000000 | std 2.501121e-02 | grad:data ratio 4.598068e-01</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-140-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="data-ratio-over-time" class="level4">
<h4 class="anchored" data-anchor-id="data-ratio-over-time">data ratio over time</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_data_ratio_over_time(parameters, ud):</span>
<span id="cb224-2"><a href="#cb224-2" aria-hidden="true" tabindex="-1"></a>    plot.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">4</span>))</span>
<span id="cb224-3"><a href="#cb224-3" aria-hidden="true" tabindex="-1"></a>    legends <span class="op">=</span> []</span>
<span id="cb224-4"><a href="#cb224-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(parameters):</span>
<span id="cb224-5"><a href="#cb224-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p.ndim <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb224-6"><a href="#cb224-6" aria-hidden="true" tabindex="-1"></a>            plot.plot([ud[j][i] <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ud))])</span>
<span id="cb224-7"><a href="#cb224-7" aria-hidden="true" tabindex="-1"></a>            legends.append(<span class="st">'param </span><span class="sc">%d</span><span class="st">'</span> <span class="op">%</span> i)</span>
<span id="cb224-8"><a href="#cb224-8" aria-hidden="true" tabindex="-1"></a>    plot.plot([<span class="dv">0</span>, <span class="bu">len</span>(ud)], [<span class="op">-</span><span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>], <span class="st">'k'</span>) <span class="co"># these ratios should be ~ 1e-3, indicate on plot</span></span>
<span id="cb224-9"><a href="#cb224-9" aria-hidden="true" tabindex="-1"></a>    plot.legend(legends)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a>visualize_data_ratio_over_time(p, ud)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-142-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb226"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1000</span>, Xtr, Ytr, weight_scale<span class="op">=</span><span class="dv">1</span>, network_type<span class="op">=</span><span class="st">'linear'</span>, learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/   1000: 3.3380</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb228"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a>visualize_data_ratio_over_time(p, ud)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-144-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear:</span>
<span id="cb229-2"><a href="#cb229-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb229-3"><a href="#cb229-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, fan_in, fan_out, bias<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb229-4"><a href="#cb229-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weight <span class="op">=</span> torch.randn((fan_in, fan_out), generator<span class="op">=</span>g) <span class="co">#/ fan_in ** 0.5</span></span>
<span id="cb229-5"><a href="#cb229-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> torch.zeros(fan_out) <span class="cf">if</span> bias <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb229-6"><a href="#cb229-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb229-7"><a href="#cb229-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb229-8"><a href="#cb229-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> x <span class="op">@</span> <span class="va">self</span>.weight</span>
<span id="cb229-9"><a href="#cb229-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb229-10"><a href="#cb229-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.out <span class="op">+=</span> <span class="va">self</span>.bias</span>
<span id="cb229-11"><a href="#cb229-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out</span>
<span id="cb229-12"><a href="#cb229-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb229-13"><a href="#cb229-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parameters(<span class="va">self</span>):</span>
<span id="cb229-14"><a href="#cb229-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="va">self</span>.weight] <span class="op">+</span> ([] <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> [<span class="va">self</span>.bias])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1000</span>, Xtr, Ytr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 46497
      0/   1000: 3.7327</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb232"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a>visualize_data_ratio_over_time(p, ud)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-147-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Linear:</span>
<span id="cb233-2"><a href="#cb233-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb233-3"><a href="#cb233-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, fan_in, fan_out, bias<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb233-4"><a href="#cb233-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weight <span class="op">=</span> torch.randn((fan_in, fan_out), generator<span class="op">=</span>g) <span class="op">/</span> fan_in <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb233-5"><a href="#cb233-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias <span class="op">=</span> torch.zeros(fan_out) <span class="cf">if</span> bias <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb233-6"><a href="#cb233-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb233-7"><a href="#cb233-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb233-8"><a href="#cb233-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out <span class="op">=</span> x <span class="op">@</span> <span class="va">self</span>.weight</span>
<span id="cb233-9"><a href="#cb233-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb233-10"><a href="#cb233-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.out <span class="op">+=</span> <span class="va">self</span>.bias</span>
<span id="cb233-11"><a href="#cb233-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.out</span>
<span id="cb233-12"><a href="#cb233-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb233-13"><a href="#cb233-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> parameters(<span class="va">self</span>):</span>
<span id="cb233-14"><a href="#cb233-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="va">self</span>.weight] <span class="op">+</span> ([] <span class="cf">if</span> <span class="va">self</span>.bias <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> [<span class="va">self</span>.bias])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb234"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1000</span>, Xtr, Ytr, network_type <span class="op">=</span> <span class="st">'batchnorm'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 47551
      0/   1000: 3.3050</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb236"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 2 (      Tanh): mean -0.002824, std 6.360319e-01
layer 5 (      Tanh): mean -0.003577, std 6.418643e-01
layer 8 (      Tanh): mean -0.000634, std 6.393718e-01
layer 11 (      Tanh): mean +0.004614, std 6.429055e-01
layer 14 (      Tanh): mean -0.005592, std 6.441681e-01</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-150-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb238"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, output_type<span class="op">=</span><span class="st">'backward'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 2 (      Tanh): mean +0.000000, std 3.329200e-03
layer 5 (      Tanh): mean +0.000000, std 3.038263e-03
layer 8 (      Tanh): mean -0.000000, std 2.737059e-03
layer 11 (      Tanh): mean +0.000000, std 2.601666e-03
layer 14 (      Tanh): mean -0.000000, std 2.437597e-03</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-151-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb240"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb240-1"><a href="#cb240-1" aria-hidden="true" tabindex="-1"></a>visualize_data_ratio_over_time(p, ud)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-152-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>l, p, li, ud <span class="op">=</span> train(<span class="dv">1000</span>, Xtr, Ytr, weight_scale<span class="op">=</span><span class="fl">0.2</span>, network_type <span class="op">=</span> <span class="st">'batchnorm'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total number of parameters are : 47551
      0/   1000: 3.2990</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb243"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 2 (      Tanh): mean -0.001280, std 6.382423e-01
layer 5 (      Tanh): mean +0.004930, std 6.569912e-01
layer 8 (      Tanh): mean -0.003945, std 6.697033e-01
layer 11 (      Tanh): mean -0.000414, std 6.793090e-01
layer 14 (      Tanh): mean -0.002082, std 6.810060e-01</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-154-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a>visualize_histograms(l, output_type<span class="op">=</span><span class="st">'backward'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>layer 2 (      Tanh): mean -0.000000, std 1.021346e-03
layer 5 (      Tanh): mean -0.000000, std 8.389445e-04
layer 8 (      Tanh): mean +0.000000, std 8.275748e-04
layer 11 (      Tanh): mean +0.000000, std 8.728803e-04
layer 14 (      Tanh): mean +0.000000, std 1.020851e-03</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-155-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb247"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a>visualize_data_ratio_over_time(p, ud)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="04_building_makemore_mlp2_files/figure-html/cell-156-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>