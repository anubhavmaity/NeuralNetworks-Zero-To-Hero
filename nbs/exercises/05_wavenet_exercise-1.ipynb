{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf09f86b",
      "metadata": {
        "id": "bf09f86b"
      },
      "source": [
        "# Wavenet Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "32dd6a19-db09-4a78-9f66-66a416f5cf95",
      "metadata": {
        "id": "32dd6a19-db09-4a78-9f66-66a416f5cf95"
      },
      "outputs": [],
      "source": [
        "# !pip install ray[tune]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c252421",
      "metadata": {
        "id": "9c252421"
      },
      "outputs": [],
      "source": [
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ee0815e2",
      "metadata": {
        "id": "ee0815e2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import random\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e7e1df47-e95f-430f-96c0-12e5c7969860",
      "metadata": {
        "id": "e7e1df47-e95f-430f-96c0-12e5c7969860"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda:0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0ed816f9-a512-42d2-a0dc-f5f0ba0636c6",
      "metadata": {
        "id": "0ed816f9-a512-42d2-a0dc-f5f0ba0636c6",
        "outputId": "04b51a3c-bbe5-4e85-8e34-42b2d3a70444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29f0b5a9",
      "metadata": {
        "id": "29f0b5a9"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5404db14",
      "metadata": {
        "id": "5404db14"
      },
      "outputs": [],
      "source": [
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "BelHa9vXFWzR",
        "outputId": "1cf643e1-1d93-4676-b317-1a4661fdeedd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BelHa9vXFWzR",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca34c512",
      "metadata": {
        "id": "ca34c512"
      },
      "source": [
        "### Setup Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b1b7a5a5",
      "metadata": {
        "id": "b1b7a5a5"
      },
      "outputs": [],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "98d76291",
      "metadata": {
        "id": "98d76291"
      },
      "outputs": [],
      "source": [
        "random.shuffle(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d27e029e",
      "metadata": {
        "id": "d27e029e"
      },
      "outputs": [],
      "source": [
        "def build_dataset(words, block_size=8):\n",
        "    \n",
        "    X, Y = [], []\n",
        "    \n",
        "    random.seed(42)\n",
        "    random.shuffle(words)\n",
        "    \n",
        "    chars = sorted(list(set(''.join(words))))\n",
        "    stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
        "    stoi['.'] = 0\n",
        "    itos = {i: s for s, i in stoi.items()}\n",
        "    vocab_size = len(itos)\n",
        "    \n",
        "    for w in words:\n",
        "        context = [0] * block_size\n",
        "        for ch in w + '.':\n",
        "            ix = stoi[ch]\n",
        "            X.append(context)\n",
        "            Y.append(ix)\n",
        "            context = context[1:] + [ix]\n",
        "    \n",
        "    X = torch.tensor(X).to(device)\n",
        "    Y = torch.tensor(Y).to(device)\n",
        "    return X, Y\n",
        "\n",
        "n1 = int(0.8 * len(words))\n",
        "n2 = int(0.9 * len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3a1f4953",
      "metadata": {
        "id": "3a1f4953",
        "outputId": "05a13099-3bb6-4160-df80-933933d5dfec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([182625, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "Xtr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cabedf8a-25b9-4f90-bac5-fb44546fb38a",
      "metadata": {
        "id": "cabedf8a-25b9-4f90-bac5-fb44546fb38a"
      },
      "source": [
        "### Create Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "11fe3309",
      "metadata": {
        "id": "11fe3309"
      },
      "outputs": [],
      "source": [
        "# --- Flatten Consecutive ---\n",
        "class FlattenConsecutive(nn.Module):\n",
        "    def __init__(self, n):\n",
        "        super().__init__()\n",
        "        self.n = n\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        x = x.reshape(B, T//self.n, C*self.n)\n",
        "        if x.shape[1] == 1: \n",
        "            x = x.squeeze(1)\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "# -- SwapDim ---\n",
        "class SwapDim(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return torch.transpose(x, 1, 2)\n",
        "\n",
        "# -- SwapDimBack -- \n",
        "class SwapDimBack(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return torch.transpose(x, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "24c8868a",
      "metadata": {
        "id": "24c8868a"
      },
      "outputs": [],
      "source": [
        "vocab_size = 27\n",
        "n_embd = 24\n",
        "n_hidden = 128\n",
        "model = nn.Sequential(\n",
        "    nn.Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(2), nn.Linear(n_embd*2, n_hidden, bias=False), SwapDim(), nn.BatchNorm1d(n_hidden), SwapDimBack(), nn.Tanh(),\n",
        "    FlattenConsecutive(2), nn.Linear(n_hidden*2, n_hidden, bias=False), SwapDim(), nn.BatchNorm1d(n_hidden), SwapDimBack(), nn.Tanh(),\n",
        "   FlattenConsecutive(2), nn.Linear(n_hidden*2, n_hidden, bias=False),  nn.BatchNorm1d(n_hidden), nn.Tanh(),\n",
        "#     nn.Linear(n_hidden, vocab_size),\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d74c66b3",
      "metadata": {
        "id": "d74c66b3",
        "outputId": "d7a9c134-cd6d-4cad-f9e5-622135c52ce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  1],\n",
              "         [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "         [ 0,  0,  0,  0,  0, 16,  1, 24],\n",
              "         [ 0,  0,  0,  0,  0,  1,  4, 18]], device='cuda:0'),\n",
              " torch.Size([4, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb, logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a3f11c1e-d7fb-4adc-bd47-dc79d9a5c7e2",
      "metadata": {
        "id": "a3f11c1e-d7fb-4adc-bd47-dc79d9a5c7e2"
      },
      "outputs": [],
      "source": [
        "def build_model(n_embd, # the dimensionality of the character embedding vectors\n",
        "                n_hidden, # the number of neurons in the hidden layer of the MLP \n",
        "                last_layer_factor = 0.1 # the factor by to reduce the weights of the last layer\n",
        "               ):\n",
        "    vocab_size = 27\n",
        "    model = nn.Sequential(\n",
        "    nn.Embedding(vocab_size, n_embd),\n",
        "    FlattenConsecutive(2), nn.Linear(n_embd*2, n_hidden, bias=False), SwapDim(), nn.BatchNorm1d(n_hidden), SwapDimBack(), nn.Tanh(),\n",
        "    FlattenConsecutive(2), nn.Linear(n_hidden*2, n_hidden, bias=False), SwapDim(), nn.BatchNorm1d(n_hidden), SwapDimBack(), nn.Tanh(),\n",
        "   FlattenConsecutive(2), nn.Linear(n_hidden*2, n_hidden, bias=False),  nn.BatchNorm1d(n_hidden), nn.Tanh(),\n",
        "      nn.Linear(n_hidden, vocab_size)\n",
        "    ).to(device)\n",
        "\n",
        "\n",
        "    # parameter init\n",
        "    with torch.no_grad(): model[-1].weight *= last_layer_factor\n",
        "\n",
        "    parameters = model.parameters()\n",
        "    print(\"No of parameters \", sum(p.nelement() for p in parameters))\n",
        "    for p in parameters: p.requires_grad = True\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b57c57b0",
      "metadata": {
        "id": "b57c57b0",
        "outputId": "4e6a0771-9d21-4cea-da30-a055ad0ed16d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of parameters  76579\n"
          ]
        }
      ],
      "source": [
        "model = build_model(24, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "af66e115",
      "metadata": {
        "id": "af66e115",
        "outputId": "760d88f8-139c-40d1-fe8f-be7193770208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  3, 15, 18, 20],\n",
              "        [ 0,  0,  0,  0,  0,  0,  7,  9],\n",
              "        [ 0,  0,  0,  0,  0, 12,  1,  3],\n",
              "        [ 0,  0,  0, 17, 21,  9, 14,  3]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8584dfc0-ce59-4211-85c9-b53fcba9fce5",
      "metadata": {
        "id": "8584dfc0-ce59-4211-85c9-b53fcba9fce5",
        "outputId": "1975e852-0002-47f1-b483-a6d68dd7b6e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c640cf2c-f407-4ead-aaf8-1ade48438d54",
      "metadata": {
        "id": "c640cf2c-f407-4ead-aaf8-1ade48438d54"
      },
      "outputs": [],
      "source": [
        "def train(config, checkpoint_dir=None):\n",
        "    \n",
        "    n_embd = config['n_embd']\n",
        "    n_hidden = config['n_hidden']\n",
        "    last_layer_factor = config['last_layer_factor']\n",
        "    max_steps = config['max_steps'] \n",
        "    lr = config['lr']\n",
        "    batch_size = config['batch_size']\n",
        "    \n",
        "    model = build_model(n_embd, n_hidden, last_layer_factor)\n",
        "\n",
        "    train_loss = F.cross_entropy(model(Xtr), Ytr)\n",
        "    print('Initial loss ', train_loss)\n",
        "    \n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    \n",
        "    lossi = []\n",
        "    \n",
        "    for i in range(max_steps):\n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        # minibatch construct\n",
        "        ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
        "        Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "\n",
        "        logits = model(Xb)\n",
        "        loss = F.cross_entropy(logits, Yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # track stats\n",
        "        if i % 10_000 == 0:\n",
        "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "        lossi.append(loss.log10().item())\n",
        "    \n",
        "        \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "daceac7a-c216-4680-b45a-3c7cbb58caba",
      "metadata": {
        "id": "daceac7a-c216-4680-b45a-3c7cbb58caba"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "        \"n_embd\": 24,\n",
        "        \"n_hidden\": 128,\n",
        "        \"lr\": 0.001,\n",
        "        \"last_layer_factor\": 0.1,\n",
        "        \"batch_size\": 32,\n",
        "        \"max_steps\": 200_000\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4828e4ad-47e6-4770-8460-ec9e358e1809",
      "metadata": {
        "id": "4828e4ad-47e6-4770-8460-ec9e358e1809",
        "outputId": "d243fdb6-facf-488e-a2c7-f2d96fba247a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of parameters  76579\n",
            "Initial loss  tensor(3.2798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "      0/ 200000: 3.2850\n",
            "  10000/ 200000: 1.9604\n",
            "  20000/ 200000: 1.9096\n",
            "  30000/ 200000: 2.1808\n",
            "  40000/ 200000: 1.9603\n",
            "  50000/ 200000: 2.0830\n",
            "  60000/ 200000: 1.9285\n",
            "  70000/ 200000: 1.8355\n",
            "  80000/ 200000: 2.1152\n",
            "  90000/ 200000: 1.7333\n",
            " 100000/ 200000: 2.5383\n",
            " 110000/ 200000: 2.5408\n",
            " 120000/ 200000: 1.7806\n",
            " 130000/ 200000: 1.5074\n",
            " 140000/ 200000: 2.2836\n",
            " 150000/ 200000: 2.1666\n",
            " 160000/ 200000: 2.0499\n",
            " 170000/ 200000: 2.4158\n",
            " 180000/ 200000: 1.8051\n",
            " 190000/ 200000: 1.6264\n"
          ]
        }
      ],
      "source": [
        "m = train(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "43c67352-0081-47f5-94fa-aaabd02aca8c",
      "metadata": {
        "id": "43c67352-0081-47f5-94fa-aaabd02aca8c",
        "outputId": "5137032b-1a39-4921-dd60-0aae482292d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3831,  5.9946, -0.4334, -3.1496, -1.0150,  3.1747, -3.4749, -3.2213,\n",
              "          0.9639,  2.5345, -2.5072, -4.6121, -2.3915, -1.1776, -1.0199,  4.6581,\n",
              "         -2.2405, -5.6197,  1.3689, -1.8678, -2.7871,  1.0448, -3.2367, -4.8778,\n",
              "         -4.8898,  1.1356, -0.6535],\n",
              "        [-1.8927, -1.4403, -2.6883,  2.1526,  0.8893, -1.0265, -1.4148,  0.8529,\n",
              "          1.6819, -2.4304,  1.2136,  3.3855,  1.9102,  1.1939,  1.9362, -3.9292,\n",
              "         -0.9157, -0.2079,  1.1477,  1.5550,  0.8729, -2.7374,  0.1523,  0.2212,\n",
              "         -0.3517, -0.8675, -0.6843],\n",
              "        [-1.8927, -1.4403, -2.6883,  2.1526,  0.8893, -1.0265, -1.4148,  0.8529,\n",
              "          1.6819, -2.4304,  1.2136,  3.3855,  1.9102,  1.1939,  1.9362, -3.9292,\n",
              "         -0.9157, -0.2079,  1.1477,  1.5550,  0.8729, -2.7374,  0.1523,  0.2212,\n",
              "         -0.3517, -0.8675, -0.6843],\n",
              "        [ 4.3652,  1.3847,  0.9043, -2.2867,  0.5967,  2.3756, -3.3935, -2.3518,\n",
              "         -3.2263,  2.7976, -4.1615, -2.9255,  0.9531, -1.9894, -1.8476,  0.9243,\n",
              "         -3.5244, -4.1242, -1.3296,  1.9078,  1.0783, -0.3561, -1.0896, -1.9243,\n",
              "         -2.5875,  0.5664, -3.5556]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
        "Xb, Yb = Xtr[ix], Ytr[ix]\n",
        "logits = m(Xb)\n",
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3b263806-b786-49ba-8253-1d688b06f08b",
      "metadata": {
        "id": "3b263806-b786-49ba-8253-1d688b06f08b",
        "outputId": "64127988-380f-42c6-b5f0-3d50bf3407c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.86216139793396 2.0197317600250244\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    train_loss = F.cross_entropy(m(Xtr), Ytr).item() \n",
        "    val_loss = F.cross_entropy(m(Xdev), Ydev).item()\n",
        "    print(train_loss, val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c003f9d",
      "metadata": {
        "id": "6c003f9d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "zhnn",
      "language": "python",
      "name": "zhnn"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}