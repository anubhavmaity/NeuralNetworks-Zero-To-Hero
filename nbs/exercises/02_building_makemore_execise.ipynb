{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05880f23",
   "metadata": {},
   "source": [
    "# Building makemore exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c427c8ba",
   "metadata": {},
   "source": [
    "## E01\n",
    "> Train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae4c6c",
   "metadata": {},
   "source": [
    "### Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f799f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7372178",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4631f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/names.txt') as f:\n",
    "    words = list(map(lambda x: x.strip(), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "946703a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['emma',\n",
       "  'olivia',\n",
       "  'ava',\n",
       "  'isabella',\n",
       "  'sophia',\n",
       "  'charlotte',\n",
       "  'mia',\n",
       "  'amelia',\n",
       "  'harper',\n",
       "  'evelyn'],\n",
       " 32033)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10], len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5a470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tripling(words):\n",
    "    for w in words:\n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            yield ch1, ch2, ch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68b8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = '.abcdefghijklmnopqrstuvwxyz'\n",
    "stoi = {char: alphabets.index(char) for char in alphabets}\n",
    "itos = dict(map(reversed, stoi.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cefa088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e m\n",
      "e m m\n",
      "m m a\n",
      "m a .\n",
      ". o l\n",
      "o l i\n",
      "l i v\n",
      "i v i\n",
      "v i a\n",
      "i a .\n",
      ". a v\n",
      "a v a\n",
      "v a .\n"
     ]
    }
   ],
   "source": [
    "for ch1, ch2, ch3 in generate_tripling(words[:3]): print(ch1, ch2, ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e187a330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for ch1, ch2, ch3 in generate_tripling(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b6598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tripling_counter(words):\n",
    "    tripling_counter = Counter()\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        tripling_counter[(ch1, ch2, ch3)] += 1\n",
    "    return tripling_counter    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d5467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'h', '.'), 1714),\n",
       " (('n', 'a', '.'), 1673),\n",
       " (('a', 'n', '.'), 1509),\n",
       " (('o', 'n', '.'), 1503),\n",
       " (('.', 'm', 'a'), 1453),\n",
       " (('.', 'j', 'a'), 1255),\n",
       " (('.', 'k', 'a'), 1254),\n",
       " (('e', 'n', '.'), 1217),\n",
       " (('l', 'y', 'n'), 976),\n",
       " (('y', 'n', '.'), 953)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripling_counter = generate_tripling_counter(words)\n",
    "tripling_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0da84c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6037"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tripling_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48147548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix():\n",
    "    N = torch.zeros((27, 27, 27), dtype=torch.int32)\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        N[ix1, ix2, ix3] += 1\n",
    "    return N  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bd4471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = create_matrix(); N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d7c5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1714, dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[1, 8, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74f7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P = P/P.sum(-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a286139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tripling_prob(words):\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        prob = P[ix1, ix2, ix3]\n",
    "        yield ch1, ch2, ch3, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f5201fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e m tensor(0.1855)\n",
      "e m m tensor(0.1269)\n",
      "m m a tensor(0.3744)\n",
      "m a . tensor(0.0669)\n",
      ". o l tensor(0.2494)\n",
      "o l i tensor(0.1084)\n",
      "l i v tensor(0.0219)\n",
      "i v i tensor(0.2669)\n",
      "v i a tensor(0.1578)\n",
      "i a . tensor(0.3657)\n",
      ". a v tensor(0.0550)\n",
      "a v a tensor(0.1882)\n",
      "v a . tensor(0.1405)\n"
     ]
    }
   ],
   "source": [
    "for ch1, ch2, ch3, prob in generate_tripling_prob(words[:3]): \n",
    "    print(ch1, ch2, ch3, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "911d6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_names(count, P):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    for i in range(count):\n",
    "        out = []\n",
    "        ix1, ix2 = 0, 0\n",
    "        while True:\n",
    "            p = P[ix1, ix2]\n",
    "            ix1 = ix2\n",
    "            ix2 = torch.multinomial(p, num_samples = 1, replacement = True).item()\n",
    "            out.append(itos[ix2])\n",
    "            if ix2 == 0:\n",
    "                break\n",
    "        yield ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd68a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bryemoxoniqqiibaireolist.\n",
      "ennovayledilase.\n",
      "olform.\n",
      "fa.\n",
      "ottias.\n"
     ]
    }
   ],
   "source": [
    "for name in generate_names(5, P): print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffbc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(words):\n",
    "    sum_log = 0\n",
    "    count = 0\n",
    "    for ch1, ch2, ch3, prob in generate_tripling_prob(words):\n",
    "        sum_log += torch.log(prob)\n",
    "        count += 1\n",
    "    return sum_log/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "303fdbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "448e2f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.0927)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002465a",
   "metadata": {},
   "source": [
    "negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "599b6f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0927)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- log_likelihood(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393714c",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a57a25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_set(words):\n",
    "    xs1 = []\n",
    "    xs2 = []\n",
    "    ys = []\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs1.append(ix1)\n",
    "        xs2.append(ix2)\n",
    "        ys.append(ix3)\n",
    "    xs1 = torch.tensor(xs1)\n",
    "    xs2 = torch.tensor(xs2)\n",
    "    xs = torch.vstack((xs1, xs2)).permute(1, 0)\n",
    "    ys = torch.tensor(ys)\n",
    "    return xs, ys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc611c11",
   "metadata": {},
   "source": [
    "#### Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "861e9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = generate_training_set(words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21479578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28a67e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5ba6b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0d21a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb6cb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc_flattened = xenc.view(4, -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5408eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4784, -0.0288,  0.9226,  ..., -0.2990, -1.4303,  1.3789],\n",
       "        [ 0.5463, -0.0881,  0.5297,  ...,  0.2599,  0.6881, -0.2659],\n",
       "        [ 1.2698,  1.2695,  0.3575,  ..., -0.8792, -0.0050, -0.0139],\n",
       "        ...,\n",
       "        [-0.9656, -0.4642, -0.8045,  ..., -0.1527,  1.3452,  0.1447],\n",
       "        [-0.3415,  0.3170, -1.6429,  ..., -1.5612, -0.4946, -1.3341],\n",
       "        [-0.2823,  2.7903,  1.6254,  ..., -0.5698,  0.9835, -0.7987]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27*2, 27))\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b75c0f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xenc_flattened @ W # log counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cff7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a3a21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts/counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0eb6f9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3065f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13,  1,  0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "754b316b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0590), tensor(0.0087), tensor(0.0375), tensor(0.0484))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0, 13], prob[1, 13], prob[2, 1], prob[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08016216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4730)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-prob[torch.arange(4), ys].log().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bb6c1",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4034548",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = generate_training_set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b509975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27)\n",
    "xenc_flattened = xenc.view(len(xenc), -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49bed484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_flattened.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2bd853cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196113, 54]), torch.Size([196113]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_flattened.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "059cb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs, lr):\n",
    "    num = X.shape[0]\n",
    "    print(num)\n",
    "    W = torch.randn((54, 27), requires_grad=True)\n",
    "    for i in range(epochs):\n",
    "        logits = X @ W\n",
    "        counts = logits.exp()\n",
    "        prob = counts/counts.sum(1, keepdims=True)\n",
    "        loss = -prob[torch.arange(num), y].log().mean()\n",
    "        print(f'Epoch {i} Loss {loss}')\n",
    "        \n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "        W.data += -lr * W.grad \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7ad4b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_flattened.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b05162c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196113\n",
      "Epoch 0 Loss 4.2755351066589355\n",
      "Epoch 1 Loss 3.4453465938568115\n",
      "Epoch 2 Loss 3.105201482772827\n",
      "Epoch 3 Loss 2.9067018032073975\n",
      "Epoch 4 Loss 2.7822177410125732\n",
      "Epoch 5 Loss 2.697117805480957\n",
      "Epoch 6 Loss 2.6361849308013916\n",
      "Epoch 7 Loss 2.590273141860962\n",
      "Epoch 8 Loss 2.554192066192627\n",
      "Epoch 9 Loss 2.524949550628662\n",
      "Epoch 10 Loss 2.500777244567871\n",
      "Epoch 11 Loss 2.480471134185791\n",
      "Epoch 12 Loss 2.4631757736206055\n",
      "Epoch 13 Loss 2.448251724243164\n",
      "Epoch 14 Loss 2.4352245330810547\n",
      "Epoch 15 Loss 2.423734426498413\n",
      "Epoch 16 Loss 2.413508176803589\n",
      "Epoch 17 Loss 2.4043331146240234\n",
      "Epoch 18 Loss 2.396044969558716\n",
      "Epoch 19 Loss 2.388511896133423\n",
      "Epoch 20 Loss 2.3816282749176025\n",
      "Epoch 21 Loss 2.375307321548462\n",
      "Epoch 22 Loss 2.369478940963745\n",
      "Epoch 23 Loss 2.364084005355835\n",
      "Epoch 24 Loss 2.3590734004974365\n",
      "Epoch 25 Loss 2.3544061183929443\n",
      "Epoch 26 Loss 2.3500466346740723\n",
      "Epoch 27 Loss 2.3459651470184326\n",
      "Epoch 28 Loss 2.3421366214752197\n",
      "Epoch 29 Loss 2.3385379314422607\n",
      "Epoch 30 Loss 2.3351502418518066\n",
      "Epoch 31 Loss 2.331956624984741\n",
      "Epoch 32 Loss 2.328941583633423\n",
      "Epoch 33 Loss 2.326092481613159\n",
      "Epoch 34 Loss 2.323397159576416\n",
      "Epoch 35 Loss 2.320844888687134\n",
      "Epoch 36 Loss 2.3184263706207275\n",
      "Epoch 37 Loss 2.316132068634033\n",
      "Epoch 38 Loss 2.3139538764953613\n",
      "Epoch 39 Loss 2.311884880065918\n",
      "Epoch 40 Loss 2.309917449951172\n",
      "Epoch 41 Loss 2.3080451488494873\n",
      "Epoch 42 Loss 2.306262254714966\n",
      "Epoch 43 Loss 2.304562568664551\n",
      "Epoch 44 Loss 2.302940845489502\n",
      "Epoch 45 Loss 2.301391839981079\n",
      "Epoch 46 Loss 2.2999110221862793\n",
      "Epoch 47 Loss 2.298494338989258\n",
      "Epoch 48 Loss 2.2971370220184326\n",
      "Epoch 49 Loss 2.2958359718322754\n",
      "Epoch 50 Loss 2.2945871353149414\n",
      "Epoch 51 Loss 2.293386936187744\n",
      "Epoch 52 Loss 2.29223370552063\n",
      "Epoch 53 Loss 2.291123390197754\n",
      "Epoch 54 Loss 2.2900538444519043\n",
      "Epoch 55 Loss 2.28902268409729\n",
      "Epoch 56 Loss 2.2880280017852783\n",
      "Epoch 57 Loss 2.2870676517486572\n",
      "Epoch 58 Loss 2.286139488220215\n",
      "Epoch 59 Loss 2.2852418422698975\n",
      "Epoch 60 Loss 2.2843739986419678\n",
      "Epoch 61 Loss 2.2835335731506348\n",
      "Epoch 62 Loss 2.282719612121582\n",
      "Epoch 63 Loss 2.281930685043335\n",
      "Epoch 64 Loss 2.2811660766601562\n",
      "Epoch 65 Loss 2.280423879623413\n",
      "Epoch 66 Loss 2.2797036170959473\n",
      "Epoch 67 Loss 2.2790040969848633\n",
      "Epoch 68 Loss 2.278325080871582\n",
      "Epoch 69 Loss 2.277665138244629\n",
      "Epoch 70 Loss 2.2770235538482666\n",
      "Epoch 71 Loss 2.276399612426758\n",
      "Epoch 72 Loss 2.2757925987243652\n",
      "Epoch 73 Loss 2.2752020359039307\n",
      "Epoch 74 Loss 2.2746269702911377\n",
      "Epoch 75 Loss 2.274066686630249\n",
      "Epoch 76 Loss 2.2735214233398438\n",
      "Epoch 77 Loss 2.2729897499084473\n",
      "Epoch 78 Loss 2.2724716663360596\n",
      "Epoch 79 Loss 2.2719666957855225\n",
      "Epoch 80 Loss 2.2714738845825195\n",
      "Epoch 81 Loss 2.270993709564209\n",
      "Epoch 82 Loss 2.270524501800537\n",
      "Epoch 83 Loss 2.270066976547241\n",
      "Epoch 84 Loss 2.269620180130005\n",
      "Epoch 85 Loss 2.269183874130249\n",
      "Epoch 86 Loss 2.2687575817108154\n",
      "Epoch 87 Loss 2.268341064453125\n",
      "Epoch 88 Loss 2.2679343223571777\n",
      "Epoch 89 Loss 2.2675364017486572\n",
      "Epoch 90 Loss 2.267148017883301\n",
      "Epoch 91 Loss 2.2667675018310547\n",
      "Epoch 92 Loss 2.2663955688476562\n",
      "Epoch 93 Loss 2.2660319805145264\n",
      "Epoch 94 Loss 2.2656760215759277\n",
      "Epoch 95 Loss 2.2653274536132812\n",
      "Epoch 96 Loss 2.264986276626587\n",
      "Epoch 97 Loss 2.2646522521972656\n",
      "Epoch 98 Loss 2.2643253803253174\n",
      "Epoch 99 Loss 2.264004945755005\n"
     ]
    }
   ],
   "source": [
    "model = train(xenc_flattened, ys, 100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598424b",
   "metadata": {},
   "source": [
    "Here the loss is less, it is an improve over bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d86e5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(torch.tensor([0, 0]), num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb589b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 27])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0e525",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "778af19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words():\n",
    "    for i in range(5):\n",
    "        out = []\n",
    "        ix1, ix2 = 0, 0\n",
    "        while True:\n",
    "            xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
    "            xenc_flattened = xenc.view(1, -1)\n",
    "            logits = xenc_flattened @ model # predict log-counts\n",
    "            counts = logits.exp()\n",
    "            p = counts/counts.sum(1, keepdims=True)\n",
    "            ix1 = ix2\n",
    "            ix2 = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "            out.append(itos[ix2])\n",
    "            if ix2 == 0:\n",
    "                break\n",
    "        print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6759b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "san.\n",
      "udany.\n",
      "arie.\n",
      "en.\n",
      "dansiy.\n"
     ]
    }
   ],
   "source": [
    "generate_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a098d",
   "metadata": {},
   "source": [
    "## E02\n",
    "> split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8ec6ace4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_flattened.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f290a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zhnn)",
   "language": "python",
   "name": "zhnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
