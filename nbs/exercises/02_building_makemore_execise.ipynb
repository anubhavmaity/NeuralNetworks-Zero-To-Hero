{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05880f23",
   "metadata": {},
   "source": [
    "# Building makemore exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5106440",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b149621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68f05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c427c8ba",
   "metadata": {},
   "source": [
    "## E01\n",
    "> Train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae4c6c",
   "metadata": {},
   "source": [
    "### Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7372178",
   "metadata": {},
   "source": [
    "Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4631f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/names.txt') as f:\n",
    "    words = list(map(lambda x: x.strip(), f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946703a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['emma',\n",
       "  'olivia',\n",
       "  'ava',\n",
       "  'isabella',\n",
       "  'sophia',\n",
       "  'charlotte',\n",
       "  'mia',\n",
       "  'amelia',\n",
       "  'harper',\n",
       "  'evelyn'],\n",
       " 32033)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10], len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5a470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tripling(words):\n",
    "    for w in words:\n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            yield ch1, ch2, ch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68b8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = '.abcdefghijklmnopqrstuvwxyz'\n",
    "stoi = {char: alphabets.index(char) for char in alphabets}\n",
    "itos = dict(map(reversed, stoi.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cefa088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e m\n",
      "e m m\n",
      "m m a\n",
      "m a .\n",
      ". o l\n",
      "o l i\n",
      "l i v\n",
      "i v i\n",
      "v i a\n",
      "i a .\n",
      ". a v\n",
      "a v a\n",
      "v a .\n"
     ]
    }
   ],
   "source": [
    "for ch1, ch2, ch3 in generate_tripling(words[:3]): print(ch1, ch2, ch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e187a330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for ch1, ch2, ch3 in generate_tripling(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b6598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tripling_counter(words):\n",
    "    tripling_counter = Counter()\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        tripling_counter[(ch1, ch2, ch3)] += 1\n",
    "    return tripling_counter    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54d5467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'h', '.'), 1714),\n",
       " (('n', 'a', '.'), 1673),\n",
       " (('a', 'n', '.'), 1509),\n",
       " (('o', 'n', '.'), 1503),\n",
       " (('.', 'm', 'a'), 1453),\n",
       " (('.', 'j', 'a'), 1255),\n",
       " (('.', 'k', 'a'), 1254),\n",
       " (('e', 'n', '.'), 1217),\n",
       " (('l', 'y', 'n'), 976),\n",
       " (('y', 'n', '.'), 953)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripling_counter = generate_tripling_counter(words)\n",
    "tripling_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da84c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6037"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tripling_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48147548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix():\n",
    "    N = torch.zeros((27, 27, 27), dtype=torch.int32)\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        N[ix1, ix2, ix3] += 1\n",
    "    return N  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26bd4471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = create_matrix(); N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d7c5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1714, dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[1, 8, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d74f7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P = P/P.sum(-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a286139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tripling_prob(words):\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        prob = P[ix1, ix2, ix3]\n",
    "        yield ch1, ch2, ch3, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5201fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e m tensor(0.1855)\n",
      "e m m tensor(0.1269)\n",
      "m m a tensor(0.3744)\n",
      "m a . tensor(0.0669)\n",
      ". o l tensor(0.2494)\n",
      "o l i tensor(0.1084)\n",
      "l i v tensor(0.0219)\n",
      "i v i tensor(0.2669)\n",
      "v i a tensor(0.1578)\n",
      "i a . tensor(0.3657)\n",
      ". a v tensor(0.0550)\n",
      "a v a tensor(0.1882)\n",
      "v a . tensor(0.1405)\n"
     ]
    }
   ],
   "source": [
    "for ch1, ch2, ch3, prob in generate_tripling_prob(words[:3]): \n",
    "    print(ch1, ch2, ch3, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "911d6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_names(count, P):\n",
    "    g = torch.Generator().manual_seed(2147483647)\n",
    "    for i in range(count):\n",
    "        out = []\n",
    "        ix1, ix2 = 0, 0\n",
    "        while True:\n",
    "            p = P[ix1, ix2]\n",
    "            ix1 = ix2\n",
    "            ix2 = torch.multinomial(p, num_samples = 1, replacement = True, generator=g).item()\n",
    "            out.append(itos[ix2])\n",
    "            if ix2 == 0:\n",
    "                break\n",
    "        yield ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd68a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quia.\n",
      "yu.\n",
      "quinslyntien.\n",
      "nolliahi.\n",
      "ha.\n"
     ]
    }
   ],
   "source": [
    "for name in generate_names(5, P): print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ffbc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(words):\n",
    "    sum_log = 0\n",
    "    count = 0\n",
    "    for ch1, ch2, ch3, prob in generate_tripling_prob(words):\n",
    "        sum_log += torch.log(prob)\n",
    "        count += 1\n",
    "    return sum_log/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "303fdbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448e2f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.0927)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002465a",
   "metadata": {},
   "source": [
    "negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "599b6f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0927)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- log_likelihood(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393714c",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a57a25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_set(words):\n",
    "    xs1 = []\n",
    "    xs2 = []\n",
    "    ys = []\n",
    "    for ch1, ch2, ch3 in generate_tripling(words):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs1.append(ix1)\n",
    "        xs2.append(ix2)\n",
    "        ys.append(ix3)\n",
    "    xs1 = torch.tensor(xs1)\n",
    "    xs2 = torch.tensor(xs2)\n",
    "    xs = torch.vstack((xs1, xs2)).permute(1, 0)\n",
    "    ys = torch.tensor(ys)\n",
    "    return xs, ys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc611c11",
   "metadata": {},
   "source": [
    "#### Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "861e9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = generate_training_set(words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21479578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28a67e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5ba6b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 27])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0d21a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb6cb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc_flattened = xenc.view(4, -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5408eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5674, -0.2373, -0.0274,  ..., -0.0707,  2.4968,  2.4448],\n",
       "        [-0.6701, -1.2199,  0.3031,  ...,  0.8032,  0.5411, -1.1646],\n",
       "        [ 0.1476, -1.0006,  0.3801,  ..., -0.6279,  0.0770, -1.1641],\n",
       "        ...,\n",
       "        [ 0.5283, -0.9056, -0.0124,  ..., -0.9310, -0.0919,  0.1651],\n",
       "        [-0.7125,  0.6541,  0.8071,  ..., -1.1854,  1.0008,  0.9374],\n",
       "        [-0.2512, -0.8699,  0.5397,  ...,  0.0908, -0.4618, -0.8567]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27*2, 27), generator=g)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75c0f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = xenc_flattened @ W # log counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cff7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a3a21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts/counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eb6f9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3065f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13,  1,  0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "754b316b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0240), tensor(0.0074), tensor(0.0417), tensor(0.0104))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0, 13], prob[1, 13], prob[2, 1], prob[3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08016216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0953)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-prob[torch.arange(4), ys].log().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bb6c1",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4034548",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = generate_training_set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8f345df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  5],\n",
       "         [ 5, 13],\n",
       "         [13, 13],\n",
       "         ...,\n",
       "         [26, 25],\n",
       "         [25, 26],\n",
       "         [26, 24]]),\n",
       " tensor([13, 13,  1,  ..., 26, 24,  0]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b509975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27)\n",
    "xenc_flattened = xenc.view(len(xenc), -1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49bed484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_flattened.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bd853cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196113, 54]), torch.Size([196113]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_flattened.shape, ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "059cb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs, lr):\n",
    "    num = X.shape[0]\n",
    "    print(num)\n",
    "    W = torch.randn((54, 27), requires_grad=True, generator=g)\n",
    "    for i in range(epochs):\n",
    "        logits = X @ W\n",
    "        counts = logits.exp()\n",
    "        prob = counts/counts.sum(1, keepdims=True)\n",
    "        loss = -prob[torch.arange(num), y].log().mean()\n",
    "        print(f'Epoch {i} Loss {loss}')\n",
    "        \n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "        W.data += -lr * W.grad \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ad4b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_flattened.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b05162c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196113\n",
      "Epoch 0 Loss 4.278286457061768\n",
      "Epoch 1 Loss 3.480670690536499\n",
      "Epoch 2 Loss 3.124514102935791\n",
      "Epoch 3 Loss 2.9295425415039062\n",
      "Epoch 4 Loss 2.803150177001953\n",
      "Epoch 5 Loss 2.7155046463012695\n",
      "Epoch 6 Loss 2.6521811485290527\n",
      "Epoch 7 Loss 2.604522228240967\n",
      "Epoch 8 Loss 2.5672547817230225\n",
      "Epoch 9 Loss 2.5370802879333496\n",
      "Epoch 10 Loss 2.511944532394409\n",
      "Epoch 11 Loss 2.4905476570129395\n",
      "Epoch 12 Loss 2.4720511436462402\n",
      "Epoch 13 Loss 2.455875873565674\n",
      "Epoch 14 Loss 2.4416065216064453\n",
      "Epoch 15 Loss 2.4289278984069824\n",
      "Epoch 16 Loss 2.4175968170166016\n",
      "Epoch 17 Loss 2.407419204711914\n",
      "Epoch 18 Loss 2.398238182067871\n",
      "Epoch 19 Loss 2.3899240493774414\n",
      "Epoch 20 Loss 2.3823699951171875\n",
      "Epoch 21 Loss 2.3754842281341553\n",
      "Epoch 22 Loss 2.3691892623901367\n",
      "Epoch 23 Loss 2.3634181022644043\n",
      "Epoch 24 Loss 2.3581130504608154\n",
      "Epoch 25 Loss 2.3532233238220215\n",
      "Epoch 26 Loss 2.3487045764923096\n",
      "Epoch 27 Loss 2.3445184230804443\n",
      "Epoch 28 Loss 2.3406310081481934\n",
      "Epoch 29 Loss 2.3370120525360107\n",
      "Epoch 30 Loss 2.3336353302001953\n",
      "Epoch 31 Loss 2.3304781913757324\n",
      "Epoch 32 Loss 2.327519655227661\n",
      "Epoch 33 Loss 2.324742078781128\n",
      "Epoch 34 Loss 2.322129249572754\n",
      "Epoch 35 Loss 2.319667100906372\n",
      "Epoch 36 Loss 2.317342519760132\n",
      "Epoch 37 Loss 2.315145254135132\n",
      "Epoch 38 Loss 2.313063859939575\n",
      "Epoch 39 Loss 2.311089515686035\n",
      "Epoch 40 Loss 2.3092143535614014\n",
      "Epoch 41 Loss 2.307431221008301\n",
      "Epoch 42 Loss 2.3057329654693604\n",
      "Epoch 43 Loss 2.3041131496429443\n",
      "Epoch 44 Loss 2.3025670051574707\n",
      "Epoch 45 Loss 2.301089286804199\n",
      "Epoch 46 Loss 2.299675226211548\n",
      "Epoch 47 Loss 2.298321008682251\n",
      "Epoch 48 Loss 2.297022581100464\n",
      "Epoch 49 Loss 2.295776605606079\n",
      "Epoch 50 Loss 2.2945797443389893\n",
      "Epoch 51 Loss 2.293429136276245\n",
      "Epoch 52 Loss 2.2923221588134766\n",
      "Epoch 53 Loss 2.2912561893463135\n",
      "Epoch 54 Loss 2.290228843688965\n",
      "Epoch 55 Loss 2.289238452911377\n",
      "Epoch 56 Loss 2.288282632827759\n",
      "Epoch 57 Loss 2.2873594760894775\n",
      "Epoch 58 Loss 2.2864675521850586\n",
      "Epoch 59 Loss 2.2856051921844482\n",
      "Epoch 60 Loss 2.284771203994751\n",
      "Epoch 61 Loss 2.283963918685913\n",
      "Epoch 62 Loss 2.283182144165039\n",
      "Epoch 63 Loss 2.2824244499206543\n",
      "Epoch 64 Loss 2.2816898822784424\n",
      "Epoch 65 Loss 2.280977487564087\n",
      "Epoch 66 Loss 2.2802860736846924\n",
      "Epoch 67 Loss 2.2796149253845215\n",
      "Epoch 68 Loss 2.2789628505706787\n",
      "Epoch 69 Loss 2.278329372406006\n",
      "Epoch 70 Loss 2.2777135372161865\n",
      "Epoch 71 Loss 2.2771143913269043\n",
      "Epoch 72 Loss 2.27653169631958\n",
      "Epoch 73 Loss 2.2759647369384766\n",
      "Epoch 74 Loss 2.2754125595092773\n",
      "Epoch 75 Loss 2.274874687194824\n",
      "Epoch 76 Loss 2.27435040473938\n",
      "Epoch 77 Loss 2.2738397121429443\n",
      "Epoch 78 Loss 2.273341655731201\n",
      "Epoch 79 Loss 2.2728559970855713\n",
      "Epoch 80 Loss 2.2723817825317383\n",
      "Epoch 81 Loss 2.271919012069702\n",
      "Epoch 82 Loss 2.2714672088623047\n",
      "Epoch 83 Loss 2.271026372909546\n",
      "Epoch 84 Loss 2.2705953121185303\n",
      "Epoch 85 Loss 2.270174026489258\n",
      "Epoch 86 Loss 2.2697625160217285\n",
      "Epoch 87 Loss 2.269359827041626\n",
      "Epoch 88 Loss 2.2689664363861084\n",
      "Epoch 89 Loss 2.2685811519622803\n",
      "Epoch 90 Loss 2.2682044506073\n",
      "Epoch 91 Loss 2.2678356170654297\n",
      "Epoch 92 Loss 2.267474412918091\n",
      "Epoch 93 Loss 2.267120838165283\n",
      "Epoch 94 Loss 2.2667741775512695\n",
      "Epoch 95 Loss 2.266435146331787\n",
      "Epoch 96 Loss 2.2661023139953613\n",
      "Epoch 97 Loss 2.2657763957977295\n",
      "Epoch 98 Loss 2.2654569149017334\n",
      "Epoch 99 Loss 2.265143632888794\n"
     ]
    }
   ],
   "source": [
    "model = train(xenc_flattened, ys, 100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598424b",
   "metadata": {},
   "source": [
    "Here the loss is less, it is an improve over bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d86e5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(torch.tensor([0, 0]), num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb589b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 27])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0e525",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "778af19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words():\n",
    "    for i in range(5):\n",
    "        out = []\n",
    "        ix1, ix2 = 0, 0\n",
    "        while True:\n",
    "            xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
    "            xenc_flattened = xenc.view(1, -1)\n",
    "            logits = xenc_flattened @ model # predict log-counts\n",
    "            counts = logits.exp()\n",
    "            p = counts/counts.sum(1, keepdims=True)\n",
    "            ix1 = ix2\n",
    "            ix2 = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "            out.append(itos[ix2])\n",
    "            if ix2 == 0:\n",
    "                break\n",
    "        print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6759b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyne.\n",
      "ou.\n",
      "surie.\n",
      "ainn.\n",
      "iass.\n"
     ]
    }
   ],
   "source": [
    "generate_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a098d",
   "metadata": {},
   "source": [
    "## E02\n",
    "> split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ec6ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc_num = xenc_flattened.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb0f6758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 196113)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(xenc_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6036972",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subset, valid_subset, train_subset = random_split(range(xenc_num), [0.1, 0.1, 0.8], \n",
    "                          generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc5f290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = torch.tensor(train_subset)\n",
    "valid_idx = torch.tensor(valid_subset)\n",
    "test_idx = torch.tensor(test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "933cdac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([156890]), torch.Size([19611]), torch.Size([19612]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx.shape, valid_idx.shape, test_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d848c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = xenc_flattened[train_idx], ys[train_idx]\n",
    "x_valid, y_valid = xenc_flattened[valid_idx], ys[valid_idx]\n",
    "x_test, y_test = xenc_flattened[test_idx], ys[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43328adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156890\n",
      "Epoch 0 Loss 4.1095499992370605\n",
      "Epoch 1 Loss 3.914874315261841\n",
      "Epoch 2 Loss 3.7504496574401855\n",
      "Epoch 3 Loss 3.611818313598633\n",
      "Epoch 4 Loss 3.494288206100464\n",
      "Epoch 5 Loss 3.393850088119507\n",
      "Epoch 6 Loss 3.307448387145996\n",
      "Epoch 7 Loss 3.2327330112457275\n",
      "Epoch 8 Loss 3.167773485183716\n",
      "Epoch 9 Loss 3.110938310623169\n",
      "Epoch 10 Loss 3.0608606338500977\n",
      "Epoch 11 Loss 3.0164265632629395\n",
      "Epoch 12 Loss 2.9767415523529053\n",
      "Epoch 13 Loss 2.9410929679870605\n",
      "Epoch 14 Loss 2.908905506134033\n",
      "Epoch 15 Loss 2.8797104358673096\n",
      "Epoch 16 Loss 2.8531150817871094\n",
      "Epoch 17 Loss 2.8287878036499023\n",
      "Epoch 18 Loss 2.8064448833465576\n",
      "Epoch 19 Loss 2.7858426570892334\n",
      "Epoch 20 Loss 2.766771078109741\n",
      "Epoch 21 Loss 2.7490503787994385\n",
      "Epoch 22 Loss 2.7325260639190674\n",
      "Epoch 23 Loss 2.717067003250122\n",
      "Epoch 24 Loss 2.7025599479675293\n",
      "Epoch 25 Loss 2.6889100074768066\n",
      "Epoch 26 Loss 2.6760339736938477\n",
      "Epoch 27 Loss 2.6638612747192383\n",
      "Epoch 28 Loss 2.6523303985595703\n",
      "Epoch 29 Loss 2.641388177871704\n",
      "Epoch 30 Loss 2.6309874057769775\n",
      "Epoch 31 Loss 2.621086835861206\n",
      "Epoch 32 Loss 2.611649990081787\n",
      "Epoch 33 Loss 2.602644205093384\n",
      "Epoch 34 Loss 2.5940401554107666\n",
      "Epoch 35 Loss 2.5858120918273926\n",
      "Epoch 36 Loss 2.577935218811035\n",
      "Epoch 37 Loss 2.5703883171081543\n",
      "Epoch 38 Loss 2.5631518363952637\n",
      "Epoch 39 Loss 2.5562074184417725\n",
      "Epoch 40 Loss 2.5495386123657227\n",
      "Epoch 41 Loss 2.5431301593780518\n",
      "Epoch 42 Loss 2.5369670391082764\n",
      "Epoch 43 Loss 2.5310370922088623\n",
      "Epoch 44 Loss 2.525327444076538\n",
      "Epoch 45 Loss 2.5198264122009277\n",
      "Epoch 46 Loss 2.514524221420288\n",
      "Epoch 47 Loss 2.5094101428985596\n",
      "Epoch 48 Loss 2.5044748783111572\n",
      "Epoch 49 Loss 2.4997100830078125\n",
      "Epoch 50 Loss 2.4951069355010986\n",
      "Epoch 51 Loss 2.4906582832336426\n",
      "Epoch 52 Loss 2.486356258392334\n",
      "Epoch 53 Loss 2.482194423675537\n",
      "Epoch 54 Loss 2.478166341781616\n",
      "Epoch 55 Loss 2.4742653369903564\n",
      "Epoch 56 Loss 2.4704864025115967\n",
      "Epoch 57 Loss 2.4668235778808594\n",
      "Epoch 58 Loss 2.4632720947265625\n",
      "Epoch 59 Loss 2.459826707839966\n",
      "Epoch 60 Loss 2.4564831256866455\n",
      "Epoch 61 Loss 2.4532368183135986\n",
      "Epoch 62 Loss 2.4500839710235596\n",
      "Epoch 63 Loss 2.4470205307006836\n",
      "Epoch 64 Loss 2.444042682647705\n",
      "Epoch 65 Loss 2.4411470890045166\n",
      "Epoch 66 Loss 2.4383299350738525\n",
      "Epoch 67 Loss 2.4355885982513428\n",
      "Epoch 68 Loss 2.432920455932617\n",
      "Epoch 69 Loss 2.43032169342041\n",
      "Epoch 70 Loss 2.4277899265289307\n",
      "Epoch 71 Loss 2.425323009490967\n",
      "Epoch 72 Loss 2.4229180812835693\n",
      "Epoch 73 Loss 2.4205729961395264\n",
      "Epoch 74 Loss 2.418285369873047\n",
      "Epoch 75 Loss 2.416053295135498\n",
      "Epoch 76 Loss 2.413874387741089\n",
      "Epoch 77 Loss 2.4117469787597656\n",
      "Epoch 78 Loss 2.4096691608428955\n",
      "Epoch 79 Loss 2.407639503479004\n",
      "Epoch 80 Loss 2.4056556224823\n",
      "Epoch 81 Loss 2.403716802597046\n",
      "Epoch 82 Loss 2.401820659637451\n",
      "Epoch 83 Loss 2.399966239929199\n",
      "Epoch 84 Loss 2.3981523513793945\n",
      "Epoch 85 Loss 2.396376848220825\n",
      "Epoch 86 Loss 2.394639253616333\n",
      "Epoch 87 Loss 2.3929378986358643\n",
      "Epoch 88 Loss 2.3912713527679443\n",
      "Epoch 89 Loss 2.389639377593994\n",
      "Epoch 90 Loss 2.38804030418396\n",
      "Epoch 91 Loss 2.3864729404449463\n",
      "Epoch 92 Loss 2.384936809539795\n",
      "Epoch 93 Loss 2.3834304809570312\n",
      "Epoch 94 Loss 2.381953477859497\n",
      "Epoch 95 Loss 2.380504608154297\n",
      "Epoch 96 Loss 2.3790829181671143\n",
      "Epoch 97 Loss 2.37768816947937\n",
      "Epoch 98 Loss 2.37631893157959\n",
      "Epoch 99 Loss 2.3749752044677734\n"
     ]
    }
   ],
   "source": [
    "model_trigram = train(x_train, y_train, 100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fade0b",
   "metadata": {},
   "source": [
    "Loss on the dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7cceeff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, x, y):\n",
    "    logits = x @ model\n",
    "    counts = logits.exp()\n",
    "    pred = counts/counts.sum(1, keepdims=True)\n",
    "    return - pred[torch.arange(x.shape[0]), y].log().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6bd70f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.379625082015991"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model_trigram, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcd835",
   "metadata": {},
   "source": [
    "Loss on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "871e6bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3864219188690186"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model_trigram, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff05689",
   "metadata": {},
   "source": [
    "The loss on test and validation dataset are about the same for the trigram model on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0b206",
   "metadata": {},
   "source": [
    "Same we can for the bigram model that I have computed in `nbs/lecture_notes/02_building_makemore.ipynb`. The validation and test dataset have about the same losses to the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf51d7",
   "metadata": {},
   "source": [
    "The trigram is better than bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae169bb",
   "metadata": {},
   "source": [
    "## E03\n",
    "> Use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca9bd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs, lr, regularization_param, print_at_every_epoch = False, print_at_last=False):\n",
    "    num = X.shape[0]\n",
    "    W = torch.randn((54, 27), requires_grad=True, generator=g)\n",
    "    for i in range(epochs):\n",
    "        logits = X @ W\n",
    "        counts = logits.exp()\n",
    "        prob = counts/counts.sum(1, keepdims=True)\n",
    "        loss = -prob[torch.arange(num), y].log().mean()\n",
    "        \n",
    "        # regularization\n",
    "        regularization_loss = regularization_param * (W **2).mean()\n",
    "        loss += regularization_loss\n",
    "        \n",
    "        if print_at_every_epoch: print(f'Epoch {i} Loss {loss}')\n",
    "        \n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "        W.data += -lr * W.grad \n",
    "        \n",
    "    if print_at_last: print(f'Loss {loss}')\n",
    "    return W, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5ab0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_param_trend():\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    reg_params = []\n",
    "\n",
    "    for reg_param in torch.linspace(0, 10, 100):\n",
    "        model, train_loss = train(x_train, y_train, 100, 10, reg_param)\n",
    "        val_loss = evaluate_loss(model, x_valid, y_valid)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        reg_params.append(reg_param)\n",
    "\n",
    "    return train_losses, val_losses, reg_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fda8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, reg_params = get_reg_param_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9615e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('regularization parameter')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de09835",
   "metadata": {},
   "source": [
    "As we increase the regularization strength, we see that both the losses are increasing and the training loss is increasing over validation loss, it means that the model is underfitting. Lets choose the regularization parameter as 0 and evaluate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea6c93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss = train(x_train, y_train, 100, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef9f4235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3726656436920166"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dbf6086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.374793767929077"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99a39a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.383634328842163"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bead42",
   "metadata": {},
   "source": [
    "## E04\n",
    " > We saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21e9ed8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196113, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5a8a632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196113"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91d6a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = xs[train_idx], ys[train_idx]\n",
    "x_valid, y_valid = xs[valid_idx], ys[valid_idx]\n",
    "x_test, y_test = xs[test_idx], ys[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d76f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs, lr, regularization_param, print_at_every_epoch = False, print_at_last=False):\n",
    "    assert X.shape[-1] == 2\n",
    "    num = X.shape[0]\n",
    "    W = torch.randn((54, 27), requires_grad=True, generator=g)\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        #indexing\n",
    "        W1 = W[:27]\n",
    "        W2 = W[27:]\n",
    "        \n",
    "        logits = W1[X[:, 0]] + W2[X[:, 1]]\n",
    "        \n",
    "        counts = logits.exp()\n",
    "        prob = counts/counts.sum(1, keepdims=True)\n",
    "        loss = -prob[torch.arange(num), y].log().mean()\n",
    "        \n",
    "        # regularization\n",
    "        regularization_loss = regularization_param * (W **2).mean()\n",
    "        loss += regularization_loss\n",
    "        \n",
    "        if print_at_every_epoch: print(f'Epoch {i} Loss {loss}')\n",
    "        \n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "        W.data += -lr * W.grad \n",
    "        \n",
    "    if print_at_last: print(f'Loss {loss}')\n",
    "    return W, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "383de3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss = train(x_train, y_train, 100, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7154695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3768, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e36a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, x, y):\n",
    "    W1 = model[:27]\n",
    "    W2 = model[27:]\n",
    "    \n",
    "    logits = W1[x[:, 0]] + W2[x[:, 1]]\n",
    "    \n",
    "    counts = logits.exp()\n",
    "    prob = counts/counts.sum(1, keepdims=True)\n",
    "    return -prob[torch.arange(x.shape[0]), y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "964b791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3810, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "826d0053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3880, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d95656",
   "metadata": {},
   "source": [
    "## E05\n",
    "> Look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1882c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = xenc_flattened[train_idx], ys[train_idx]\n",
    "x_valid, y_valid = xenc_flattened[valid_idx], ys[valid_idx]\n",
    "x_test, y_test = xenc_flattened[test_idx], ys[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2494d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs, lr, print_at_every_epoch = False, print_at_last=False):\n",
    "    num = X.shape[0]\n",
    "    W = torch.randn((54, 27), requires_grad=True, generator=g)\n",
    "    for i in range(epochs):\n",
    "        logits = X @ W\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        if print_at_every_epoch: print(f'Epoch {i} Loss {loss}')\n",
    "        \n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "        W.data += -lr * W.grad \n",
    "        \n",
    "    if print_at_last: print(f'Loss {loss}')\n",
    "    return W, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0381f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, x, y):\n",
    "    logits = x @ model\n",
    "    counts = logits.exp()\n",
    "    pred = counts/counts.sum(1, keepdims=True)\n",
    "    return - pred[torch.arange(x.shape[0]), y].log().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f569c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss = train(x_train, y_train, 100, 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78d7b61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3824, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19506a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3871989250183105"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc11e7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3962411880493164"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba8336",
   "metadata": {},
   "source": [
    "Using `F.cross_entropy`, we dont have to compute the counts and probabilities ourselves instead we just have to pass the logits and labels to the function, also we can pass the weight given to each class and label smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a7c30",
   "metadata": {},
   "source": [
    "### E06\n",
    "> meta-exercise! Think of a fun/interesting exercise and complete it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531aaa64",
   "metadata": {},
   "source": [
    "Lets introduce bias, activation function and another layer of weight in the neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f78a36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = torch.nn.ReLU() # activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d9501379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs, lr, print_at_every_epoch = False, print_at_last=False):\n",
    "    num = X.shape[0]\n",
    "    W1 = torch.randn((54, 50), requires_grad=True, generator=g)\n",
    "    W2 = torch.randn((50, 27), requires_grad=True, generator=g)\n",
    "    b = torch.zeros(50, requires_grad=True)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        #first layer\n",
    "        output = relu(X @ W1 + b)\n",
    "        \n",
    "        # second layer\n",
    "        logits = output @ W2\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        if print_at_every_epoch: print(f'Epoch {i} Loss {loss}')\n",
    "        \n",
    "        W1.grad = None\n",
    "        W2.grad = None\n",
    "        b.grad = None\n",
    "        \n",
    "        loss.backward()\n",
    "        W1.data += -lr * W1.grad \n",
    "        W2.data += -lr * W2.grad \n",
    "        b.data += -lr * b.grad\n",
    "        \n",
    "    if print_at_last: print(f'Loss {loss}')\n",
    "    return W1, W2, b, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "39a2b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 14.356369018554688\n",
      "Epoch 1 Loss 6.445797443389893\n",
      "Epoch 2 Loss 4.845088958740234\n",
      "Epoch 3 Loss 3.610227346420288\n",
      "Epoch 4 Loss 3.2677083015441895\n",
      "Epoch 5 Loss 3.147526264190674\n",
      "Epoch 6 Loss 3.073038339614868\n",
      "Epoch 7 Loss 3.011115789413452\n",
      "Epoch 8 Loss 2.9635703563690186\n",
      "Epoch 9 Loss 2.9246973991394043\n",
      "Epoch 10 Loss 2.889881134033203\n",
      "Epoch 11 Loss 2.8589870929718018\n",
      "Epoch 12 Loss 2.8271501064300537\n",
      "Epoch 13 Loss 2.7997994422912598\n",
      "Epoch 14 Loss 2.777028799057007\n",
      "Epoch 15 Loss 2.7568700313568115\n",
      "Epoch 16 Loss 2.738692283630371\n",
      "Epoch 17 Loss 2.7220845222473145\n",
      "Epoch 18 Loss 2.7064385414123535\n",
      "Epoch 19 Loss 2.6917459964752197\n",
      "Epoch 20 Loss 2.678067922592163\n",
      "Epoch 21 Loss 2.664644956588745\n",
      "Epoch 22 Loss 2.65147066116333\n",
      "Epoch 23 Loss 2.6392555236816406\n",
      "Epoch 24 Loss 2.627774715423584\n",
      "Epoch 25 Loss 2.6169304847717285\n",
      "Epoch 26 Loss 2.606522798538208\n",
      "Epoch 27 Loss 2.5968828201293945\n",
      "Epoch 28 Loss 2.5878326892852783\n",
      "Epoch 29 Loss 2.5790443420410156\n",
      "Epoch 30 Loss 2.5707550048828125\n",
      "Epoch 31 Loss 2.5628936290740967\n",
      "Epoch 32 Loss 2.555367946624756\n",
      "Epoch 33 Loss 2.548060178756714\n",
      "Epoch 34 Loss 2.540865898132324\n",
      "Epoch 35 Loss 2.533935308456421\n",
      "Epoch 36 Loss 2.5273752212524414\n",
      "Epoch 37 Loss 2.5211167335510254\n",
      "Epoch 38 Loss 2.5150935649871826\n",
      "Epoch 39 Loss 2.5094754695892334\n",
      "Epoch 40 Loss 2.504162549972534\n",
      "Epoch 41 Loss 2.499098777770996\n",
      "Epoch 42 Loss 2.4943039417266846\n",
      "Epoch 43 Loss 2.4897239208221436\n",
      "Epoch 44 Loss 2.4852793216705322\n",
      "Epoch 45 Loss 2.4809038639068604\n",
      "Epoch 46 Loss 2.476732015609741\n",
      "Epoch 47 Loss 2.4729301929473877\n",
      "Epoch 48 Loss 2.4693245887756348\n",
      "Epoch 49 Loss 2.4662768840789795\n",
      "Epoch 50 Loss 2.463529348373413\n",
      "Epoch 51 Loss 2.4625327587127686\n",
      "Epoch 52 Loss 2.4603705406188965\n",
      "Epoch 53 Loss 2.4633936882019043\n",
      "Epoch 54 Loss 2.4599740505218506\n",
      "Epoch 55 Loss 2.4705214500427246\n",
      "Epoch 56 Loss 2.457852840423584\n",
      "Epoch 57 Loss 2.4718434810638428\n",
      "Epoch 58 Loss 2.4522647857666016\n",
      "Epoch 59 Loss 2.4626526832580566\n",
      "Epoch 60 Loss 2.4469213485717773\n",
      "Epoch 61 Loss 2.4574408531188965\n",
      "Epoch 62 Loss 2.4430127143859863\n",
      "Epoch 63 Loss 2.453047752380371\n",
      "Epoch 64 Loss 2.4383814334869385\n",
      "Epoch 65 Loss 2.447606325149536\n",
      "Epoch 66 Loss 2.434413194656372\n",
      "Epoch 67 Loss 2.44319486618042\n",
      "Epoch 68 Loss 2.430687665939331\n",
      "Epoch 69 Loss 2.439272165298462\n",
      "Epoch 70 Loss 2.4267563819885254\n",
      "Epoch 71 Loss 2.4345061779022217\n",
      "Epoch 72 Loss 2.423175096511841\n",
      "Epoch 73 Loss 2.430905818939209\n",
      "Epoch 74 Loss 2.4197804927825928\n",
      "Epoch 75 Loss 2.4282257556915283\n",
      "Epoch 76 Loss 2.4168829917907715\n",
      "Epoch 77 Loss 2.4250295162200928\n",
      "Epoch 78 Loss 2.41373610496521\n",
      "Epoch 79 Loss 2.4221179485321045\n",
      "Epoch 80 Loss 2.410914897918701\n",
      "Epoch 81 Loss 2.418801784515381\n",
      "Epoch 82 Loss 2.408095359802246\n",
      "Epoch 83 Loss 2.4158382415771484\n",
      "Epoch 84 Loss 2.405586004257202\n",
      "Epoch 85 Loss 2.413395643234253\n",
      "Epoch 86 Loss 2.403322696685791\n",
      "Epoch 87 Loss 2.4110255241394043\n",
      "Epoch 88 Loss 2.401683807373047\n",
      "Epoch 89 Loss 2.4100100994110107\n",
      "Epoch 90 Loss 2.3993263244628906\n",
      "Epoch 91 Loss 2.4081666469573975\n",
      "Epoch 92 Loss 2.3970468044281006\n",
      "Epoch 93 Loss 2.4049551486968994\n",
      "Epoch 94 Loss 2.3944251537323\n",
      "Epoch 95 Loss 2.4016761779785156\n",
      "Epoch 96 Loss 2.392186164855957\n",
      "Epoch 97 Loss 2.39933443069458\n",
      "Epoch 98 Loss 2.390073776245117\n",
      "Epoch 99 Loss 2.3971004486083984\n",
      "Loss 2.3971004486083984\n"
     ]
    }
   ],
   "source": [
    "params1, params2, bias,  loss = train(x_train, y_train, 100, 5, print_at_every_epoch = True, print_at_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6f8ae56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(X, y, W1, W2, b):\n",
    "    #first layer\n",
    "    output = relu(X @ W1 + b)\n",
    "        \n",
    "    # second layer\n",
    "    logits = output @ W2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5be7c6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3898, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(x_valid, y_valid, params1, params2, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "18a47dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4028, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(x_test, y_test, params1, params2, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7f220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zhnn)",
   "language": "python",
   "name": "zhnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
