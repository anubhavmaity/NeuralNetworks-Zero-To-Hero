{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7e8c49",
   "metadata": {},
   "source": [
    "# Wavenet Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d3ed6",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d67a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from ray import tune\n",
    "import torch.nn.functional as F\n",
    "from ray import tune, air\n",
    "from ray.air import session\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697e06d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07dcd579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / fan_in ** 0.5 # note: kaiming init\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6928ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x.view(x.shape[0], -1)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84788a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding: \n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "        \n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f264230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        # get parameters of all layers and stretch them out into one list\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dabf32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers (trained with a running `momentum update`)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "            if x.ndim == 2: dim = 0\n",
    "            elif x.ndim == 3: dim = (0, 1)\n",
    "            xmean = x.mean(dim, keepdim=True)\n",
    "            xvar = x.var(dim, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        \n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45eb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenConsecutive:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1: \n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733248c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_embd, # the dimensionality of the character embedding vectors\n",
    "                n_hidden # the number of neurons in the hidden layer of the MLP \n",
    "               ):\n",
    "    vocab_size = 27\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, n_embd),\n",
    "        FlattenConsecutive(2), Linear(n_embd*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "        FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "        FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "        Linear(n_hidden, vocab_size),\n",
    "    ])\n",
    "\n",
    "    # parameter init\n",
    "    with torch.no_grad():\n",
    "        model.layers[-1].weight *= 0.1\n",
    "\n",
    "    parameters = model.parameters()\n",
    "    print(sum(p.nelement() for p in parameters))\n",
    "    for p in parameters: p.requires_grad = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9f1fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "words = open('/Users/anubhavmaity/projects/NeuralNetworks-Zero-To-Hero/nbs/data/names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aba4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(words):\n",
    "    chars = sorted(list(set(''.join(words))))\n",
    "    stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "    stoi['.'] = 0\n",
    "    itos = {i: s for s, i in stoi.items()}\n",
    "    vocab_size = len(itos)\n",
    "    return stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdedd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, block_size=8):\n",
    "    X, Y = [], []\n",
    "    stoi = get_map(words)\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    "\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1: n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d50708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the loss\n",
    "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
    "def split_loss(model, split):\n",
    "    x, y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte)\n",
    "    }[split]\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7f1c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same optimization as last time\n",
    "def train(model, max_steps, batch_size):\n",
    "    lossi = []\n",
    "\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "\n",
    "        # forward pass\n",
    "        logits = model(Xb)\n",
    "        loss = F.cross_entropy(logits, Yb)\n",
    "\n",
    "        # backward pass\n",
    "        for p in model.parameters():\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        # update: simple SGD\n",
    "        lr = 0.1 if i < 150_000 else 0.01 # step learning rate decay\n",
    "        for p in model.parameters(): \n",
    "            p.data += -lr * p.grad\n",
    "\n",
    "        # track stats\n",
    "        if i % 10_000 == 0: # print every once in a while\n",
    "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "        \n",
    "    return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95e15141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):\n",
    "    # Load from config\n",
    "    max_steps = 200_000\n",
    "    batch_size = config['batch_size']\n",
    "    n_embd = config['n_embd']\n",
    "    n_hidden = config['n_hidden']\n",
    "    \n",
    "    # Load the data\n",
    "    words = open('/Users/anubhavmaity/projects/NeuralNetworks-Zero-To-Hero/nbs/data/names.txt', 'r').read().splitlines()\n",
    "    n1 = int(0.8 * len(words))\n",
    "    n2 = int(0.9 * len(words))\n",
    "    Xtr, Ytr = build_dataset(words[:n1])\n",
    "    Xdev, Ydev = build_dataset(words[n1: n2])\n",
    "    Xte, Yte = build_dataset(words[n2:])\n",
    "    \n",
    "    # Create a model\n",
    "    model = build_model(n_embd, n_hidden)\n",
    "    \n",
    "    \n",
    "    train(model, max_steps, batch_size)\n",
    "    val_loss = split_loss(model, 'val')  # Compute loss\n",
    "    session.report({\"val_loss\": val_loss})  # Report to Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63f6179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-02-25 07:43:48</td></tr>\n",
       "<tr><td>Running for: </td><td>08:44:44.81        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.1/4.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/1.14 GiB heap, 0.0/0.57 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  n_embd</th><th style=\"text-align: right;\">  n_hidden</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_e09e6d50</td><td>RUNNING </td><td>127.0.0.1:14371</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">       128</td></tr>\n",
       "<tr><td>objective_710a549e</td><td>RUNNING </td><td>127.0.0.1:14379</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">        32</td></tr>\n",
       "<tr><td>objective_5a2b4a2f</td><td>RUNNING </td><td>127.0.0.1:14388</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">       512</td></tr>\n",
       "<tr><td>objective_81f1e0c2</td><td>RUNNING </td><td>127.0.0.1:14397</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">       128</td></tr>\n",
       "<tr><td>objective_563ab57c</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">       512</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 22:59:04,273\tWARNING worker.py:1866 -- Warning: The actor ImplicitFunc is very large (15 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2023-02-24 22:59:04,425\tWARNING util.py:244 -- The `start_trial` operation took 0.672 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=14371)\u001b[0m 76579\n",
      "\u001b[2m\u001b[36m(objective pid=14371)\u001b[0m       0/ 200000: 3.2968\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m 7363\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m       0/ 200000: 3.2918\n",
      "\u001b[2m\u001b[36m(objective pid=14388)\u001b[0m 1118049\n",
      "\u001b[2m\u001b[36m(objective pid=14388)\u001b[0m       0/ 200000: 3.2886\n",
      "\u001b[2m\u001b[36m(objective pid=14397)\u001b[0m 76579\n",
      "\u001b[2m\u001b[36m(objective pid=14397)\u001b[0m       0/ 200000: 3.2904\n",
      "\u001b[2m\u001b[36m(objective pid=14371)\u001b[0m   10000/ 200000: 2.2415\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m   10000/ 200000: 2.2179\n",
      "\u001b[2m\u001b[36m(objective pid=14371)\u001b[0m   20000/ 200000: 1.6273\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m   20000/ 200000: 2.1193\n",
      "\u001b[2m\u001b[36m(objective pid=14397)\u001b[0m   10000/ 200000: 2.0203\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m   30000/ 200000: 2.0717\n",
      "\u001b[2m\u001b[36m(objective pid=14371)\u001b[0m   30000/ 200000: 1.8968\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m   40000/ 200000: 2.1775\n",
      "\u001b[2m\u001b[36m(objective pid=14371)\u001b[0m   40000/ 200000: 1.9022\n",
      "\u001b[2m\u001b[36m(objective pid=14388)\u001b[0m   10000/ 200000: 1.9961\n",
      "\u001b[2m\u001b[36m(objective pid=14397)\u001b[0m   20000/ 200000: 1.8763\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m   50000/ 200000: 2.0287\n",
      "\u001b[2m\u001b[36m(objective pid=14371)\u001b[0m   50000/ 200000: 1.8816\n",
      "\u001b[2m\u001b[36m(objective pid=14379)\u001b[0m   60000/ 200000: 1.7980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 07:43:48,156\tWARNING tune.py:147 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-02-25 07:43:48,221\tERROR tune.py:794 -- Trials did not complete: [objective_e09e6d50, objective_710a549e, objective_5a2b4a2f, objective_81f1e0c2, objective_563ab57c]\n",
      "2023-02-25 07:43:48,223\tINFO tune.py:799 -- Total run time: 31485.06 seconds (31484.79 seconds for the tuning loop).\n",
      "2023-02-25 07:43:48,225\tWARNING tune.py:805 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x7f8d9342b050>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_space = {\"batch_size\": tune.choice([32, 64, 128]), \n",
    "                \"n_embd\": tune.choice([10, 24, 50, 100, 300]), \n",
    "                \"n_hidden\": tune.choice([32, 64, 128, 256, 512])}\n",
    "\n",
    "current_best_params = [{\n",
    "    'batch_size': 32,\n",
    "    'n_embd': 24,\n",
    "    'n_hidden': 128,\n",
    "}]\n",
    "\n",
    "hyperopt_search = HyperOptSearch(\n",
    "    metric=\"val_loss\", mode=\"min\",\n",
    "    points_to_evaluate=current_best_params)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    objective,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=hyperopt_search,\n",
    "        num_samples = 10\n",
    "    ),\n",
    "    param_space=search_space\n",
    ")\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43706640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = {\"batch_size\": tune.choice([32, 64]), \"n_embd\": tune.choice([10, 24, 50]), \"n_hidden\": tune.choice([32, 64, 128, 256, 512])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo = OptunaSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = tune.Tuner(\n",
    "#     objective,\n",
    "#     tune_config=tune.TuneConfig(\n",
    "#         metric=\"val_loss\",\n",
    "#         mode=\"min\",\n",
    "#         search_alg=algo,\n",
    "#     ),\n",
    "#     run_config=air.RunConfig(\n",
    "#         stop={\"training_iteration\": 5},\n",
    "#     ),\n",
    "#     param_space=search_space,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = tuner.fit()\n",
    "# print(\"Best config is:\", results.get_best_result().config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132e9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhnn",
   "language": "python",
   "name": "zhnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
