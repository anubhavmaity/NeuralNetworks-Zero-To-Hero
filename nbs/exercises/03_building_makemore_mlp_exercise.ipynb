{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Makemore MLP Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T05:19:26.219468Z",
     "iopub.status.busy": "2022-12-29T05:19:26.218956Z",
     "iopub.status.idle": "2022-12-29T05:19:28.244231Z",
     "shell.execute_reply": "2022-12-29T05:19:28.242487Z",
     "shell.execute_reply.started": "2022-12-29T05:19:26.219370Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plot\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T05:19:28.247919Z",
     "iopub.status.busy": "2022-12-29T05:19:28.246794Z",
     "iopub.status.idle": "2022-12-29T05:19:28.422776Z",
     "shell.execute_reply": "2022-12-29T05:19:28.421102Z",
     "shell.execute_reply.started": "2022-12-29T05:19:28.247822Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27/29846070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.device_count(), torch.cuda.current_device(), torch.cuda.device(0), torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-29T05:19:28.423852Z",
     "iopub.status.idle": "2022-12-29T05:19:28.424858Z",
     "shell.execute_reply": "2022-12-29T05:19:28.424645Z",
     "shell.execute_reply.started": "2022-12-29T05:19:28.424619Z"
    }
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:58.233042Z",
     "iopub.status.busy": "2022-12-28T22:34:58.232454Z",
     "iopub.status.idle": "2022-12-28T22:34:58.255208Z",
     "shell.execute_reply": "2022-12-28T22:34:58.254351Z",
     "shell.execute_reply.started": "2022-12-28T22:34:58.233003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('/kaggle/input/nameszhnn/names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:58.257002Z",
     "iopub.status.busy": "2022-12-28T22:34:58.256590Z",
     "iopub.status.idle": "2022-12-28T22:34:58.264008Z",
     "shell.execute_reply": "2022-12-28T22:34:58.262986Z",
     "shell.execute_reply.started": "2022-12-28T22:34:58.256967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:58.266196Z",
     "iopub.status.busy": "2022-12-28T22:34:58.265550Z",
     "iopub.status.idle": "2022-12-28T22:34:58.276240Z",
     "shell.execute_reply": "2022-12-28T22:34:58.275414Z",
     "shell.execute_reply.started": "2022-12-28T22:34:58.266154Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_training_set(words, block_size, print_disabled=False):\n",
    "    \n",
    "    chars = sorted(list(set(''.join(words))))\n",
    "    stoi = {s: i+1 for i, s in enumerate(chars)}\n",
    "    stoi['.'] = 0\n",
    "    itos = {i:s for s, i in stoi.items()}\n",
    "    \n",
    "    X, Y = [], []\n",
    "    \n",
    "    for w in words:\n",
    "        if print_disabled: print(w)\n",
    "        \n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            if print_disabled: print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:58.278525Z",
     "iopub.status.busy": "2022-12-28T22:34:58.277775Z",
     "iopub.status.idle": "2022-12-28T22:34:58.721316Z",
     "shell.execute_reply": "2022-12-28T22:34:58.720357Z",
     "shell.execute_reply.started": "2022-12-28T22:34:58.278456Z"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = generate_training_set(words, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:58.722950Z",
     "iopub.status.busy": "2022-12-28T22:34:58.722590Z",
     "iopub.status.idle": "2022-12-28T22:34:58.730985Z",
     "shell.execute_reply": "2022-12-28T22:34:58.729979Z",
     "shell.execute_reply.started": "2022-12-28T22:34:58.722911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:58.733459Z",
     "iopub.status.busy": "2022-12-28T22:34:58.732715Z",
     "iopub.status.idle": "2022-12-28T22:34:58.741494Z",
     "shell.execute_reply": "2022-12-28T22:34:58.740386Z",
     "shell.execute_reply.started": "2022-12-28T22:34:58.733424Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_train_valid_test_split(words, block_size=3):\n",
    "    random.seed(42)\n",
    "    random.shuffle(words)\n",
    "    n1 = int(0.8*len(words))\n",
    "    n2 = int(0.9*len(words))\n",
    "\n",
    "    Xtr, Ytr = generate_training_set(words[:n1], block_size)\n",
    "    Xdev, Ydev = generate_training_set(words[n1:n2], block_size)\n",
    "    Xte, Yte = generate_training_set(words[n2:], block_size)\n",
    "    \n",
    "    return Xtr, Ytr, Xdev, Ydev, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:58.745377Z",
     "iopub.status.busy": "2022-12-28T22:34:58.744906Z",
     "iopub.status.idle": "2022-12-28T22:34:59.203030Z",
     "shell.execute_reply": "2022-12-28T22:34:59.202063Z",
     "shell.execute_reply.started": "2022-12-28T22:34:58.745334Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xdev, Ydev, Xte, Yte = generate_train_valid_test_split(words, block_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:59.204948Z",
     "iopub.status.busy": "2022-12-28T22:34:59.204565Z",
     "iopub.status.idle": "2022-12-28T22:34:59.213832Z",
     "shell.execute_reply": "2022-12-28T22:34:59.212778Z",
     "shell.execute_reply.started": "2022-12-28T22:34:59.204912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([182625, 3]), torch.Size([182625]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Ytr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:59.216447Z",
     "iopub.status.busy": "2022-12-28T22:34:59.215599Z",
     "iopub.status.idle": "2022-12-28T22:34:59.223917Z",
     "shell.execute_reply": "2022-12-28T22:34:59.222845Z",
     "shell.execute_reply.started": "2022-12-28T22:34:59.216412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([22655, 3]), torch.Size([22655]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdev.shape, Ydev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:59.225976Z",
     "iopub.status.busy": "2022-12-28T22:34:59.225570Z",
     "iopub.status.idle": "2022-12-28T22:34:59.234314Z",
     "shell.execute_reply": "2022-12-28T22:34:59.233248Z",
     "shell.execute_reply.started": "2022-12-28T22:34:59.225941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([22866, 3]), torch.Size([22866]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte.shape, Yte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E01\n",
    "\n",
    "Tune the hyperparameters of the training to beat the validation loss of 2.2\n",
    "\n",
    "   - no of neurons in the hidden layer\n",
    "    \n",
    "   - embedding size\n",
    "    \n",
    "   - no of characters\n",
    "    \n",
    "   - epochs\n",
    "    \n",
    "   - learning rate; change/decay it over the epochs\n",
    "    \n",
    "   - batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:59.236753Z",
     "iopub.status.busy": "2022-12-28T22:34:59.236039Z",
     "iopub.status.idle": "2022-12-28T22:34:59.245075Z",
     "shell.execute_reply": "2022-12-28T22:34:59.243850Z",
     "shell.execute_reply.started": "2022-12-28T22:34:59.236717Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_loss(parameters, X, Y, block_size=3, embedding_size=10):\n",
    "    C, W1, b1, W2, b2 = parameters\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits.cuda(), Y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:34:59.246952Z",
     "iopub.status.busy": "2022-12-28T22:34:59.246625Z",
     "iopub.status.idle": "2022-12-28T22:34:59.255770Z",
     "shell.execute_reply": "2022-12-28T22:34:59.254489Z",
     "shell.execute_reply.started": "2022-12-28T22:34:59.246920Z"
    }
   },
   "outputs": [],
   "source": [
    "def _regularization_loss(parameters, lambdas):\n",
    "    C = parameters[0]\n",
    "    W1 = parameters[1]\n",
    "    W2 = parameters[3]\n",
    "    \n",
    "    return lambdas[0]*(C**2).mean() + lambdas[1]*(W1**2).mean() + lambdas[2]*(W2**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T21:23:18.715382Z",
     "iopub.status.busy": "2022-12-28T21:23:18.714976Z",
     "iopub.status.idle": "2022-12-28T21:23:18.728194Z",
     "shell.execute_reply": "2022-12-28T21:23:18.727171Z",
     "shell.execute_reply.started": "2022-12-28T21:23:18.715334Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X, \n",
    "          Y, \n",
    "          epochs, \n",
    "          block_size=3, \n",
    "          embedding_size=10, \n",
    "          hidden_neuron=300, \n",
    "          bs=32, \n",
    "          lr=0.1, \n",
    "          parameters=[], \n",
    "          lambdas = [0, 0, 0],\n",
    "          enable_print=True,\n",
    "          print_at_every_nth_epoch=10000\n",
    "         ):\n",
    "    \n",
    "    if not parameters:\n",
    "        C = torch.randn((27, embedding_size), generator=g).cuda()\n",
    "        W1 = torch.randn((block_size * embedding_size, hidden_neuron), generator=g).cuda()\n",
    "        b1 = torch.randn(hidden_neuron, generator=g).cuda()\n",
    "        W2 = torch.randn((hidden_neuron, 27), generator=g).cuda()\n",
    "        b2 = torch.randn(27, generator=g).cuda()\n",
    "        parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "    \n",
    "    for p in parameters: p.requires_grad = True \n",
    "        \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "        ix = torch.randint(0, X.shape[0], (bs, )).cuda()\n",
    "\n",
    "        loss = evaluate_loss(parameters, X[ix].cuda(), Y[ix].cuda(), block_size, embedding_size)\n",
    "        regularization_loss = _regularization_loss(parameters, lambdas)\n",
    "        loss += regularization_loss\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad= None\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += - lr * p.grad\n",
    "\n",
    "        if enable_print and epoch % print_at_every_nth_epoch == 0: print(epoch, loss.item())\n",
    "    \n",
    "    return parameters, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T21:23:19.613256Z",
     "iopub.status.busy": "2022-12-28T21:23:19.612898Z",
     "iopub.status.idle": "2022-12-28T21:31:28.982923Z",
     "shell.execute_reply": "2022-12-28T21:31:28.981428Z",
     "shell.execute_reply.started": "2022-12-28T21:23:19.613224Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/100000 [00:00<30:45, 54.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19.391998291015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10010/100000 [03:03<27:34, 54.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.2867367267608643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20009/100000 [06:02<23:37, 56.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2.210310935974121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 26950/100000 [08:09<22:06, 55.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/278725407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_neuron\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_at_every_nth_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_23/1581440720.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X, Y, epochs, block_size, embedding_size, hidden_neuron, bs, lr, parameters, lambdas, enable_print, print_at_every_nth_epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters, loss = train(Xtr, Ytr, 100_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T16:57:20.397661Z",
     "iopub.status.busy": "2022-12-28T16:57:20.396225Z",
     "iopub.status.idle": "2022-12-28T16:57:20.424788Z",
     "shell.execute_reply": "2022-12-28T16:57:20.423837Z",
     "shell.execute_reply.started": "2022-12-28T16:57:20.397624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.112903356552124,\n",
       " tensor(2.1565, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, evaluate_loss(parameters, Xdev.cuda(), Ydev.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T16:57:20.427842Z",
     "iopub.status.busy": "2022-12-28T16:57:20.426689Z",
     "iopub.status.idle": "2022-12-28T18:26:08.403965Z",
     "shell.execute_reply": "2022-12-28T18:26:08.402966Z",
     "shell.execute_reply.started": "2022-12-28T16:57:20.427798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [1:28:47<00:00, 56.31it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(Xtr, Ytr, 300_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.01, parameters=parameters, enable_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T18:26:08.406902Z",
     "iopub.status.busy": "2022-12-28T18:26:08.405963Z",
     "iopub.status.idle": "2022-12-28T18:26:08.418320Z",
     "shell.execute_reply": "2022-12-28T18:26:08.417189Z",
     "shell.execute_reply.started": "2022-12-28T18:26:08.406865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1061928272247314,\n",
       " tensor(2.1500, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, evaluate_loss(parameters, Xdev.cuda(), Ydev.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T18:26:08.428267Z",
     "iopub.status.busy": "2022-12-28T18:26:08.427338Z",
     "iopub.status.idle": "2022-12-28T18:29:05.826135Z",
     "shell.execute_reply": "2022-12-28T18:29:05.825070Z",
     "shell.execute_reply.started": "2022-12-28T18:26:08.428232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:57<00:00, 56.38it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(Xtr, Ytr, 10_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=1, parameters=parameters, enable_print=True, print_at_every_nth_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T18:29:07.053377Z",
     "iopub.status.busy": "2022-12-28T18:29:07.052240Z",
     "iopub.status.idle": "2022-12-28T18:29:07.063761Z",
     "shell.execute_reply": "2022-12-28T18:29:07.062779Z",
     "shell.execute_reply.started": "2022-12-28T18:29:07.053340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.125706911087036,\n",
       " tensor(2.2161, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, evaluate_loss(parameters, Xdev.cuda(), Ydev.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T18:29:07.066877Z",
     "iopub.status.busy": "2022-12-28T18:29:07.065785Z",
     "iopub.status.idle": "2022-12-28T18:32:04.119395Z",
     "shell.execute_reply": "2022-12-28T18:32:04.118342Z",
     "shell.execute_reply.started": "2022-12-28T18:29:07.066838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/10000 [00:00<03:03, 54.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.166624069213867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1008/10000 [00:17<02:38, 56.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2.0816526412963867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2010/10000 [00:35<02:20, 57.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2.0698986053466797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3012/10000 [00:53<02:03, 56.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 2.085846424102783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4008/10000 [01:10<01:45, 57.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 2.0758490562438965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5010/10000 [01:28<01:33, 53.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 2.085636615753174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6012/10000 [01:46<01:10, 56.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 2.076601505279541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7008/10000 [02:04<00:52, 56.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 2.0770840644836426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8010/10000 [02:21<00:35, 56.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2.0789082050323486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9012/10000 [02:39<00:17, 56.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 2.0974490642547607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:57<00:00, 56.49it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(Xtr, Ytr, 10_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, parameters=parameters, enable_print=True, print_at_every_nth_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T18:32:04.121826Z",
     "iopub.status.busy": "2022-12-28T18:32:04.121449Z",
     "iopub.status.idle": "2022-12-28T18:32:04.132570Z",
     "shell.execute_reply": "2022-12-28T18:32:04.131391Z",
     "shell.execute_reply.started": "2022-12-28T18:32:04.121789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.085941791534424,\n",
       " tensor(2.1405, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, evaluate_loss(parameters, Xdev.cuda(), Ydev.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5th try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T18:32:04.136039Z",
     "iopub.status.busy": "2022-12-28T18:32:04.135496Z",
     "iopub.status.idle": "2022-12-28T19:01:34.213254Z",
     "shell.execute_reply": "2022-12-28T19:01:34.212194Z",
     "shell.execute_reply.started": "2022-12-28T18:32:04.136005Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/100000 [00:00<27:16, 61.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.070305109024048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10011/100000 [02:57<27:57, 53.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.0962393283843994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20012/100000 [05:54<23:27, 56.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2.0833041667938232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30008/100000 [08:50<20:31, 56.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 2.074430465698242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40008/100000 [11:47<17:32, 56.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 2.087279796600342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50010/100000 [14:45<14:36, 57.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 2.0869252681732178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60008/100000 [17:42<11:40, 57.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 2.0887160301208496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70010/100000 [20:39<08:49, 56.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 2.097712755203247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80010/100000 [23:36<05:50, 57.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 2.0827200412750244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90008/100000 [26:33<02:55, 57.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000 2.0914275646209717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [29:30<00:00, 56.50it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(Xtr, Ytr, 100_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.01, parameters=parameters, enable_print=True, print_at_every_nth_epoch=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T19:01:34.215244Z",
     "iopub.status.busy": "2022-12-28T19:01:34.214873Z",
     "iopub.status.idle": "2022-12-28T19:01:34.227081Z",
     "shell.execute_reply": "2022-12-28T19:01:34.226032Z",
     "shell.execute_reply.started": "2022-12-28T19:01:34.215209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.063863515853882,\n",
       " tensor(2.1395, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, evaluate_loss(parameters, Xdev.cuda(), Ydev.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T19:01:34.229420Z",
     "iopub.status.busy": "2022-12-28T19:01:34.228821Z",
     "iopub.status.idle": "2022-12-28T19:01:34.239572Z",
     "shell.execute_reply": "2022-12-28T19:01:34.238277Z",
     "shell.execute_reply.started": "2022-12-28T19:01:34.229384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.063863515853882,\n",
       " tensor(2.1439, device='cuda:0', grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, evaluate_loss(parameters, Xte.cuda(), Yte.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E02\n",
    "- Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve? \n",
    "\n",
    "(2) Can you tune the initialization to get a starting loss that is much more similar to (1)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to (1)\n",
    "\n",
    "If the predicted probabilities were uniform then the probabilities would have been `1/27` of each character prediction\n",
    "\n",
    "And we would have take the log of the probability which would have been"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T19:57:12.571877Z",
     "iopub.status.busy": "2022-12-28T19:57:12.571247Z",
     "iopub.status.idle": "2022-12-28T19:57:12.593024Z",
     "shell.execute_reply": "2022-12-28T19:57:12.591947Z",
     "shell.execute_reply.started": "2022-12-28T19:57:12.571828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.2958)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1/27).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to the get the loss it would have been"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T19:57:43.114799Z",
     "iopub.status.busy": "2022-12-28T19:57:43.114318Z",
     "iopub.status.idle": "2022-12-28T19:57:43.124735Z",
     "shell.execute_reply": "2022-12-28T19:57:43.123802Z",
     "shell.execute_reply.started": "2022-12-28T19:57:43.114760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2958)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- torch.tensor(1/27).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we sum up the losses and divide by the count, `(n * (3.2958))/n`\n",
    "which is equal to `3.2958`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the initial loss when we train the model with current initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:01:55.101263Z",
     "iopub.status.busy": "2022-12-28T20:01:55.100896Z",
     "iopub.status.idle": "2022-12-28T20:01:59.319026Z",
     "shell.execute_reply": "2022-12-28T20:01:59.318067Z",
     "shell.execute_reply.started": "2022-12-28T20:01:55.101232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18.98647117614746\n",
      "1 18.139089584350586\n",
      "2 17.4639949798584\n",
      "3 16.95638084411621\n",
      "4 16.41069984436035\n",
      "5 16.088415145874023\n",
      "6 15.858123779296875\n",
      "7 15.584877967834473\n",
      "8 15.392867088317871\n",
      "9 14.91295051574707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(Xtr, Ytr, 10, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial loss is `18.98` which is high comparative to `3.2958`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the probabilities of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:06:10.464098Z",
     "iopub.status.busy": "2022-12-28T20:06:10.463750Z",
     "iopub.status.idle": "2022-12-28T20:06:10.496895Z",
     "shell.execute_reply": "2022-12-28T20:06:10.495888Z",
     "shell.execute_reply.started": "2022-12-28T20:06:10.464069Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 45.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17.784887313842773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train(Xtr, Ytr, 1, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:12:59.662879Z",
     "iopub.status.busy": "2022-12-28T20:12:59.662519Z",
     "iopub.status.idle": "2022-12-28T20:12:59.668778Z",
     "shell.execute_reply": "2022-12-28T20:12:59.667547Z",
     "shell.execute_reply.started": "2022-12-28T20:12:59.662848Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_probs(parameters, X, block_size=3, embedding_size=50):\n",
    "    C, W1, b1, W2, b2 = parameters\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    return F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:13:00.030387Z",
     "iopub.status.busy": "2022-12-28T20:13:00.029471Z",
     "iopub.status.idle": "2022-12-28T20:13:00.043422Z",
     "shell.execute_reply": "2022-12-28T20:13:00.042378Z",
     "shell.execute_reply.started": "2022-12-28T20:13:00.030338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0857e-04, 3.6501e-02, 2.1932e-06,  ..., 2.3620e-11, 3.5701e-07,\n",
       "         1.1134e-09],\n",
       "        [4.6675e-07, 3.9523e-03, 2.2363e-13,  ..., 9.9556e-17, 1.7200e-13,\n",
       "         1.9502e-14],\n",
       "        [1.1533e-03, 3.5033e-05, 1.8715e-15,  ..., 1.2193e-10, 1.2248e-08,\n",
       "         6.8308e-16],\n",
       "        ...,\n",
       "        [5.5263e-07, 4.1990e-03, 2.8210e-11,  ..., 1.3669e-13, 7.7488e-08,\n",
       "         4.2720e-17],\n",
       "        [8.9470e-06, 6.5655e-03, 6.6855e-04,  ..., 5.5212e-08, 6.7759e-13,\n",
       "         1.9382e-04],\n",
       "        [3.5907e-07, 2.2142e-07, 4.3963e-06,  ..., 1.0096e-06, 9.9789e-01,\n",
       "         1.2103e-13]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_probs(parameters, Xtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view a single row of probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:13:12.292023Z",
     "iopub.status.busy": "2022-12-28T20:13:12.291660Z",
     "iopub.status.idle": "2022-12-28T20:13:12.304923Z",
     "shell.execute_reply": "2022-12-28T20:13:12.303825Z",
     "shell.execute_reply.started": "2022-12-28T20:13:12.291989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0857e-04, 3.6501e-02, 2.1932e-06, 1.3373e-08, 1.1020e-10, 5.3793e-03,\n",
       "        3.0107e-08, 2.6294e-14, 9.6476e-12, 1.1091e-11, 1.0275e-08, 1.0968e-10,\n",
       "        3.7358e-05, 8.2368e-08, 3.6925e-07, 1.4491e-08, 2.4197e-08, 1.3568e-12,\n",
       "        4.5940e-06, 1.9727e-07, 8.8267e-05, 1.2796e-02, 1.9823e-04, 9.4488e-01,\n",
       "        2.3620e-11, 3.5701e-07, 1.1134e-09], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_probs(parameters, Xtr)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get a uniform probability, I think we need to have all logits as equal so that we can get probability of each as `1/27`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets try uniform wieght initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:17:10.818010Z",
     "iopub.status.busy": "2022-12-28T20:17:10.817659Z",
     "iopub.status.idle": "2022-12-28T20:17:10.829816Z",
     "shell.execute_reply": "2022-12-28T20:17:10.828935Z",
     "shell.execute_reply.started": "2022-12-28T20:17:10.817980Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_v2(X, \n",
    "          Y, \n",
    "          epochs, \n",
    "          block_size=3, \n",
    "          embedding_size=10, \n",
    "          hidden_neuron=300, \n",
    "          bs=32, \n",
    "          lr=0.1, \n",
    "          parameters=[], \n",
    "          lambdas = [0, 0, 0],\n",
    "          enable_print=True,\n",
    "          print_at_every_nth_epoch=10000\n",
    "         ):\n",
    "    \n",
    "    if not parameters:\n",
    "        C = torch.rand((27, embedding_size), generator=g).cuda()\n",
    "        W1 = torch.rand((block_size * embedding_size, hidden_neuron), generator=g).cuda()\n",
    "        b1 = torch.rand(hidden_neuron, generator=g).cuda()\n",
    "        W2 = torch.rand((hidden_neuron, 27), generator=g).cuda()  \n",
    "        b2 = torch.rand(27, generator=g).cuda()\n",
    "        parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "    \n",
    "    for p in parameters: p.requires_grad = True \n",
    "        \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "        ix = torch.randint(0, X.shape[0], (bs, )).cuda()\n",
    "\n",
    "        loss = evaluate_loss(parameters, X[ix].cuda(), Y[ix].cuda(), block_size, embedding_size)\n",
    "        regularization_loss = _regularization_loss(parameters, lambdas)\n",
    "        loss += regularization_loss\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad= None\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += - lr * p.grad\n",
    "\n",
    "        if enable_print and epoch % print_at_every_nth_epoch == 0: print(epoch, loss.item())\n",
    "    \n",
    "    return parameters, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:17:11.184152Z",
     "iopub.status.busy": "2022-12-28T20:17:11.183797Z",
     "iopub.status.idle": "2022-12-28T20:17:11.216150Z",
     "shell.execute_reply": "2022-12-28T20:17:11.215087Z",
     "shell.execute_reply.started": "2022-12-28T20:17:11.184115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 46.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.422854900360107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train_v2(Xtr, Ytr, 1, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With uniform weight initialization the intial loss (`6.422`) obtained is less than of normal weight initialization (`17.7`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets initialize the last layers of weights and biases as zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:58:22.427177Z",
     "iopub.status.busy": "2022-12-28T20:58:22.426815Z",
     "iopub.status.idle": "2022-12-28T20:58:22.438809Z",
     "shell.execute_reply": "2022-12-28T20:58:22.437521Z",
     "shell.execute_reply.started": "2022-12-28T20:58:22.427146Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_v3(X, \n",
    "          Y, \n",
    "          epochs, \n",
    "          block_size=3, \n",
    "          embedding_size=10, \n",
    "          hidden_neuron=300, \n",
    "          bs=32, \n",
    "          lr=0.1, \n",
    "          parameters=[], \n",
    "          lambdas = [0, 0, 0],\n",
    "          enable_print=True,\n",
    "          print_at_every_nth_epoch=10000\n",
    "         ):\n",
    "    \n",
    "    if not parameters:\n",
    "        C = torch.rand((27, embedding_size), generator=g).cuda()\n",
    "        W1 = torch.rand((block_size * embedding_size, hidden_neuron), generator=g).cuda()\n",
    "        b1 = torch.rand(hidden_neuron).cuda()\n",
    "        W2 = torch.zeros((hidden_neuron, 27)).cuda()  \n",
    "        b2 = torch.zeros(27).cuda()\n",
    "        parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "    \n",
    "    for p in parameters: p.requires_grad = True \n",
    "        \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "        ix = torch.randint(0, X.shape[0], (bs, )).cuda()\n",
    "\n",
    "        loss = evaluate_loss(parameters, X[ix].cuda(), Y[ix].cuda(), block_size, embedding_size)\n",
    "        regularization_loss = _regularization_loss(parameters, lambdas)\n",
    "        loss += regularization_loss\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad= None\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += - lr * p.grad\n",
    "\n",
    "        if enable_print and epoch % print_at_every_nth_epoch == 0: print(epoch, loss.item())\n",
    "    \n",
    "    return parameters, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T20:58:23.926591Z",
     "iopub.status.busy": "2022-12-28T20:58:23.926218Z",
     "iopub.status.idle": "2022-12-28T20:58:23.958216Z",
     "shell.execute_reply": "2022-12-28T20:58:23.957139Z",
     "shell.execute_reply.started": "2022-12-28T20:58:23.926559Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 46.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.295814037322998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train_v3(Xtr, Ytr, 1, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial loss is now `3.2958` (which we wanted). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how well it trains now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T21:06:35.665208Z",
     "iopub.status.busy": "2022-12-28T21:06:35.664857Z",
     "iopub.status.idle": "2022-12-28T21:15:47.637249Z",
     "shell.execute_reply": "2022-12-28T21:15:47.636265Z",
     "shell.execute_reply.started": "2022-12-28T21:06:35.665178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/30000 [00:00<09:14, 54.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.295814037322998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10008/30000 [03:03<06:04, 54.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.8334920406341553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20009/30000 [06:08<03:04, 54.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2.827484369277954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [09:11<00:00, 54.35it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train_v3(Xtr, Ytr, 30_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T21:16:18.063951Z",
     "iopub.status.busy": "2022-12-28T21:16:18.063542Z",
     "iopub.status.idle": "2022-12-28T21:16:18.070236Z",
     "shell.execute_reply": "2022-12-28T21:16:18.069147Z",
     "shell.execute_reply.started": "2022-12-28T21:16:18.063905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8184070587158203"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the losses are not decreasing faster, lets not initialize weight to zero but close to zero and see ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T21:16:35.333446Z",
     "iopub.status.busy": "2022-12-28T21:16:35.332462Z",
     "iopub.status.idle": "2022-12-28T21:16:35.344949Z",
     "shell.execute_reply": "2022-12-28T21:16:35.343454Z",
     "shell.execute_reply.started": "2022-12-28T21:16:35.333383Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_v4(X, \n",
    "          Y, \n",
    "          epochs, \n",
    "          block_size=3, \n",
    "          embedding_size=10, \n",
    "          hidden_neuron=300, \n",
    "          bs=32, \n",
    "          lr=0.1, \n",
    "          parameters=[], \n",
    "          lambdas = [0, 0, 0],\n",
    "          enable_print=True,\n",
    "          print_at_every_nth_epoch=10000\n",
    "         ):\n",
    "    \n",
    "    if not parameters:\n",
    "        C = torch.rand((27, embedding_size), generator=g).cuda()\n",
    "        W1 = torch.rand((block_size * embedding_size, hidden_neuron), generator=g).cuda()\n",
    "        b1 = torch.rand(hidden_neuron).cuda()\n",
    "        W2 = torch.rand((hidden_neuron, 27)).cuda() * 0.01 # close to zero\n",
    "        b2 = torch.zeros(27).cuda()\n",
    "        parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "    \n",
    "    for p in parameters: p.requires_grad = True \n",
    "        \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "        ix = torch.randint(0, X.shape[0], (bs, )).cuda()\n",
    "\n",
    "        loss = evaluate_loss(parameters, X[ix].cuda(), Y[ix].cuda(), block_size, embedding_size)\n",
    "        regularization_loss = _regularization_loss(parameters, lambdas)\n",
    "        loss += regularization_loss\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad= None\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += - lr * p.grad\n",
    "\n",
    "        if enable_print and epoch % print_at_every_nth_epoch == 0: print(epoch, loss.item())\n",
    "    \n",
    "    return parameters, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T21:31:53.631253Z",
     "iopub.status.busy": "2022-12-28T21:31:53.630902Z",
     "iopub.status.idle": "2022-12-28T21:40:58.806741Z",
     "shell.execute_reply": "2022-12-28T21:40:58.805651Z",
     "shell.execute_reply.started": "2022-12-28T21:31:53.631223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/30000 [00:00<08:38, 57.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2842519283294678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10008/30000 [03:01<05:57, 55.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.810333013534546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20010/30000 [06:01<03:02, 54.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2.8224377632141113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [09:05<00:00, 55.03it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train_v4(Xtr, Ytr, 30_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets not try to uniformly initiate all the weights but only the last layers and the rest we can keep as normal initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:35:23.645843Z",
     "iopub.status.busy": "2022-12-28T22:35:23.645459Z",
     "iopub.status.idle": "2022-12-28T22:35:23.659794Z",
     "shell.execute_reply": "2022-12-28T22:35:23.658615Z",
     "shell.execute_reply.started": "2022-12-28T22:35:23.645811Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_v5(X, \n",
    "          Y, \n",
    "          epochs, \n",
    "          block_size=3, \n",
    "          embedding_size=10, \n",
    "          hidden_neuron=300, \n",
    "          bs=32, \n",
    "          lr=0.1, \n",
    "          parameters=[], \n",
    "          lambdas = [0, 0, 0],\n",
    "          enable_print=True,\n",
    "          print_at_every_nth_epoch=10000\n",
    "         ):\n",
    "    \n",
    "    if not parameters:\n",
    "        C = torch.randn((27, embedding_size), generator=g).cuda()\n",
    "        W1 = torch.randn((block_size * embedding_size, hidden_neuron), generator=g).cuda()\n",
    "        b1 = torch.randn(hidden_neuron).cuda()\n",
    "        W2 = torch.rand((hidden_neuron, 27)).cuda() * 0.01 # close to zero\n",
    "        b2 = torch.zeros(27).cuda()\n",
    "        parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "    \n",
    "    for p in parameters: p.requires_grad = True \n",
    "        \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "        ix = torch.randint(0, X.shape[0], (bs, )).cuda()\n",
    "\n",
    "        loss = evaluate_loss(parameters, X[ix].cuda(), Y[ix].cuda(), block_size, embedding_size)\n",
    "        regularization_loss = _regularization_loss(parameters, lambdas)\n",
    "        loss += regularization_loss\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad= None\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += - lr * p.grad\n",
    "\n",
    "        if enable_print and epoch % print_at_every_nth_epoch == 0: print(epoch, loss.item())\n",
    "    \n",
    "    return parameters, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:35:45.537950Z",
     "iopub.status.busy": "2022-12-28T22:35:45.537604Z",
     "iopub.status.idle": "2022-12-28T22:44:31.113146Z",
     "shell.execute_reply": "2022-12-28T22:44:31.112173Z",
     "shell.execute_reply.started": "2022-12-28T22:35:45.537921Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/30000 [00:01<58:14,  8.58it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2948546409606934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10008/30000 [02:54<05:42, 58.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.190589427947998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20010/30000 [05:48<02:53, 57.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2.175851821899414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [08:42<00:00, 57.39it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train_v5(Xtr, Ytr, 30_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=10_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The losses are reducing now. Lets train for 100_000 and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T22:47:17.409034Z",
     "iopub.status.busy": "2022-12-28T22:47:17.408674Z",
     "iopub.status.idle": "2022-12-28T23:16:17.322021Z",
     "shell.execute_reply": "2022-12-28T23:16:17.320990Z",
     "shell.execute_reply.started": "2022-12-28T22:47:17.409005Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/100000 [00:00<29:50, 55.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.297055721282959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10009/100000 [02:58<26:48, 55.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.2041165828704834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20008/100000 [05:55<23:44, 56.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2.1607794761657715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30010/100000 [08:49<20:05, 58.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 2.153400182723999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40012/100000 [11:42<17:13, 58.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 2.128110408782959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50008/100000 [14:34<14:20, 58.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 2.111949920654297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60008/100000 [17:27<11:28, 58.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 2.116779327392578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70009/100000 [20:19<08:36, 58.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 2.094712972640991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80011/100000 [23:12<05:43, 58.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 2.095874309539795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90008/100000 [26:04<02:56, 56.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000 2.104464530944824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [28:59<00:00, 57.47it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train_v5(Xtr, Ytr, 100_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T23:16:17.324042Z",
     "iopub.status.busy": "2022-12-28T23:16:17.323695Z",
     "iopub.status.idle": "2022-12-28T23:16:17.330516Z",
     "shell.execute_reply": "2022-12-28T23:16:17.329573Z",
     "shell.execute_reply.started": "2022-12-28T23:16:17.324006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0862724781036377"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The losses are getting reduced faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T23:19:41.774902Z",
     "iopub.status.busy": "2022-12-28T23:19:41.774553Z",
     "iopub.status.idle": "2022-12-28T23:19:41.800488Z",
     "shell.execute_reply": "2022-12-28T23:19:41.799522Z",
     "shell.execute_reply.started": "2022-12-28T23:19:41.774873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1515, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(parameters, Xdev.cuda(), Ydev.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-28T23:20:45.225423Z",
     "iopub.status.busy": "2022-12-28T23:20:45.224990Z",
     "iopub.status.idle": "2022-12-28T23:20:45.241142Z",
     "shell.execute_reply": "2022-12-28T23:20:45.240379Z",
     "shell.execute_reply.started": "2022-12-28T23:20:45.225387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1520, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss(parameters, Xte.cuda(), Yte.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Bengio et al 2003 paper, implement and try any idea from the paper. Did it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper there is a mention of direct connection from the word features to output. \n",
    "\n",
    "Lets implement the direct connection from embedding to output and see the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct connection from embedding to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T00:12:25.990828Z",
     "iopub.status.busy": "2022-12-29T00:12:25.990167Z",
     "iopub.status.idle": "2022-12-29T00:12:25.997450Z",
     "shell.execute_reply": "2022-12-29T00:12:25.996392Z",
     "shell.execute_reply.started": "2022-12-29T00:12:25.990791Z"
    }
   },
   "outputs": [],
   "source": [
    "C = torch.randn((27, 50), generator=g).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T00:12:37.161315Z",
     "iopub.status.busy": "2022-12-29T00:12:37.160962Z",
     "iopub.status.idle": "2022-12-29T00:12:37.171011Z",
     "shell.execute_reply": "2022-12-29T00:12:37.170008Z",
     "shell.execute_reply.started": "2022-12-29T00:12:37.161284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 150])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape; C[X].view(-1, 150).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T00:13:17.415426Z",
     "iopub.status.busy": "2022-12-29T00:13:17.414974Z",
     "iopub.status.idle": "2022-12-29T00:13:17.422479Z",
     "shell.execute_reply": "2022-12-29T00:13:17.421467Z",
     "shell.execute_reply.started": "2022-12-29T00:13:17.415391Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_loss_dir_conn(parameters, X, Y, block_size=3, embedding_size=10):\n",
    "    C, W1, b1, W2, W3, b2 = parameters\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2 + C[X].view(-1, block_size * embedding_size) @ W3\n",
    "    loss = F.cross_entropy(logits.cuda(), Y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T00:13:17.769097Z",
     "iopub.status.busy": "2022-12-29T00:13:17.768827Z",
     "iopub.status.idle": "2022-12-29T00:13:17.780236Z",
     "shell.execute_reply": "2022-12-29T00:13:17.779285Z",
     "shell.execute_reply.started": "2022-12-29T00:13:17.769073Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_dir_conn(X, \n",
    "          Y, \n",
    "          epochs, \n",
    "          block_size=3, \n",
    "          embedding_size=10, \n",
    "          hidden_neuron=300, \n",
    "          bs=32, \n",
    "          lr=0.1, \n",
    "          parameters=[], \n",
    "          lambdas = [0, 0, 0],\n",
    "          enable_print=True,\n",
    "          print_at_every_nth_epoch=10000\n",
    "         ):\n",
    "    \n",
    "    if not parameters:\n",
    "        C = torch.randn((27, embedding_size), generator=g).cuda()\n",
    "        W1 = torch.randn((block_size * embedding_size, hidden_neuron), generator=g).cuda()\n",
    "        b1 = torch.randn(hidden_neuron).cuda()\n",
    "        W2 = torch.rand((hidden_neuron, 27)).cuda() * 0.01 # close to zero\n",
    "        W3 = torch.rand((block_size * embedding_size, 27)).cuda() * 0.01 # close to zero\n",
    "        b2 = torch.zeros(27).cuda()\n",
    "        parameters = [C, W1, b1, W2, W3, b2]\n",
    "\n",
    "    \n",
    "    for p in parameters: p.requires_grad = True \n",
    "        \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "        ix = torch.randint(0, X.shape[0], (bs, )).cuda()\n",
    "\n",
    "        loss = evaluate_loss_dir_conn(parameters, X[ix].cuda(), Y[ix].cuda(), block_size, embedding_size)\n",
    "        regularization_loss = _regularization_loss(parameters, lambdas)\n",
    "        loss += regularization_loss\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad= None\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        for p in parameters:\n",
    "            p.data += - lr * p.grad\n",
    "\n",
    "        if enable_print and epoch % print_at_every_nth_epoch == 0: print(epoch, loss.item())\n",
    "    \n",
    "    return parameters, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T00:13:20.253468Z",
     "iopub.status.busy": "2022-12-29T00:13:20.253084Z",
     "iopub.status.idle": "2022-12-29T01:06:46.285132Z",
     "shell.execute_reply": "2022-12-29T01:06:46.284239Z",
     "shell.execute_reply.started": "2022-12-29T00:13:20.253437Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/100000 [00:00<51:53, 32.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.295320987701416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10006/100000 [05:20<47:52, 31.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.150477647781372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20005/100000 [10:40<42:17, 31.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 2.124218702316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30006/100000 [16:01<37:17, 31.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 2.0882301330566406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40006/100000 [21:21<31:49, 31.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 2.1032118797302246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50007/100000 [26:41<27:06, 30.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 2.0811822414398193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60006/100000 [32:01<21:20, 31.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 2.0820119380950928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70007/100000 [37:22<16:01, 31.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 2.064924478530884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80005/100000 [42:42<10:33, 31.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 2.0588784217834473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90005/100000 [48:02<05:15, 31.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000 2.078995704650879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [53:26<00:00, 31.19it/s]\n"
     ]
    }
   ],
   "source": [
    "parameters, loss = train_dir_conn(Xtr, Ytr, 100_000, block_size=3, embedding_size=50, hidden_neuron=100, bs=16384, lr=0.1, enable_print=True, print_at_every_nth_epoch=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T01:31:03.583955Z",
     "iopub.status.busy": "2022-12-29T01:31:03.583594Z",
     "iopub.status.idle": "2022-12-29T01:31:03.590394Z",
     "shell.execute_reply": "2022-12-29T01:31:03.589386Z",
     "shell.execute_reply.started": "2022-12-29T01:31:03.583926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0455985069274902"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T01:31:47.236163Z",
     "iopub.status.busy": "2022-12-29T01:31:47.235819Z",
     "iopub.status.idle": "2022-12-29T01:31:47.247385Z",
     "shell.execute_reply": "2022-12-29T01:31:47.246172Z",
     "shell.execute_reply.started": "2022-12-29T01:31:47.236134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1238, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss_dir_conn(parameters, Xdev.cuda(), Ydev.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-29T01:32:22.305929Z",
     "iopub.status.busy": "2022-12-29T01:32:22.305219Z",
     "iopub.status.idle": "2022-12-29T01:32:22.314562Z",
     "shell.execute_reply": "2022-12-29T01:32:22.313363Z",
     "shell.execute_reply.started": "2022-12-29T01:32:22.305897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1266, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_loss_dir_conn(parameters, Xte.cuda(), Yte.cuda(), block_size=3, embedding_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss decreased by lot with this direct connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixing NN output with the trigram model output\n",
    "> Trigram model is the statistical model I implemented in the Lesson's 2 exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (zhnn)",
   "language": "python",
   "name": "zhnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
